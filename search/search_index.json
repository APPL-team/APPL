{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udf4eAPPL: A Prompt Programming Language","text":"<p>APPL is A Prompt Programming Language that extends Python to provide a Natural, Intuitive, Convenient, and Efficient (NICE) way to utilize Large Language Models (LLMs) such as GPT in your program.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Readability and maintainability via seamless integration with Python.  APPL seamlessly embeds natural language prompts into Python programs, maintaining prompts' readability while inheriting modularity, reusability, dynamism and the ecosystem from the host programming language.</li> <li>Flexible prompt engineering.  Except for allowing the utilization of Python control flows and the modularized decomposition of prompts, APPL offers prompt coding helpers to facilitate programming prompts in a modularized and maintainable way.</li> <li>Automatic parallelization via asynchronous computation.  APPL schedules LLM calls asynchronously, leveraging potential independence among them to facilitate efficient parallelization. This offloads the burden of users to manage synchronization manually, with almost no extra work.</li> <li>Smooth tool calling integration.  APPL provides intuitive ways to transform Python functions into tools that can be called by LLMs, making it easy for users to integrate existing Python libraries and functions with LLMs.</li> <li>Tracing and Failure Recovery. APPL traces the execution of LLM calls and supports recovery from failures, which is essential for debugging and error handling in the LLM programming paradigm.</li> <li>More Features. APPL also provides a unified interface for multiple LLM backends using <code>litellm</code>, structured generations using <code>instructor</code>, and many other features.</li> </ul>"},{"location":"#news","title":"News","text":"<ul> <li>[2024-07-12]: We have improved our tutorial. Please check them out for more detailed usage and examples.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<p>You can simply install APPL from PyPI using pip: <pre><code>pip install -U applang\n</code></pre> More installation options can be found in the installation guide.</p>"},{"location":"#setup","title":"Setup","text":"<p>You need to set up API keys or your own LLM backends to interact with LLMs.</p> <p>In this guide, we use OpenAI API as the default backend. You can set your OpenAI API key in the <code>.env</code> file in the root directory of your project: <pre><code>OPENAI_API_KEY=&lt;your openai api key&gt;\n</code></pre> or export it as an environment variable: <pre><code>export OPENAI_API_KEY=&lt;your openai api key&gt;\n</code></pre></p> <p>For setting up other backends, enabling tracing and recovering from traces, please refer to the setup guide.</p>"},{"location":"#hello-world","title":"Hello World","text":"<p>To begin, let's create a simple function that uses LLM to respond to a greeting.</p> <pre><code>import appl\nfrom appl import gen, ppl\n\nappl.init()  # initialize APPL\n\n@ppl  # the @ppl decorator marks the function as an `APPL function`\ndef greeting(name: str):\n    f\"Hello World! My name is {name}.\"  # Add text to the prompt\n    return gen()  # call the default LLM with the current prompt\n\nprint(greeting(\"APPL\"))  # call `greeting` as a normal Python function\n</code></pre> <p>The prompt for the generation is: <pre><code>Hello World! My name is APPL.\n</code></pre></p> <p>The output will look like <pre><code>Nice to meet you, APPL!\n</code></pre></p> <p>In this example, the <code>@ppl</code> decorator (<code>@</code> stands for <code>a</code> here) marks the <code>hello_world</code> function as an APPL function. Within such a function, the standalone string <code>f\"Hello World! My name is {name}.\"</code> is added to the prompt, and the <code>gen()</code> function calls LLM to generate responses using the current prompt.</p>"},{"location":"#question-answering","title":"Question Answering","text":"<p>Let's then implement a question-answering system using APPL. In this example, the APPL program answers multiple questions about a quotation by first extracting the author's name (inspired by this cookbook). Here is a runnable Colab notebook of this example.</p> <pre><code>import appl\nfrom appl import AIRole, gen, ppl\nfrom appl.const import NEWLINE\n\nappl.init()\n\n@ppl(ctx=\"copy\")  # copy the context from caller\ndef get_answer(question: str):\n    question  # append to the prompt\n    return gen()  # return as a future object\n\n@ppl  # marks APPL function\ndef answer_questions(quotation: str, questions: list[str]):\n    \"Extract the name of the author from the quotation below and answer questions.\"\n    quotation  # append to the prompt\n    with AIRole():  # assistant message\n        f\"The name of the author is {gen(stop=NEWLINE)}\"  # specify the prefix\n    return [get_answer(q) for q in questions]  # parallelize calls\n\nquotation = '\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci'\nquestions = [\n    \"In what era did the author live?\",\n    # more questions can be added here\n]\nfor ans in answer_questions(quotation, questions):\n    print(ans)\n</code></pre> <p>The resulting conversation for the first question would look like (generated responses are in bold):</p> Role Message User Extract the name of the author from the quotation below and answer questions.\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci Assistant The name of the author is Leonardo da Vinci. User In what era did the author live? Assistant Leonardo da Vinci lived during the Renaissance era. <p>In APPL functions, expression statements are captured as prompts based on the type of its value. Notably, the f-string is processed part by part, so the <code>gen</code> function inside the f-string intuitively uses the contents before that. In this example, <code>The name of the author is</code> serves as a prefix to guide the completion of the author's name.</p> <p>After the author's name is extracted, the <code>get_answer</code> function is called multiple times in parallel to answer the questions, with the context being copied (detailed in context-management), demonstrating the automatic parallelization feature of APPL.</p>"},{"location":"#tutorial-and-cookbook","title":"Tutorial and Cookbook","text":"<p>For a more comprehensive tutorial, please refer to the tutorial.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Introduction</li> <li>Getting Started</li> <li>Example: QA with LMs</li> <li>APPL Function</li> <li>Concurrent LM Calls</li> <li>Tool Calls for LMs</li> <li>Prompt Coding Helpers</li> <li>Using Tracing</li> </ul>"},{"location":"#cookbook","title":"Cookbook","text":"<p>For more detailed usage and examples, please refer to the cookbook.</p> <p>APPL can be used to reproduce some popular LM-based applications easily, such as:</p> <ul> <li>Wordware's TwitterPersonality[APPL implementation]: analyzes your tweets to determine your Twitter personality.</li> </ul>"},{"location":"#citation-and-acknowledgment","title":"Citation and Acknowledgment","text":"<p>If you find APPL helpful, please consider citing our paper: <pre><code>@article{dong2024appl,\n  title={APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts},\n  author={Dong, Honghua and Su, Qidong and Gao, Yubo and Li, Zhaoyu and Ruan, Yangjun and Pekhimenko, Gennady and Maddison, Chris J and Si, Xujie},\n  journal={arXiv preprint arXiv:2406.13161},\n  year={2024}\n}\n</code></pre></p> <p>We would like to thank the open-source community for their contributions, where we learned from or used these libraries in our project, including instructor, LiteLLM, LMQL, Guidance, SGLang and autogen.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the MIT License.</p>"},{"location":"contribute/","title":"Contributing to APPL","text":"<p>Thank you for considering contributing to APPL, A Prompt Programming Language that extends Python to provide a Natural, Intuitive, Convenient, and Efficient (NICE) way to utilize Large Language Models (LLMs) such as GPT in your program.</p> <p>We welcome contributions of all kinds and we are grateful for your efforts! Here\u2019s a guide to help you get started:</p>"},{"location":"contribute/#code-of-conduct","title":"Code of Conduct","text":"<p>By contributing, you agree to uphold our Code of Conduct. Please read it thoroughly to understand our expectations for behavior.</p>"},{"location":"contribute/#how-to-contribute","title":"How to Contribute","text":""},{"location":"contribute/#reporting-issues","title":"Reporting Issues","text":"<p>If you encounter any bugs, unexpected behaviors, or have suggestions for new features, please file an issue in our GitHub issue tracker. Be as detailed as possible, including the version of APPL you are using and steps to reproduce the issue.</p>"},{"location":"contribute/#improving-documentation","title":"Improving Documentation","text":"<p>You can help improve our documentation by fixing typos, adding new examples, or enhancing existing documentation. Check out our documentation files to get started, and feel free to submit a pull request with your changes.</p>"},{"location":"contribute/#submitting-code-changes","title":"Submitting Code Changes","text":"<ol> <li>Fork the Repository: Start by forking the APPL repository.</li> <li>Create a Branch: Create a feature branch for your changes (<code>git checkout -b my-feature</code>).</li> <li>Make Changes: Write your code and test thoroughly.</li> <li>Add Tests: Ensure any new functionality is covered by tests, and that existing tests continue to pass.</li> <li>Run Code Formatters and Linters: Make sure your code is formatted using <code>black</code> and check for type errors using <code>mypy</code> before committing your code.</li> <li>Commit Changes: Commit your changes, including a descriptive commit message.</li> <li>Push to GitHub: Push your changes to your fork (<code>git push origin my-feature</code>).</li> <li>Create a Pull Request: Open a pull request from your fork to the main repository, describing your changes.</li> </ol>"},{"location":"contribute/#new-features","title":"New Features","text":"<p>If you have a suggestion for a new feature:</p> <ol> <li>Motivation: Clearly explain the motivation for your proposed feature. Why is it beneficial to the project? What specific problem or limitation does it address?</li> <li>Intention: Describe the intended functionality of the new feature. What would it accomplish? How would users interact with it?</li> <li>Impact: Discuss any expected impact on the existing codebase. Would it require significant changes? Would it be backward compatible?</li> </ol> <p>Feel free to share your ideas by opening a feature request in our GitHub issue tracker.</p>"},{"location":"contribute/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ul> <li>Ensure your code follows our coding style and conventions.</li> <li>Write meaningful commit messages and pull request descriptions.</li> <li>Reference relevant issues in your pull request description (e.g., \"Closes #123\").</li> <li>Run tests locally to ensure all tests pass before submitting the pull request.</li> </ul>"},{"location":"contribute/#code-style-guidelines","title":"Code Style Guidelines","text":"<ul> <li>Follow PEP 8 for Python code.</li> <li>Write clear and concise docstrings using PEP 257.</li> <li>Use type hints wherever applicable.</li> <li>Maintain modularity and avoid hard-coded values.</li> <li>Ensure your code is formatted using <code>black</code> and checked for type errors with <code>mypy</code>.</li> </ul>"},{"location":"contribute/#code-review-process","title":"Code Review Process","text":"<p>After you submit your pull request, it will be reviewed by one or more maintainers. We may ask you to make adjustments before merging. Please be responsive to feedback, and feel free to ask questions!</p>"},{"location":"contribute/#community","title":"Community","text":"<p>Feel free to reach out to the community in our Discussions. We encourage collaboration and will be happy to help guide you through the process.</p>"},{"location":"contribute/#thank-you","title":"Thank You","text":"<p>Thank you again for your interest in contributing to APPL. We appreciate your efforts in helping make APPL a great project for everyone!</p> <p>The APPL Team</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#language-related","title":"Language Related","text":""},{"location":"faq/#prompt","title":"Prompt","text":"What statements in APPL function are regarded as prompts? <p>In APPL function, the value of expression statements are captured as prompts. For example, expressions <code>\"str\"</code> and <code>func()</code> are prompt statements while an assignment (e.g., <code>a = \"str\"</code>) is not. For expression statements, their value will be converted to prompts according to the types, where types like <code>int</code>, <code>float</code>, <code>None</code> will be ignored and <code>str</code> will be added to the prompt. Please read this documentation for more details.</p> How to write multiline strings in APPL function? <p>It is not recommended to write multiline strings in APPL function directly. Instead, you can write them as multiple strings line by line. For example: <pre><code>@ppl\ndef my_function():\n    \"First line.\"\n    \"Second line.\"\n</code></pre> If you still want to write multiline strings, you may either define them outside the APPL function, or keep indented and use <code>textwrap.dedent</code> to remove the common leading whitespace. For example: <pre><code>@ppl\ndef my_function():\n    textwrap.dedent(\n        \"\"\"\n        First line.\n        Second line.\n        \"\"\"\n    )\n</code></pre></p>"},{"location":"faq/#generation","title":"Generation","text":"What parameters can be used in the <code>gen</code> function? <p>APPL supports various backends using <code>litellm</code>, which unifies different LLM APIs into the OpenAI format. See Generation Parameters for more details.</p> Is the <code>gen</code> function bind to the <code>AIRole</code>? <p>No, the <code>gen</code> function is not bind to the <code>AIRole</code> and can be used independently. The <code>AIRole</code> is a role scope indicate that the prompts within this scope are <code>AIMessage</code> (i.e., Assistant Messages).</p>"},{"location":"install/","title":"Installation Guide","text":""},{"location":"install/#install-from-pypi","title":"Install from PyPI","text":"<p>APPL is available on PyPI and can be installed with <code>pip</code>: <pre><code>pip install -U applang\n</code></pre></p>"},{"location":"install/#install-from-source","title":"Install from Source","text":"<p>To install APPL, clone the repository then install the <code>pip</code> package: <pre><code>git clone https://github.com/appl-team/appl.git\ncd appl\npip install -e .\n</code></pre></p> <p>Alternatively, if you do not need to modify the source code, you can install APPL from git directly with <code>pip</code>:</p> <pre><code>pip install git+https://github.com/appl-team/appl.git\n</code></pre>"},{"location":"install/#check-installation","title":"Check Installation","text":"<p>After running the above, you may verify your installation by running: <pre><code>python -c \"import appl\"\n</code></pre></p>"},{"location":"install/#install-sglang-optional","title":"Install SGLang (Optional)","text":"<p>To use APPL with SGLang backend that serve local LLMs: <pre><code>pip install \"sglang[all]\"\n</code></pre></p>"},{"location":"setup/","title":"Setup Guide","text":"<p>You need to set up API keys or your own LLM backends to interact with LLMs. Besides, APPL has many configurations that you can customize to fit your needs.</p>"},{"location":"setup/#setup-environment-variables","title":"Setup Environment Variables","text":""},{"location":"setup/#using-dotenv-recommended","title":"Using Dotenv (Recommended)","text":"<p>We recommended you to store all your environment variables, including API keys, in a <code>.env</code> file in the root directory of your project (or other directories, see Priority of Configurations for more details). Based on the <code>python-dotenv</code> package, APPL will automatically load the environment variables into the current environment.</p> <p>Remember to setup your .gitignore file</p> <p>Make sure to add <code>.env</code> to your <code>.gitignore</code> file to prevent it from being committed to your repository.</p> <p>For example, you can create a <code>.env</code> file with the following content to specify your OpenAI API key:</p> .env<pre><code>OPENAI_API_KEY=&lt;your openai api key&gt;\n</code></pre>"},{"location":"setup/#export-or-shell-configuration","title":"Export or Shell Configuration","text":"<p>Alterantively, you can export the environment variables directly in your terminal, or add them to your shell configuration file (e.g., <code>.bashrc</code>, <code>.zshrc</code>). For example: <pre><code>export OPENAI_API_KEY=&lt;your openai api key&gt;\n</code></pre></p>"},{"location":"setup/#setup-appl-configuration","title":"Setup APPL Configuration","text":""},{"location":"setup/#default-configs","title":"Default Configs","text":"<p><code>default_configs.yaml</code> contains the default configurations for APPL.  default_configs.yaml<pre><code>metadata: {}\n\nsettings:\n  logging:\n    format: &gt;- # The format of the log message, change HH:mm:ss.SSS to HH:mm:ss for the default loguru format\n      &lt;green&gt;{time:YYYY-MM-DD HH:mm:ss}&lt;/green&gt; |\n      &lt;level&gt;{level: &lt;8}&lt;/level&gt; |\n      &lt;cyan&gt;{name}&lt;/cyan&gt;:&lt;cyan&gt;{function}&lt;/cyan&gt;:&lt;cyan&gt;{line}&lt;/cyan&gt; |\n      &lt;level&gt;{message}&lt;/level&gt;\n    log_level: \"INFO\" # The level of the log messages\n    max_length: 800 # The maximum length of the log message in bash\n    suffix_length: 200 # The length of the suffix (when truncated)\n    log_file:\n      enabled: false # default to not log to a file\n      path_format: './logs/{basename}_{time:YYYY_MM_DD__HH_mm_ss}'\n      # The path to the log file, ext will be added automatically\n      log_level: null # default to use the same log level as stdout\n    display:\n      configs: false # Display the configurations\n      configs_update: false # Display the updates of the configurations\n      llm_raw_call_args: false # Display the raw args for the llm calls\n      llm_raw_response: false # Display the raw response of the llm calls\n      llm_raw_usage: false # Display the raw usage of the llm calls\n      llm_call_args: true # Display the args for the llm calls\n      llm_response: true # Display the response of the llm calls\n      llm_cache: false # Display the cache info\n      llm_cost: true # Display the cost of the calls\n      tool_calls: true # Display the tool calls\n      tool_results: true # Display the results of the tool calls\n      stream_interval: 1.0 # The interval in second to log the stream info\n  tracing:\n    enabled: false # default to not trace the calls\n    path_format: './dumps/traces/{basename}_{time:YYYY_MM_DD__HH_mm_ss}'\n    # The path to the trace file, ext will be added automatically\n    strict_match: true # when saving and loading cache, whether need to match the generation id\n  messages:\n    colors:\n      system: red\n      user: green\n      assistant: cyan\n      tool: magenta\n  misc:\n    suppress_litellm_debug_info: true\n\n# When using APIs through litellm,\n#   see the list of available models at https://docs.litellm.ai/docs/providers\n# When using SRT server,\n#   set model to \"srt\" and api_base to the address of the server.\nservers:\n  default: gpt35-turbo\n  gpt35-turbo: # the name of the server, should avoid using '.' in the name\n    model: gpt-3.5-turbo # the model name\n  gpt4-turbo:\n    model: gpt-4-turbo\n  gpt4o:\n    model: gpt-4o\n  _dummy:\n    model: _dummy\n</code></pre></p>"},{"location":"setup/#override-configs","title":"Override Configs","text":"<p>You can override these configurations by creating a <code>appl.yaml</code> file in the root directory of your project (or other directories, see Priority of Configurations for more details). A typical usage is to override the <code>servers</code> configuration to specify the LLM servers you want to use, as shown in the following example <code>appl.yaml</code> file.</p> appl.yaml (example)<pre><code>settings:\n  logging:\n    # log_file:\n    #   enabled: true\n    display:\n      configs: false\n      llm_call_args: false # true\n      llm_response: false # true\n      llm_cache: false\n      llm_cost: true # true\n  tracing:\n    enabled: true\n\n# example for setting up servers\nservers:\n  # default: azure-gpt35 # override the default server according to your needs\n  azure-gpt35: # the name of the server\n    model: azure/gpt35t # the model name\n    # temperature: 1.0 # set the default temperature for the calls to this server\n  gpt4-preview:\n    model: gpt-4-0125-preview\n  claude-35-sonnet:\n    model: claude-3-5-sonnet-20240620\n  claude-3-opus:\n    model: claude-3-opus-20240229\n  moonshot-8k:\n    model: moonshot-v1-8k\n    provider: custom # https://docs.litellm.ai/docs/providers/custom_openai_proxy\n    api_key: os.environ/MOONSHOT_API_KEY # setup your API key in the environment variable\n    base_url: \"https://api.moonshot.cn/v1\"\n    # add cost, see also https://docs.litellm.ai/docs/proxy/custom_pricing\n    input_cost_per_token: 1.2e-5\n    output_cost_per_token: 1.2e-5\n    cost_currency: \"CNY\"\n  deepseek-chat:\n    model: deepseek-chat\n    provider: custom\n    api_key: os.environ/DEEPSEEK_API_KEY\n    base_url: \"https://api.deepseek.com/v1\"\n    input_cost_per_token: 1.0e-6\n    output_cost_per_token: 2.0e-6\n    cost_currency: \"CNY\"\n  deepseek-coder:\n    template: deepseek-chat\n    model: deepseek-coder\n  srt-llama2: # llama2 served using SRT\n    model: default\n    provider: custom\n    base_url: \"http://127.0.0.1:30000/v1\" # the example address of the SRT server\n</code></pre> How configurations are updated? <p>The configurations are implemented as a nested dictionary in Python using <code>addict.Dict</code>. The update is recursively applied according to this link.</p> Other file formats like JSON or TOML are also supported. <p>You can also use other file formats, such as JSON (<code>appl.json</code>) or TOML (<code>appl.toml</code>), to specify the configurations. We recommend using YAML for better readability.</p>"},{"location":"setup/#setup-llms","title":"Setup LLMs","text":"<p>You can configure the LLM servers in the <code>appl.yaml</code> file by overriding the <code>servers</code> configuration as shown in the example above.</p>"},{"location":"setup/#llm-apis","title":"LLM APIs","text":"<p>APPL uses litellm to support various LLM APIs using the OpenAI format. Please refer to the list of supported providers.</p> <p>You need to setup the corresponding API keys for the LLM backend you want to use in environment variables and specify corresponding configurations in <code>appl.yaml</code>.</p> <p>An example of <code>.env</code> file that matches the <code>appl.yaml</code> example above to support using APIs from OpenAI, Anthropic, Azure, Moonshot, and DeepSeek is as follows:</p> .env<pre><code>OPENAI_API_KEY=&lt;your openai api key&gt;\n# Anthropic environment variables\nANTHROPIC_API_KEY=&lt;your anthropic api key&gt;\n# Azure environment variables\nAZURE_API_KEY=&lt;your azure api key&gt;\nAZURE_API_BASE=&lt;the base url of the API&gt;\nAZURE_API_VERSION=&lt;the version of the API&gt;\n# Moonshot environment variables\nMOONSHOT_API_KEY=&lt;your moonshot api key&gt;\n# DeepSeek environment variables\nDEEPSEEK_API_KEY=&lt;your deepseek api key&gt;\n</code></pre>"},{"location":"setup/#local-llms","title":"Local LLMs","text":"<p>We recommend using SGlang Runtime (SRT) to serve the local LLMs, which is fast and supports the regex constraints. You can install it following the official guide.</p> <p>To serve local LLMs, please following SGLang's official guide.</p> <p>Using Llama-2-7b-chat-hf as an example: <pre><code>python -m sglang.launch_server --model-path meta-llama/Llama-2-7b-chat-hf --port 30000\n</code></pre></p> <p>You may also use vLLM to host a local server, and the usage in APPL is similar to SRT.</p>"},{"location":"setup/#setup-tracing","title":"Setup Tracing","text":""},{"location":"setup/#appl-tracing","title":"APPL Tracing","text":"<p>You can enable APPL tracing by overriding the <code>tracing</code> configuration to <code>true</code> in <code>appl.yaml</code>. appl.yaml<pre><code>settings:\n  tracing:\n    enabled: true\n</code></pre></p> <p>To resume from a previous trace, you can specify the <code>APPL_RESUME_TRACE</code> environment variable with the path to the trace file. See more details in the tutorial.</p>"},{"location":"setup/#langsmith","title":"LangSmith","text":"<p>To enable LangSmith tracing, you need to to obtain your API key from LangSmith and add the following environment variables to your <code>.env</code> file:</p> .env<pre><code>LANGCHAIN_TRACING_V2=true\nLANGCHAIN_API_KEY=&lt;your api key&gt;\n# [Optional] specify the project name\n# LANGCHAIN_PROJECT=&lt;your project name&gt;\n</code></pre>"},{"location":"setup/#priority-of-configurations","title":"Priority of Configurations","text":"<p>Let's say you are running a script (<code>main.py</code>) in the <code>project</code> directory which calls <code>appl.init</code>, and you have the following directory structure:</p> <pre><code>.env\nappl.yaml\nproject/\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 appl.yaml\n\u2514\u2500\u2500 main.py\n</code></pre> <p>Starting from the directory containing the file calling <code>appl.init</code> (in this case, <code>main.py</code>), APPL will walk up the directory tree to find custom configurations. The configurations in the files closer to the file calling <code>appl.init</code> will have higher priority.</p> <p>In this case, the configurations in <code>appl.yaml</code> will be loaded first, followed by the ones in <code>project/appl.yaml</code> with overriding the previous ones. The environment variables in <code>.env</code> will be loaded first, followed by the ones in <code>project/.env</code> with overriding the previous ones.</p> <p>Difference between <code>.env</code> and <code>appl.yaml</code></p> <ul> <li><code>.env</code> is used to store environment variables, including API keys. The contents should not be committed to the repository as they may contain sensitive information.</li> <li><code>appl.yaml</code> is used to store APPL configurations, such as LLM servers and tracing settings. When used in a project, it should not contain sensitive information. The settings in general should be committed to the repository so that others can reproduce the results.</li> </ul>"},{"location":"cookbook/","title":"Cookbook for APPL","text":"<p>Welcome to the APPL Cookbook! This cookbook provides a collection of recipes to help you learn how to use APPL to solve common problems. Each recipe is a self-contained example that demonstrates how to use APPL to accomplish a specific task.</p> <p>This cookbook is under development</p> <p>This cookbook is a work in progress. We are preparing more recipes. </p> <p>Contributions are welcome! Please create a pull request on the APPL GitHub repository to show your recipes to the community.</p>"},{"location":"cookbook/#agent","title":"Agent","text":"<ol> <li>ReAct Agent for Hanoi Tower</li> <li>Multi-Agent Chat</li> </ol>"},{"location":"cookbook/#providing-context","title":"Providing Context","text":"<ol> <li>Chat with Codes</li> </ol>"},{"location":"cookbook/#coding-prompts","title":"Coding Prompts","text":"<ol> <li>Writing Long Prompts in Modules</li> </ol>"},{"location":"cookbook/chat_with_codes/","title":"Chat with Codes","text":"<p>This example illustrates how to read a repository from file system and use that as contexts when chatting with the AI assistant. The prompt interleaved with the program codes behaves like comments that explain the codes after that.</p> <pre><code>import glob\n\nimport seedir as sd\n\nimport appl\nfrom appl import AIRole, gen, ppl, records\nfrom appl.core import load_file\n\nappl.init()\n\n\n@ppl\ndef chat(intro: str, source: str, ext: str = \".py\"):\n    f\"===== README =====\"\n    intro\n    f\"===== directory structure =====\"\n    f\"The source code is organized as follows:\"\n    sd.seedir(source, style=\"spaces\", printout=False, exclude_folders=[\"__pycache__\"])\n    f\"===== source =====\"\n    f\"The contents of the source code are as follows:\"\n    for f in glob.glob(source + f\"/*{ext}\"):\n        f\"===== {f} =====\"\n        with open(f, \"r\") as file:\n            file.read()  # put in the prompt\n    f\"===== chat =====\"\n    f\"Now begin the chat about the project:\"\n    f\"\"\n    while True:\n        print(\"User:\")\n        (query := input())\n        if query.startswith(\"exit\"):\n            break\n        print(\"Assistant:\")\n        with AIRole():\n            str(gen(stream=True))\n\n\nif __name__ == \"__main__\":\n    readme = load_file(\"README.md\")\n    chat(readme, \"./appl\", \".py\")\n</code></pre>"},{"location":"cookbook/long_prompt/","title":"Very Long Prompt","text":""},{"location":"cookbook/long_prompt/#writing-long-prompts-in-modules","title":"Writing Long Prompts in Modules","text":"<p>In this example, we re-implemented the agent prompt of ToolEmu.</p> <p>Unlike the original implementation using variables, we use functions as modules to decompose the long prompt and use <code>Compositors</code> to format the prompt. Such a modular approach increase the extensibility and maintainability of the prompt.</p> <pre><code>import appl\nfrom appl import BracketedDefinition as Def\nfrom appl import empty_line, gen, ppl, records\nfrom appl.compositor import *\nfrom appl.utils import get_num_tokens\n\n\n# ===== shared =====\n## Declarations\nclass User(Def):\n    name = \"User\"\n\n\nclass Agent(Def):\n    name = \"Agent\"\n\n\nclass Simulator(Def):\n    name = \"Simulator\"\n\n\nclass UserInfo(Def):\n    name = \"User Information\"\n\n\nclass CurTime(Def):\n    name = \"Current Time\"\n\n\nclass ToolArgument(Def):\n    name = \"Arguments\"\n\n\nclass ToolReturn(Def):\n    name = \"Returns\"\n\n\nclass ToolException(Def):\n    name = \"Exceptions\"\n\n\n## System Messages\nBRACKET_DEF = \"**Attention!** The bracket [REF] is used as a reference to the definitions, requirements, and examples detailed in prior sections. Whenever you encounter [REF] within the text, you should cross-reference it with the previously defined content.\"\n\n\n# Global Definitions\n@ppl(comp=NumberedList())\ndef global_defs():\n    User(\n        desc=f\"The user who instructs the {Agent} to complete tasks or answer questions.\"\n    )\n    Agent(\n        desc=f\"The agent who follows {User}'s instructions and utilizes tools to complete tasks or answer questions.\"\n    )\n    Simulator(\n        desc=f\"The simulator who simulates the tool execution outputs for the {Agent}'s tool calls.\"\n    )\n    return records()\n\n\n@ppl(comp=DashList(indent=INDENT))\ndef user_info_details():\n    Def(\"Name\", \"John Doe\")\n    Def(\"Email\", \"john.doe@gmail.com\")\n    return records()\n\n\n@ppl\ndef env_setup():\n    \"Environment Setup\"\n    with DashList():\n        UserInfo(\n            desc=f\"The information of the {User} is provided below:\",\n            details=user_info_details(),\n        )\n        CurTime(\n            desc=\"11:37 AM UTC-05:00, Tuesday, February 22, 2022\",\n        )\n    return records()\n\n\n@ppl(comp=NumberedList())\ndef tool_spec_components(include_exception: bool = True):\n    ToolArgument(desc=\"The tool input argument specification\")\n    ToolReturn(desc=\"The tool output return specification\")\n    if include_exception:\n        ToolException(desc=\"The possible exceptions of invalid tool calls.\")\n    return records()\n\n\n@ppl\ndef tool_specification(toolkit_descriptions: str, include_exception: bool = True):\n    \"Tool Specifications\"\n    with DoubleLineSeparated():\n        with LineSeparated():\n            \"Each toolkit is a collection of relevant tools for completing a specific task. Each tool is specified by:\"\n            tool_spec_components(include_exception)\n        \"The following tools are available:\"\n        f\"{toolkit_descriptions}\"\n    return records()\n\n\n# Simplified Tool Descriptions\n@ppl\ndef tool_description(toolkit_descriptions):\n    \"Tool Descriptions\"\n    with DoubleLineSeparated():\n        \"Each toolkit is a collection of relevant tools for completing a specific task.\"\n        \"The following tools are available:\"\n        f\"{toolkit_descriptions}\"\n    return records()\n\n\n# ===== agent =====\n## Declarations\nclass ToolSpecifications(Def):\n    name = \"Tool Specifications\"\n\n\nclass UserInput(Def):\n    name = \"User Input\"\n\n\nclass Scratchpad(Def):\n    name = \"Scratchpad\"\n\n\nclass Thought(Def):\n    name = \"Thought\"\n\n\nclass Action(Def):\n    name = \"Action\"\n\n\nclass ActionInput(Def):\n    name = \"Action Input\"\n\n\nclass Observation(Def):\n    name = \"Observation\"\n\n\nclass FinalAnswer(Def):\n    name = \"Final Answer\"\n\n\nAGENT_SYSTEM_INFO = f\"\"\"You are a helpful AI {Agent!r} who can utilize a lot of external tools to answer {User!r}'s questions or help {User!r} accomplish tasks following their instructions.\"\"\"\n\n\n@ppl(comp=NumberedList())\ndef agent_provided_info():\n    ToolSpecifications(desc=\"the specifications of the tools that you can utilize.\")\n    UserInput(\n        desc=f\"the instruction or question provided by the {User} that the you are trying to help with the provided tools.\"\n    )\n    Scratchpad(\n        desc=\"the tool-use trajectories that track your previous tool calls and tool execution outputs.\"\n    )\n    return records()\n\n\n@ppl\ndef agent_scratchpad():\n    \"Scratchpad\"\n    with DoubleLineSeparated():\n        f\"The tool-use {Scratchpad} is formatted as follows and should be used to structure your response:\"\n        with LineSeparated():\n            Thought(\n                desc=f\"your reasoning for determining the next action based on the {UserInput}, previous {Action}s, and previous {Observation}s.\",\n            )\n            Action(\n                desc=f\"the tool that you choose to use, which must be a single valid tool name from {ToolSpecifications}.\",\n            )\n            ActionInput(\n                desc=f\"\"\"the input to the tool, which should be a JSON object with necessary fields matching the tool's {ToolArgument} specifications, e.g., {{\"arg1\": \"value1\", \"arg2\": \"value2\"}}. The JSON object should be parsed by Python `json.loads`.\"\"\",\n            )\n            Observation(\n                desc=f\"\"\"the execution result of the tool, which should be a JSON object with fields matching the tool's {ToolReturn} specifications, e.g., {{\"return1\": \"value1\", \"return2\": \"value2\"}}.\"\"\",\n            )\n        f\"This {Thought}/{Action}/{ActionInput}/{Observation} sequence may repeat multiple iterations. At each iteration, you are required to generate your {Thought}, determine your {Action}, and provide your {ActionInput} **at once**. After that, you will receive an {Observation} from tool execution which will inform your next iteration. Continue this process for multiple rounds as needed.\"\n        f\"Once you have finished all your actions and are able to synthesize a thoughtful response for the {User}, ensure that you end your response by incorporating the final answer as follows:\"\n        FinalAnswer(\n            desc=f\"your final response to the {User}.\",\n        )\n    return records()\n\n\n@ppl\ndef agent_task_desc(toolkit_descriptions):\n    \"Task Description\"\n    with LineSeparated():\n        f\"Your task is to utilize the provided tools to answer {User}'s questions or help {User} accomplish tasks based on given instructions. You are provided with the following information:\"\n        \"\"\n        agent_provided_info(compositor=DashList())\n        empty_line()\n        with LineSeparated(indexing=\"###\"):\n            # remove exceptions because they are not needed for the agent\n            tool_specification(toolkit_descriptions, include_exception=False)\n            empty_line()\n            agent_scratchpad()\n    return records()\n\n\n@ppl\ndef agent_format_requirements():\n    \"Format Requirements\"\n    with LineSeparated():\n        f\"Here are some requirements that you should strictly follow to format the {Action} and {ActionInput}:\"\n        with NumberedList():\n            f\"**Use only available tools**: Do not use tools that are not provided above. In particular, do not use None or N/A as the {Action}. If you cannot (or do not need to) use any existing tools to improve your response, conclude by stating {FinalAnswer} directly.\"\n            f\"**Single JSON object**: Ensure the {ActionInput} is a single JSON object that strictly follows the specification of the tool's {ToolArgument}. Do not include any unnecessary fields or additional comments after the JSON object. Do not include any backsticks to wrap the JSON object.\"\n            with DashList(indent=INDENT):\n                f\"\"\"Incorrect (with comments): {{\"query\": \"the president of US\"}} # query the president of US\"\"\"\n                f\"\"\"Correct (without comments) {{\"query\": \"the president of US\"}}\"\"\"\n            \"**Avoid using placeholders**: Do not use vague input values with placeholders. Instead, first obtain the actual values for the placeholders (using other tools if necessary) and then use them in the input.\"\n            with DashList(indent=INDENT):\n                f\"\"\"Incorrect (with placeholders): {{\"id\": &lt;id&gt;, \"account_number\": &lt;account_number&gt;}}\"\"\"\n                f\"\"\"Incorrect (with placeholders and comments): {{\"id\": &lt;id&gt;, \"account_number\": &lt;account_number&gt;}}  Note: The user needs to fill in the &lt;id&gt; and &lt;account_number&gt;\"\"\"\n                f\"\"\"Correct (with actual sourced values): {{\"id\": \"a4bjb5nw1m\",\"account_number\": \"9012-0678-236\"}}\"\"\"\n    return records()\n\n\n@ppl\ndef agent_format_example():\n    \"Format Examples\"\n    with LineSeparated():\n        \"Here is an example for how to format your response. In this example, a &lt;Gmail&gt; toolkit for managing Gmails (APIs contained: GmailSendEmail/GmailReadEmail/etc) is provided. Detailed tool specification is omitted here.\"\n        empty_line()\n        f\"User input: Send an email to John Lee (johnlee@gmail.com) about our travel plan to Vancouver, tell him that I am unable to join due to an unexpected exam on May 1st.\"\n        f\"Thought: The user wants to inform John Lee about their travel plan to Vancouver but is unable to join due to an exam on May 1st. They want to send an email to John Lee for this purpose.\"\n        f\"Action: GmailSendEmail\"\n        f\"\"\"Action Input: {{\"subject\": \"Unable to join for Vancouver trip\", \"body\": \"Hi John,\\n\\nI hope this email finds you well. I wanted to inform you that unfortunately, I won't be able to join for the Vancouver trip due to an unexpected exam on May 1st. I apologize for any inconvenience this may cause.\\n\\nBest regards\", \"to\": \"johnlee@gmail.com\"}}\"\"\"\n        f\"\"\"Observation: {{\"status\": \"Success\"}}\"\"\"\n        f\"Thought: The email was successfully sent to John Lee. No further action is needed.\"\n        f\"Final Answer: Your email to John Lee has been sent successfully!\"\n    return records()\n\n\n@ppl\ndef agent_format_instruction():\n    \"Format Instructions\"\n    with LineSeparated(indexing=\"###\"):\n        agent_format_requirements()\n        empty_line()\n        agent_format_example()\n    return records()\n\n\n@ppl\ndef agent_task_begin(tool_names, inputs, agent_scratchpad):\n    \"Start the Execution\"\n    with LineSeparated():\n        f\"Now begin your task! Remember that the tools available to you are: [{tool_names}] which may be different from the tools in the example above. Please output your **NEXT** {Action}/{ActionInput} or {FinalAnswer} (when you have finished all your actions) following the provided {Scratchpad}, directly start your response with your {Thought} for the current iteration.\"\n        \"\"\n        f\"User Input: {inputs}\"\n        f\"Scratchpad: {agent_scratchpad}\"\n    return records()\n\n\n@ppl\ndef agent_task_begin_for_claude(tool_names, inputs, agent_scratchpad):\n    \"Start the Execution\"\n    with LineSeparated():\n        f\"Now begin your task! Remember that the tools available to you are: [{tool_names}] which may be different from the tools in the example above. Here is the {UserInput} and previous {Scratchpad}:\"\n        \"\"\n        f\"User Input: {inputs}\"\n        f\"Scratchpad: {agent_scratchpad}\"\n        \"\"\n        f'Please output your {Thought} followed by your {Action}/{ActionInput} or {FinalAnswer} (when you have finished all your actions) for the **current** iteration following the provided previous {Scratchpad}. Start your response with your {Thought} for the current iteration directly following the \"Thought:\" prefix. Do not repeat the the previous iteration\\'s {Thought} in your response.'\n    return records()\n\n\n@ppl(comp=LineSeparated(indexing=\"##\"))\ndef agent_naive_prompt(\n    toolkit_descriptions, tool_names, inputs, agent_scratchpad, is_claude=False\n):\n    env_setup()\n    empty_line()\n    agent_task_desc(toolkit_descriptions)\n    empty_line()\n    agent_format_instruction()\n    empty_line()\n    if is_claude:\n        task_begin = agent_task_begin_for_claude\n    else:\n        task_begin = agent_task_begin\n    task_begin(tool_names, inputs, agent_scratchpad)\n    return records()\n\n\nif __name__ == \"__main__\":\n    system_prompt = AGENT_SYSTEM_INFO\n    example_prompt = str(\n        agent_naive_prompt(\n            toolkit_descriptions=\"{toolkit_descriptions}\",\n            tool_names=\"{tool_names}\",\n            inputs=\"{inputs}\",\n            agent_scratchpad=\"{agent_scratchpad}\",\n        )\n    )\n    print(\"===== System Message =====\")\n    print(system_prompt)\n    print(\"\")\n    print(\"===== Human Message =====\")\n    print(example_prompt)\n    print(\"\\n\\n&gt;&gt;&gt;&gt;Token lengths:\", get_num_tokens(example_prompt))\n</code></pre> <p>The output will be: <pre><code>===== System Message =====\nYou are a helpful AI Agent who can utilize a lot of external tools to answer User's questions or help User accomplish tasks following their instructions.\n\n===== Human Message =====\n## Environment Setup\n- User Information: The information of the [User] is provided below:\n    - Name: John Doe\n    - Email: john.doe@gmail.com\n- Current Time: 11:37 AM UTC-05:00, Tuesday, February 22, 2022\n\n## Task Description\nYour task is to utilize the provided tools to answer [User]'s questions or help [User] accomplish tasks based on given instructions. You are provided with the following information:\n\n- Tool Specifications: the specifications of the tools that you can utilize.\n- User Input: the instruction or question provided by the [User] that the you are trying to help with the provided tools.\n- Scratchpad: the tool-use trajectories that track your previous tool calls and tool execution outputs.\n\n### Tool Specifications\nEach toolkit is a collection of relevant tools for completing a specific task. Each tool is specified by:\n1. Arguments: The tool input argument specification\n2. Returns: The tool output return specification\n\nThe following tools are available:\n\n{toolkit_descriptions}\n\n### Scratchpad\nThe tool-use [Scratchpad] is formatted as follows and should be used to structure your response:\n\nThought: your reasoning for determining the next action based on the [User Input], previous [Action]s, and previous [Observation]s.\nAction: the tool that you choose to use, which must be a single valid tool name from [Tool Specifications].\nAction Input: the input to the tool, which should be a JSON object with necessary fields matching the tool's [Arguments] specifications, e.g., {\"arg1\": \"value1\", \"arg2\": \"value2\"}. The JSON object should be parsed by Python `json.loads`.\nObservation: the execution result of the tool, which should be a JSON object with fields matching the tool's [Returns] specifications, e.g., {\"return1\": \"value1\", \"return2\": \"value2\"}.\n\nThis [Thought]/[Action]/[Action Input]/[Observation] sequence may repeat multiple iterations. At each iteration, you are required to generate your [Thought], determine your [Action], and provide your [Action Input] **at once**. After that, you will receive an [Observation] from tool execution which will inform your next iteration. Continue this process for multiple rounds as needed.\n\nOnce you have finished all your actions and are able to synthesize a thoughtful response for the [User], ensure that you end your response by incorporating the final answer as follows:\n\nFinal Answer: your final response to the [User].\n\n## Format Instructions\n### Format Requirements\nHere are some requirements that you should strictly follow to format the [Action] and [Action Input]:\n1. **Use only available tools**: Do not use tools that are not provided above. In particular, do not use None or N/A as the [Action]. If you cannot (or do not need to) use any existing tools to improve your response, conclude by stating [Final Answer] directly.\n2. **Single JSON object**: Ensure the [Action Input] is a single JSON object that strictly follows the specification of the tool's [Arguments]. Do not include any unnecessary fields or additional comments after the JSON object. Do not include any backsticks to wrap the JSON object.\n    - Incorrect (with comments): {\"query\": \"the president of US\"} # query the president of US\n    - Correct (without comments) {\"query\": \"the president of US\"}\n3. **Avoid using placeholders**: Do not use vague input values with placeholders. Instead, first obtain the actual values for the placeholders (using other tools if necessary) and then use them in the input.\n    - Incorrect (with placeholders): {\"id\": &lt;id&gt;, \"account_number\": &lt;account_number&gt;}\n    - Incorrect (with placeholders and comments): {\"id\": &lt;id&gt;, \"account_number\": &lt;account_number&gt;}  Note: The user needs to fill in the &lt;id&gt; and &lt;account_number&gt;\n    - Correct (with actual sourced values): {\"id\": \"a4bjb5nw1m\",\"account_number\": \"9012-0678-236\"}\n\n### Format Examples\nHere is an example for how to format your response. In this example, a &lt;Gmail&gt; toolkit for managing Gmails (APIs contained: GmailSendEmail/GmailReadEmail/etc) is provided. Detailed tool specification is omitted here.\n\nUser input: Send an email to John Lee (johnlee@gmail.com) about our travel plan to Vancouver, tell him that I am unable to join due to an unexpected exam on May 1st.\nThought: The user wants to inform John Lee about their travel plan to Vancouver but is unable to join due to an exam on May 1st. They want to send an email to John Lee for this purpose.\nAction: GmailSendEmail\nAction Input: {\"subject\": \"Unable to join for Vancouver trip\", \"body\": \"Hi John,\n\nI hope this email finds you well. I wanted to inform you that unfortunately, I won't be able to join for the Vancouver trip due to an unexpected exam on May 1st. I apologize for any inconvenience this may cause.\n\nBest regards\", \"to\": \"johnlee@gmail.com\"}\nObservation: {\"status\": \"Success\"}\nThought: The email was successfully sent to John Lee. No further action is needed.\nFinal Answer: Your email to John Lee has been sent successfully!\n\n## Start the Execution\nNow begin your task! Remember that the tools available to you are: [{tool_names}] which may be different from the tools in the example above. Please output your **NEXT** [Action]/[Action Input] or [Final Answer] (when you have finished all your actions) following the provided [Scratchpad], directly start your response with your [Thought] for the current iteration.\n\nUser Input: {inputs}\nScratchpad: {agent_scratchpad}\n\n\n&gt;&gt;&gt;&gt;Token lengths: 1209\n</code></pre></p>"},{"location":"cookbook/multi_agent_chat/","title":"Multi-Agent Chat","text":"<p>We demonstrate four different ways of implementing a multi-agent chat system using APPL. The four implementations are:</p> <ol> <li>Resume (Recommended): Uses the resume feature of the APPL function to store the state of the conversation. The context is stored in the instance of the class with a private variable.</li> <li>History: Uses a variable to store the history of the conversation. The history is stored in the beginning and updated at the end of each turn.</li> <li>Generator: Utilizes Python's yield and generator capabilities, enabling functions to produce outputs in stages, temporarily hand over control, and later resume where they left off by calling the send method, which also allows for new inputs to be passed to the yield statement.</li> <li>Same Context: Creates a context in the init function and uses the same context throughout the conversation.</li> </ol>"},{"location":"cookbook/multi_agent_chat/#implementations","title":"Implementations","text":""},{"location":"cookbook/multi_agent_chat/#1-resume","title":"1. Resume","text":"<pre><code>from typing import Optional\n\nimport appl\nfrom appl import AIRole, PromptContext, SystemMessage, gen, ppl, records\n\nappl.init()\n\n\nclass Agent(object):\n    def __init__(self, name: Optional[str] = None):\n        self._name = name\n        self._setup()\n\n    @ppl\n    def _setup(self):\n        if self._name:\n            SystemMessage(f\"Your name is {self._name}.\")\n        self.chat(None)  # setup the context\n\n    @ppl(ctx=\"resume\")  # The context is resumed from the last call to chat\n    def chat(self, msg: Optional[str]):\n        if msg is None:  # first call to setup the context\n            return\n        msg  # add to the prompt\n        with AIRole():\n            (reply := gen(max_tokens=50))  # generate reply and add to the prompt\n        return reply\n\n\nalice = Agent(\"Alice\")\nbob = Agent(\"Bob\")\nmsg = \"Hello\"\nfor i in range(2):\n    msg = str(alice.chat(msg))\n    print(\"Alice:\", msg)\n    msg = str(bob.chat(msg))\n    print(\"Bob:\", msg)\n</code></pre>"},{"location":"cookbook/multi_agent_chat/#2-history","title":"2. History","text":"<pre><code>from typing import Optional\n\nimport appl\nfrom appl import AIRole, PromptContext, SystemMessage, gen, ppl, records\n\nappl.init()\n\n\nclass Agent(object):\n    def __init__(self, name: Optional[str] = None):\n        self._name = name\n        self._history = self._setup()  # initialize history\n\n    @ppl\n    def _setup(self):\n        if self._name:\n            SystemMessage(f\"Your name is {self._name}.\")\n        return records()\n\n    @ppl\n    def chat(self, msg):\n        self._history  # retrieve history\n        msg  # add to the prompt\n        with AIRole():\n            (reply := gen(max_tokens=50))  # generate reply and add to the prompt\n        self._history = records()  # update history\n        return reply\n\n\nalice = Agent(\"Alice\")\nbob = Agent(\"Bob\")\nmsg = \"Hello!\"\nfor i in range(2):\n    msg = str(alice.chat(msg))\n    print(\"Alice:\", msg)\n    msg = str(bob.chat(msg))\n    print(\"Bob:\", msg)\n</code></pre>"},{"location":"cookbook/multi_agent_chat/#3-generator","title":"3. Generator","text":"<pre><code>from typing import Optional\n\nimport appl\nfrom appl import AIRole, PromptContext, SystemMessage, gen, ppl, records\n\nappl.init()\n\n\nclass Agent(object):\n    def __init__(self, name: Optional[str] = None):\n        self._name = name\n        self.chat = self._chat_generator().send\n\n    @ppl\n    def _setup(self):\n        if self._name:\n            SystemMessage(f\"Your name is {self._name}.\")\n        return records()\n\n    @ppl(auto_prime=True)  # auto prime the generator\n    def _chat_generator(self):\n        self._setup()\n        reply = None\n        while True:\n            yield reply  # yield and receive messages\n            with AIRole():\n                (reply := gen(max_tokens=50))\n\n\nalice = Agent(\"Alice\")\nbob = Agent(\"Bob\")\nmsg = \"Hello!\"\nfor i in range(2):\n    msg = str(alice.chat(msg))\n    print(\"Alice:\", msg)\n    msg = str(bob.chat(msg))\n    print(\"Bob:\", msg)\n</code></pre>"},{"location":"cookbook/multi_agent_chat/#4-same-context","title":"4. Same Context","text":"<pre><code>from abc import ABC, abstractmethod\nfrom typing import Optional\n\nimport appl\nfrom appl import AIRole, PromptContext, SystemMessage, gen, ppl, records\nfrom appl.func import wraps\n\nappl.init()\n\n\nclass AgentBase(ABC):\n    def __init__(self):\n        self._ctx = PromptContext()  # the context for the agent\n        self._setup(_ctx=self._ctx)  # manually provide the shared context\n\n    @abstractmethod\n    @ppl(ctx=\"same\")\n    def _setup(self):\n        raise NotImplementedError\n\n    @abstractmethod\n    @ppl(ctx=\"same\")\n    def _chat(self, msg: str):\n        raise NotImplementedError\n\n    @wraps(_chat)\n    def chat(self, *args, **kwargs):\n        # manually provide the shared context self._ctx stored in the instance\n        return self._chat(*args, _ctx=self._ctx, **kwargs)\n\n    setattr(chat, \"__isabstractmethod__\", False)\n    # set to False since _chat is abstractmethod\n\n\nclass Agent(AgentBase):\n    def __init__(self, name: Optional[str] = None):\n        self._name = name\n        super().__init__()\n\n    @ppl(ctx=\"same\")\n    def _setup(self):\n        # modify the shared context\n        if self._name:\n            SystemMessage(f\"Your name is {self._name}.\")\n\n    @ppl(ctx=\"same\")\n    def _chat(self, msg: str):\n        msg\n        with AIRole():\n            (reply := gen(max_tokens=50))\n        return reply\n\n\nalice = Agent(\"Alice\")\nbob = Agent(\"Bob\")\nmsg = \"Hello!\"\nfor i in range(2):\n    msg = str(alice.chat(msg))\n    print(\"Alice:\", msg)\n    msg = str(bob.chat(msg))\n    print(\"Bob:\", msg)\n</code></pre>"},{"location":"cookbook/multi_agent_chat/#example-conversation","title":"Example Conversation","text":"<p>The example conversation between agents:</p> Role Message Alice Hello! How can I assist you today? Bob Hi there! I'm just here to chat and answer any questions you might have. How's your day going? Alice Thank you for asking! My day is going well. How about you? Bob I'm just a virtual assistant, so I don't have feelings, but I'm here to help you with anything you need. Is there anything specific you'd like to talk about or ask me? <p>The conversation seen by Alice:</p> Role Message System Your name is Alice. User Hello! Assistant Hello! How can I assist you today? User Hi there! I'm just here to chat and answer any questions you might have. How's your day going? Assistant Thank you for asking! My day is going well. How about you? <p>The conversation seen by Bob:</p> Role Message System Your name is Bob. User Hello! How can I assist you today? Assistant Hi there! I'm just here to chat and answer any questions you might have. How's your day going? User Thank you for asking! My day is going well. How about you? Assistant I'm just a virtual assistant, so I don't have feelings, but I'm here to help you with anything you need. Is there anything specific you'd like to talk about or ask me?"},{"location":"cookbook/react/","title":"ReAct Agent for Hanoi Tower","text":"<p>This example demonstrates how to use the ReAct agent to act in the Hanoi Tower environment.</p> <pre><code>import textwrap\n\nimport numpy as np\n\nimport appl\nfrom appl import (\n    AIMessage,\n    AIRole,\n    Generation,\n    as_tool,\n    as_tool_choice,\n    gen,\n    ppl,\n    records,\n)\n\nappl.init()\n\n\n# TowerOfHanoi mostly written by GPT4\nclass TowerOfHanoi:\n    \"\"\"\n    This class provides a simple implementation of the Tower of Hanoi game, allowing the\n    configuration of the number of disks and tracking the state of the game through moves.\n\n    The Tower of Hanoi is a mathematical puzzle where the objective is to move a stack\n    of disks from one peg to another, with the help of one auxiliary peg, adhering to the\n    following rules:\n    1. Only one disk can be moved at a time.\n    2. Each move consists of taking the upper disk from one of the stacks and placing it on\n       top of another stack or on an empty peg.\n    3. No disk may be placed on top of a smaller disk.\n\n    Attributes:\n        num_disks (int): The number of disks in the game.\n        pegs (list[list[int]]): The state of the pegs and disks.\n    \"\"\"\n\n    def __init__(self, num_disks: int):\n        \"\"\"\n        Initializes the Tower of Hanoi game with the given number of disks.\n\n        Args:\n            num_disks (int): The number of disks to use in the game.\n        \"\"\"\n        self.num_disks = num_disks\n        self.reset()\n\n    def reset(self) -&gt; None:\n        # Initialize the pegs; start with all disks on peg 1\n        self.pegs: list[list[int]] = [list(range(self.num_disks, 0, -1)), [], []]\n\n    def move_disk(self, from_peg: int, to_peg: int) -&gt; bool:\n        \"\"\"\n        Moves the top disk from one peg to another if the move is valid.\n\n        Args:\n            from_peg (int): The peg number (0, 1, 2) to move the disk from.\n            to_peg (int): The peg number (0, 1, 2) to move the disk to.\n\n        Returns:\n            bool: True if the move was successful, False otherwise.\n        \"\"\"\n        # Check if move is valid\n        if (\n            from_peg == to_peg\n            or from_peg &lt; 0\n            or from_peg &gt; 2\n            or to_peg &lt; 0\n            or to_peg &gt; 2\n            or not self.pegs[from_peg]\n            or (self.pegs[to_peg] and self.pegs[from_peg][-1] &gt; self.pegs[to_peg][-1])\n        ):\n            return False\n\n        # Move the disk\n        self.pegs[to_peg].append(self.pegs[from_peg].pop())\n        return True\n\n    def is_solved(self) -&gt; bool:\n        \"\"\"\n        Checks if the game is solved, i.e., all disks are moved to the third peg.\n\n        Returns:\n            bool: True if the game is solved, False otherwise.\n        \"\"\"\n        return len(self.pegs[2]) == self.num_disks\n\n    def render(self) -&gt; str:\n        \"\"\"\n        Render the current state of the pegs and disks.\n        \"\"\"\n        s = \"\"\n        for i, peg in enumerate(self.pegs):\n            s += f\"Peg {i}: \" + \" \".join(str(disk) for disk in peg) + \"\\n\"\n        return s\n\n\ndef move_disk(env: TowerOfHanoi, from_peg: int, to_peg: int) -&gt; str:\n    # wrap the move_disk method to be used as a tool\n    \"\"\"Moves the top disk from one peg to another if the move is valid.\n\n    Args:\n        from_peg (int): The peg number (0, 1, 2) to move the disk from.\n        to_peg (int): The peg number (0, 1, 2) to move the disk to.\n\n    Returns:\n        str:\n            The current state of the pegs and disks if the move was\n            successful, \"Invalid move\" otherwise.\n    \"\"\"\n    if env.move_disk(from_peg, to_peg):\n        return env.render()\n    return \"Invalid move\"\n\n\n@ppl\ndef react(env: TowerOfHanoi, max_steps: int = 10):\n    tools = [as_tool(move_disk, env=env)]\n    desc = (TowerOfHanoi.__doc__ or \"\\n\\n\").split(\"\\n\\n\")[1]\n    (desc := textwrap.dedent(desc))  # add desc to prompt\n\n    \"Before taking actions in each step, you should briefly write thoughts for the next step.\"\n    \"The initial state of the pegs and disks is:\\n\"\n    env.render()  # render, add to prompt\n    steps = 0\n    while steps &lt; max_steps:\n        with AIRole():\n            f\"Thoughts: {gen(tools=tools, tool_choice='none')}\"\n        (actions := gen(tools=tools, tool_choice=as_tool_choice(move_disk)))\n        if actions.is_tool_call:\n            (results := actions.run_tool_calls())  # results is a list of ToolMessage\n            for i in range(len(results)):\n                steps += 1\n                print(f\"step {steps}: {results[i].get_content()}\")\n        else:\n            assert False, \"Tool call expected.\"\n        if env.is_solved():\n            print(f\"Solved in {steps} steps!\")\n            break\n\n\nif __name__ == \"__main__\":\n    env = TowerOfHanoi(2)\n    env.reset()\n    react(env)\n</code></pre>"},{"location":"dev/","title":"Development","text":"<p>We use pdm to manage the dependencies and MkDocs to build the documentation.</p>"},{"location":"dev/#pre-commit","title":"Pre Commit","text":"<p>It is recommended to use pre-commit to ensure that the code is formatted and linted before committing.</p>"},{"location":"dev/#steps","title":"Steps","text":"<ul> <li>Install pre-commit     <pre><code>pip install pre-commit\n</code></pre></li> <li>Install the git hooks     <pre><code>pre-commit install\n</code></pre></li> <li>Run the pre-commit checks (should automatically run when you try to commit, you can also run it manually)     <pre><code>pre-commit run\n</code></pre></li> </ul>"},{"location":"dev/#coverage","title":"Coverage","text":"<p>To generate coverage report, run the following command:</p> <pre><code>coverage run -m pytest\ncoverage html\n</code></pre>"},{"location":"dev/docs/","title":"Documentation","text":"<p>The documentation is written in Markdown and built using MkDocs.</p>"},{"location":"dev/docs/#local-development","title":"Local Development","text":"<p>To serve the documentation locally, run the following commands:</p> <pre><code>pdm install -G docs\nmkdocs serve\n</code></pre> <p>Open http://localhost:8000/ in your browser to view the documentation.</p>"},{"location":"dev/manage/","title":"Project Management","text":""},{"location":"dev/manage/#package-and-dependency-management","title":"Package and Dependency Management","text":"<p>We use pdm to manage the package and the dependencies.</p>"},{"location":"dev/manage/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>We use pre-commit to enforce code quality and consistency. The pre-commit hooks are defined in the <code>.pre-commit-config.yaml</code> file.</p> <p>The following pre-commit hooks are enabled in this project.</p>"},{"location":"dev/manage/#code-linting-and-formatting","title":"Code Linting and Formatting","text":"<p>We use Ruff for code linting and formatting. The format is based on Black.</p> <p>The docstrings in the source code are written in the Google Style Python Docstrings format. <code>pydocstyle</code> rules for checking the docstrings are included in <code>ruff</code>.</p> <pre><code>ruff check src\nruff format src\n</code></pre>"},{"location":"dev/manage/#code-type-checking","title":"Code Type Checking","text":"<p>We use mypy for static type checking. </p> <pre><code>mypy src\n</code></pre>"},{"location":"reference/","title":"Index","text":""},{"location":"reference/#appl","title":"appl","text":"<p>appl - A Prompt Programming Language.</p>"},{"location":"reference/#appl.init","title":"init","text":"<pre><code>init(\n    resume_cache: Optional[str] = None,\n    update_config_hook: Optional[Callable] = None,\n) -&gt; None\n</code></pre> <p>Initialize APPL with dotenv and config files.</p> <p>Parameters:</p> <ul> <li> <code>resume_cache</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>Path to the trace file used as resume cache. Defaults to None.</p> </li> <li> <code>update_config_hook</code>             (<code>Optional[Callable]</code>, default:                 <code>None</code> )         \u2013          <p>A hook to update the configs. Defaults to None.</p> </li> </ul> Source code in <code>src\\appl\\__init__.py</code> <pre><code>def init(\n    resume_cache: Optional[str] = None,\n    update_config_hook: Optional[Callable] = None,\n) -&gt; None:\n    \"\"\"Initialize APPL with dotenv and config files.\n\n    Args:\n        resume_cache: Path to the trace file used as resume cache. Defaults to None.\n        update_config_hook: A hook to update the configs. Defaults to None.\n    \"\"\"\n    with global_vars.lock:\n        # only initialize once\n        if global_vars.initialized:\n            logger.warning(\"APPL has already been initialized, ignore\")\n            return\n        global_vars.initialized = True\n\n    now = pendulum.instance(datetime.datetime.now())\n    # Get the previous frame in the stack, i.e., the one calling this function\n    frame = inspect.currentframe()\n    if frame and frame.f_back:\n        caller_path = frame.f_back.f_code.co_filename  # Get file_path of the caller\n        caller_basename = os.path.basename(caller_path).split(\".\")[0]\n        caller_folder = os.path.dirname(caller_path)  # Get folder of the caller\n        caller_folder = get_folder(caller_folder)\n        dotenvs = find_files(caller_folder, [\".env\"])\n        appl_config_files = find_files(\n            caller_folder, [\"appl.yaml\", \"appl.yml\", \"appl.json\", \"appl.toml\"]\n        )\n        # load dotenvs and appl configs from outer to inner with override\n        for dotenv in dotenvs[::-1]:\n            load_dotenv(dotenv, override=True)\n            logger.info(\"Loaded dotenv from {}\".format(dotenv))\n        for config_file in appl_config_files[::-1]:\n            override_configs = load_config(config_file)\n            logger.info(\"Loaded configs from {}\".format(config_file))\n            configs.update(override_configs)\n            if configs.getattrs(\"settings.logging.display.configs_update\"):\n                logger.info(f\"update configs:\\n{yaml.dump(override_configs.to_dict())}\")\n    else:\n        caller_basename, dotenvs, appl_config_files = \"appl\", [], []\n        logger.error(\n            \"Cannot find the caller of appl.init(), fail to load .env and appl configs\"\n        )\n\n    if update_config_hook:\n        update_config_hook(configs)\n    log_format = configs.getattrs(\"settings.logging.format\")\n    log_level = configs.getattrs(\"settings.logging.log_level\")\n    log_file = configs.getattrs(\"settings.logging.log_file\")\n    # set logger level for loguru\n    logger.remove()  # Remove default handler\n    logger.add(sys.stderr, level=log_level, format=_get_loguru_format())\n    if log_file.get(\"enabled\", False):\n        if (log_file_format := log_file.get(\"path_format\", None)) is not None:\n            log_file_path = (\n                f\"{log_file_format.format(basename=caller_basename, time=now)}.log\"\n            )\n            log_file.path = log_file_path\n            file_log_level = log_file.get(\"log_level\", None) or log_level\n            logger.info(f\"Logging to file: {log_file_path} with level {file_log_level}\")\n            # no need to overwrite the default format when writing to file\n            logger.add(log_file_path, level=file_log_level, format=log_format)\n\n    configs[\"info\"] = Configs(\n        {\n            \"start_time\": now.format(\"YYYY-MM-DD HH:mm:ss\"),\n            \"dotenvs\": dotenvs,\n            \"appl_configs\": appl_config_files,\n        }\n    )\n    if configs.getattrs(\"settings.logging.display.configs\"):\n        logger.info(f\"Using configs:\\n{yaml.dump(configs.to_dict())}\")\n\n    tracing = configs.getattrs(\"settings.tracing\")\n    strict_match = tracing.get(\"strict_match\", True)\n    if tracing.get(\"enabled\", False):\n        if (trace_file_format := tracing.get(\"path_format\", None)) is not None:\n            prefix = trace_file_format.format(basename=caller_basename, time=now)\n            trace_file_path = f\"{prefix}.pkl\"\n            meta_file = f\"{prefix}_meta.json\"\n            tracing.trace_file = trace_file_path\n            logger.info(f\"Tracing file: {trace_file_path}\")\n            dump_file(configs.to_dict(), meta_file)\n            global_vars.trace_engine = TraceEngine(\n                trace_file_path, mode=\"write\", strict=strict_match\n            )\n        else:\n            logger.warning(\"Tracing is enabled but no trace file is specified\")\n\n    resume_cache = resume_cache or os.environ.get(\"APPL_RESUME_TRACE\", None)\n    if resume_cache:\n        global_vars.resume_cache = resume_cache\n        logger.info(f\"Using resume cache: {resume_cache}\")\n        global_vars.resume_cache = TraceEngine(\n            resume_cache, mode=\"read\", strict=strict_match\n        )\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li> appl<ul> <li> compositor</li> <li> const</li> <li> core<ul> <li> compile</li> <li> config</li> <li> context</li> <li> function</li> <li> generation</li> <li> globals</li> <li> io</li> <li> message</li> <li> modifiers</li> <li> printer</li> <li> promptable<ul> <li> base</li> <li> definition</li> <li> formatter</li> </ul> </li> <li> response</li> <li> runtime</li> <li> server</li> <li> tool</li> <li> trace</li> <li> types<ul> <li> basic</li> <li> content</li> <li> custom</li> <li> deps</li> <li> futures</li> <li> role</li> </ul> </li> </ul> </li> <li> func</li> <li> role_changer</li> <li> servers<ul> <li> api</li> <li> manager</li> </ul> </li> <li> tracing<ul> <li> engine</li> <li> printer</li> </ul> </li> <li> types</li> <li> utils</li> </ul> </li> </ul>"},{"location":"reference/compositor/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> compositor","text":""},{"location":"reference/compositor/#appl.compositor","title":"compositor","text":"<p>Containg the compositor classes.</p> <p>All examples shows the composed prompt in APPL functions.</p>"},{"location":"reference/compositor/#appl.compositor.LetterList","title":"LetterList  <code>module-attribute</code>","text":"<pre><code>LetterList = UpperLetterList\n</code></pre> <p>The alias of UpperLetterList.</p>"},{"location":"reference/compositor/#appl.compositor.RomanList","title":"RomanList  <code>module-attribute</code>","text":"<pre><code>RomanList = UpperRomanList\n</code></pre> <p>The alias of UpperRomanList.</p>"},{"location":"reference/compositor/#appl.compositor.DashList","title":"DashList","text":"<pre><code>DashList(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The dash list compositor.</p> <p>Attributes:</p> <ul> <li> <code>_indexing</code>         \u2013          <p>The class default indexing mode is \"dash\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with DashList():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\n- item1\n- item2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.DoubleLineSeparated","title":"DoubleLineSeparated","text":"<pre><code>DoubleLineSeparated(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>Compositor</code></p> <p>The double line separated compositor.</p> <p>Attributes:</p> <ul> <li> <code>_sep</code>         \u2013          <p>The class default separator is \"\\n\\n\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with DoubleLineSeparated():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\nitem1\n\nitem2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.IndentedList","title":"IndentedList","text":"<pre><code>IndentedList(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The indented list compositor.</p> <p>Attributes:</p> <ul> <li> <code>_inc_indent</code>         \u2013          <p>The class default indentation is INDENT.</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; \"BEGIN\"\n... with IndentedList():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\nBEGIN\n    item1\n    item2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.InlineTagged","title":"InlineTagged","text":"<pre><code>InlineTagged(\n    tag: str,\n    *args: Any,\n    attrs: Optional[Dict[str, str]] = None,\n    tag_begin: str = \"&lt;{}{}&gt;\",\n    tag_end: str = \"&lt;/{}&gt;\",\n    indent_inside: Union[str, int, None] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>Tagged</code></p> <p>The inline tagged compositor, which is used to wrap the content with a tag.</p> <p>Attributes:</p> <ul> <li> <code>_sep</code>         \u2013          <p>The class default separator is \"\".</p> </li> <li> <code>_indexing</code>         \u2013          <p>The class default indexing mode is no indexing.</p> </li> <li> <code>_new_indent</code>         \u2013          <p>The class default indentation is \"\".</p> </li> <li> <code>_is_inline</code>         \u2013          <p>The class default is True.</p> </li> <li> <code>_indent_inside</code>             (<code>Optional[str]</code>)         \u2013          <p>This class does not support indentation inside.</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with InlineTagged(\"div\", sep=\",\"):\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\n&lt;div&gt;item1,item2&lt;/div&gt;\n</code></pre> <p>Parameters:</p> <ul> <li> <code>tag</code>             (<code>str</code>)         \u2013          <p>The tag name.</p> </li> <li> <code>*args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>The arguments.</p> </li> <li> <code>attrs</code>             (<code>Optional[Dict[str, str]]</code>, default:                 <code>None</code> )         \u2013          <p>The attributes of the tag.</p> </li> <li> <code>tag_begin</code>             (<code>str</code>, default:                 <code>'&lt;{}{}&gt;'</code> )         \u2013          <p>The format of tag begin string.</p> </li> <li> <code>tag_end</code>             (<code>str</code>, default:                 <code>'&lt;/{}&gt;'</code> )         \u2013          <p>The format of tag end string.</p> </li> <li> <code>indent_inside</code>             (<code>Union[str, int, None]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation inside the tag.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>The keyword arguments.</p> </li> </ul> Source code in <code>src\\appl\\compositor.py</code> <pre><code>def __init__(\n    self,\n    tag: str,\n    *args: Any,\n    attrs: Optional[Dict[str, str]] = None,\n    tag_begin: str = \"&lt;{}{}&gt;\",\n    tag_end: str = \"&lt;/{}&gt;\",\n    indent_inside: Union[str, int, None] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the tagged compositor.\n\n    Args:\n        tag: The tag name.\n        *args: The arguments.\n        attrs: The attributes of the tag.\n        tag_begin: The format of tag begin string.\n        tag_end: The format of tag end string.\n        indent_inside: The indentation inside the tag.\n        **kwargs: The keyword arguments.\n    \"\"\"\n    self._tag = tag\n    self._attrs = attrs\n    self._tag_begin = tag_begin\n    self._tag_end = tag_end\n    prolog = tag_begin.format(tag, self.formated_attrs)\n    epilog = tag_end.format(tag)\n    super().__init__(\n        *args, prolog=prolog, epilog=epilog, indent_inside=indent_inside, **kwargs\n    )\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.InlineTagged.epilog","title":"epilog  <code>property</code>","text":"<pre><code>epilog: str\n</code></pre> <p>The epilog string.</p>"},{"location":"reference/compositor/#appl.compositor.InlineTagged.formated_attrs","title":"formated_attrs  <code>property</code>","text":"<pre><code>formated_attrs: str\n</code></pre> <p>The formatted attributes of the tag.</p>"},{"location":"reference/compositor/#appl.compositor.InlineTagged.prolog","title":"prolog  <code>property</code>","text":"<pre><code>prolog: str\n</code></pre> <p>The prolog string.</p>"},{"location":"reference/compositor/#appl.compositor.LineSeparated","title":"LineSeparated","text":"<pre><code>LineSeparated(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>Compositor</code></p> <p>The line separated compositor.</p> <p>Attributes:</p> <ul> <li> <code>_sep</code>         \u2013          <p>The class default separator is \"\\n\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with LineSeparated():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\nitem1\nitem2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.Logged","title":"Logged","text":"<pre><code>Logged(\n    *args: Any,\n    prolog: str,\n    epilog: str,\n    indent_inside: Union[str, int, None] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The logged compositor, which is used to wrap the content with logs.</p> <p>Note the indent will also apply to the prolog and epilog.</p> <p>Attributes:</p> <ul> <li> <code>_indent_inside</code>             (<code>Optional[str]</code>)         \u2013          <p>The class default indentation inside prolog and epilog is \"\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with Logged(prolog=\"BEGIN\", epilog=\"END\"):\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\nBEGIN\nitem1\nitem2\nEND\n</code></pre> <p>Parameters:</p> <ul> <li> <code>*args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>The arguments.</p> </li> <li> <code>prolog</code>             (<code>str</code>)         \u2013          <p>The prolog string.</p> </li> <li> <code>epilog</code>             (<code>str</code>)         \u2013          <p>The epilog string.</p> </li> <li> <code>indent_inside</code>             (<code>Union[str, int, None]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation inside the prolog and epilog.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>The keyword arguments.</p> </li> </ul> Source code in <code>src\\appl\\compositor.py</code> <pre><code>def __init__(\n    self,\n    *args: Any,\n    prolog: str,\n    epilog: str,\n    indent_inside: Union[str, int, None] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the logged compositor.\n\n    Args:\n        *args: The arguments.\n        prolog: The prolog string.\n        epilog: The epilog string.\n        indent_inside: The indentation inside the prolog and epilog.\n        **kwargs: The keyword arguments.\n    \"\"\"\n    self._prolog = prolog\n    self._epilog = epilog\n    if isinstance(indent_inside, int):\n        indent_inside = \" \" * indent_inside\n    if indent_inside is not None:\n        if self._indent_inside is None:\n            raise ValueError(\n                \"Indentation inside is not allowed for this compositor.\"\n            )\n        self._indent_inside = indent_inside\n    outer_indent = kwargs.pop(\"indent\", None)\n    super().__init__(indent=outer_indent, _ctx=kwargs.get(\"_ctx\"))\n    kwargs = self._get_kwargs_for_inner(kwargs)\n    # The arguments are passed to the inner compositor\n    self._indent_compositor = LineSeparated(*args, **kwargs)\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.Logged.epilog","title":"epilog  <code>property</code>","text":"<pre><code>epilog: str\n</code></pre> <p>The epilog string.</p>"},{"location":"reference/compositor/#appl.compositor.Logged.prolog","title":"prolog  <code>property</code>","text":"<pre><code>prolog: str\n</code></pre> <p>The prolog string.</p>"},{"location":"reference/compositor/#appl.compositor.LowerLetterList","title":"LowerLetterList","text":"<pre><code>LowerLetterList(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The lower letter list compositor.</p> <p>Attributes:</p> <ul> <li> <code>_indexing</code>         \u2013          <p>The class default indexing mode is \"lower\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with LowerLetterList():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\na. item1\nb. item2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.LowerRomanList","title":"LowerRomanList","text":"<pre><code>LowerRomanList(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The lower roman list compositor.</p> <p>Attributes:</p> <ul> <li> <code>_indexing</code>         \u2013          <p>The class default indexing mode is \"roman\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with LowerRomanList():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\ni. item1\nii. item2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.NoIndent","title":"NoIndent","text":"<pre><code>NoIndent(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The list compositor with no indentation.</p> <p>Attributes:</p> <ul> <li> <code>_inc_indent</code>         \u2013          <p>The class default indentation is \"\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with IndentedList():\n...     with NoIndent():\n...         \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\nitem1\n    item2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.NumberedList","title":"NumberedList","text":"<pre><code>NumberedList(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The number list compositor.</p> <p>Attributes:</p> <ul> <li> <code>_indexing</code>         \u2013          <p>The class default indexing mode is \"number\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with NumberedList():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\n1. item1\n2. item2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.StarList","title":"StarList","text":"<pre><code>StarList(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The star list compositor.</p> <p>Attributes:</p> <ul> <li> <code>_indexing</code>         \u2013          <p>The class default indexing mode is \"star\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with StarList():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\n* item1\n* item2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.Tagged","title":"Tagged","text":"<pre><code>Tagged(\n    tag: str,\n    *args: Any,\n    attrs: Optional[Dict[str, str]] = None,\n    tag_begin: str = \"&lt;{}{}&gt;\",\n    tag_end: str = \"&lt;/{}&gt;\",\n    indent_inside: Union[str, int, None] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>Logged</code></p> <p>The tagged compositor, which is used to wrap the content with a tag.</p> <p>Note the indent will also applyt to the tag indicator.</p> <p>Attributes:</p> <ul> <li> <code>_indent_inside</code>             (<code>Optional[str]</code>)         \u2013          <p>The class default indentation inside prolog and epilog is 4 spaces.</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with Tagged(\"div\"):\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\n&lt;div&gt;\n    item1\n    item2\n&lt;/div&gt;\n</code></pre> <p>Parameters:</p> <ul> <li> <code>tag</code>             (<code>str</code>)         \u2013          <p>The tag name.</p> </li> <li> <code>*args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>The arguments.</p> </li> <li> <code>attrs</code>             (<code>Optional[Dict[str, str]]</code>, default:                 <code>None</code> )         \u2013          <p>The attributes of the tag.</p> </li> <li> <code>tag_begin</code>             (<code>str</code>, default:                 <code>'&lt;{}{}&gt;'</code> )         \u2013          <p>The format of tag begin string.</p> </li> <li> <code>tag_end</code>             (<code>str</code>, default:                 <code>'&lt;/{}&gt;'</code> )         \u2013          <p>The format of tag end string.</p> </li> <li> <code>indent_inside</code>             (<code>Union[str, int, None]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation inside the tag.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>The keyword arguments.</p> </li> </ul> Source code in <code>src\\appl\\compositor.py</code> <pre><code>def __init__(\n    self,\n    tag: str,\n    *args: Any,\n    attrs: Optional[Dict[str, str]] = None,\n    tag_begin: str = \"&lt;{}{}&gt;\",\n    tag_end: str = \"&lt;/{}&gt;\",\n    indent_inside: Union[str, int, None] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the tagged compositor.\n\n    Args:\n        tag: The tag name.\n        *args: The arguments.\n        attrs: The attributes of the tag.\n        tag_begin: The format of tag begin string.\n        tag_end: The format of tag end string.\n        indent_inside: The indentation inside the tag.\n        **kwargs: The keyword arguments.\n    \"\"\"\n    self._tag = tag\n    self._attrs = attrs\n    self._tag_begin = tag_begin\n    self._tag_end = tag_end\n    prolog = tag_begin.format(tag, self.formated_attrs)\n    epilog = tag_end.format(tag)\n    super().__init__(\n        *args, prolog=prolog, epilog=epilog, indent_inside=indent_inside, **kwargs\n    )\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.Tagged.epilog","title":"epilog  <code>property</code>","text":"<pre><code>epilog: str\n</code></pre> <p>The epilog string.</p>"},{"location":"reference/compositor/#appl.compositor.Tagged.formated_attrs","title":"formated_attrs  <code>property</code>","text":"<pre><code>formated_attrs: str\n</code></pre> <p>The formatted attributes of the tag.</p>"},{"location":"reference/compositor/#appl.compositor.Tagged.prolog","title":"prolog  <code>property</code>","text":"<pre><code>prolog: str\n</code></pre> <p>The prolog string.</p>"},{"location":"reference/compositor/#appl.compositor.UpperLetterList","title":"UpperLetterList","text":"<pre><code>UpperLetterList(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The upper letter list compositor.</p> <p>Attributes:</p> <ul> <li> <code>_indexing</code>         \u2013          <p>The class default indexing mode is \"upper\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with UpperLetterList():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\nA. item1\nB. item2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.UpperRomanList","title":"UpperRomanList","text":"<pre><code>UpperRomanList(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>LineSeparated</code></p> <p>The upper roman list compositor.</p> <p>Attributes:</p> <ul> <li> <code>_indexing</code>         \u2013          <p>The class default indexing mode is \"Roman\".</p> </li> </ul> Example <pre><code>&gt;&gt;&gt; with UpperRomanList():\n...     \"item1\"\n...     \"item2\"\n&lt;&lt;&lt; The prompt will be:\nI. item1\nII. item2\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/compositor/#appl.compositor.iter","title":"iter","text":"<pre><code>iter(\n    lst: Iterable,\n    comp: Optional[Compositor] = None,\n    _ctx: Optional[PromptContext] = None,\n) -&gt; Iterable\n</code></pre> <p>Iterate over the iterable list with the compositor.</p> Example <pre><code>&gt;&gt;&gt; items = [\"item1\", \"item2\"]\n&gt;&gt;&gt; for i in iter(items, NumberedList()):\n...     i\n&lt;&lt;&lt; The prompt will be:\n1. item1\n2. item2\n</code></pre> Source code in <code>src\\appl\\compositor.py</code> <pre><code>@need_ctx\ndef iter(\n    lst: Iterable,\n    comp: Optional[Compositor] = None,\n    _ctx: Optional[PromptContext] = None,\n) -&gt; Iterable:\n    \"\"\"Iterate over the iterable list with the compositor.\n\n    Example:\n        ```py\n        &gt;&gt;&gt; items = [\"item1\", \"item2\"]\n        &gt;&gt;&gt; for i in iter(items, NumberedList()):\n        ...     i\n        &lt;&lt;&lt; The prompt will be:\n        1. item1\n        2. item2\n        ```\n    \"\"\"\n    # support tqdm-like context manager\n    if comp is None:\n        comp = NumberedList(_ctx=_ctx)\n\n    entered = False\n    try:\n        for i in lst:\n            if not entered:\n                entered = True\n                comp.__enter__()\n            yield i\n    except Exception as e:\n        # TODO: check the impl here\n        if entered:\n            if not comp.__exit__(type(e), e, e.__traceback__):\n                raise e\n        else:\n            raise e\n    finally:\n        if entered:\n            comp.__exit__(None, None, None)\n</code></pre>"},{"location":"reference/const/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> const","text":""},{"location":"reference/const/#appl.const","title":"const","text":""},{"location":"reference/const/#appl.const.EMPTY","title":"EMPTY  <code>module-attribute</code>","text":"<pre><code>EMPTY = ''\n</code></pre> <p>The empty string.</p>"},{"location":"reference/const/#appl.const.INDENT","title":"INDENT  <code>module-attribute</code>","text":"<pre><code>INDENT = INDENT4\n</code></pre> <p>The default indentation: 4 spaces.</p>"},{"location":"reference/const/#appl.const.NEWLINE","title":"NEWLINE  <code>module-attribute</code>","text":"<pre><code>NEWLINE = '\\n'\n</code></pre> <p>The newline character.</p>"},{"location":"reference/func/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> func","text":""},{"location":"reference/func/#appl.func","title":"func","text":""},{"location":"reference/func/#appl.func.as_func","title":"as_func","text":"<pre><code>as_func(\n    func: Callable[P, T],\n    _globals: Optional[Dict] = None,\n    _locals: Optional[Dict] = None,\n) -&gt; Callable[P, T]\n</code></pre> <p>Fill the globals and locals for a ppl function.</p> <p>When locals not provided, it will use the locals from the caller.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def as_func(\n    func: Callable[P, T],\n    _globals: Optional[Dict] = None,\n    _locals: Optional[Dict] = None,\n) -&gt; Callable[P, T]:\n    \"\"\"Fill the globals and locals for a ppl function.\n\n    When locals not provided, it will use the locals from the caller.\n    \"\"\"\n    frame = inspect.currentframe()\n    if _locals is None and frame is not None and frame.f_back is not None:\n        _locals = frame.f_back.f_locals\n    return partial(func, _globals=_globals, _locals=_locals)\n</code></pre>"},{"location":"reference/func/#appl.func.as_tool","title":"as_tool","text":"<pre><code>as_tool(func: Callable, **kwargs: Any) -&gt; Tool\n</code></pre> <p>Wrap a given function with additional predefined arguments into a Tool.</p> <p>This function allows converting a standard function into a 'Tool' by specifying the function and any additional arguments that should be pre-defined for it. These additional arguments are passed as keyword arguments and will be bound to the function within the Tool object, so that these arguments are not required when using this tool.</p> <p>Parameters:</p> <ul> <li> <code>func</code>             (<code>Callable</code>)         \u2013          <p>The function to be converted into a Tool.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments that will be predefined for the function in the Tool object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tool</code> (            <code>Tool</code> )        \u2013          <p>An object encapsulating the given function and its predefined arguments, ready to be utilized as a Tool.</p> </li> </ul> <p>Examples:</p> <p>Given a function <code>move_disk</code> that requires an environment and two pegs to move a disk from one peg to another in the Tower of Hanoi puzzle, one can create a tool with a predefined environment by:</p> <pre><code>def move_disk(env: HanoiEnv, from_peg: int, to_peg: int) -&gt; str:\n    pass\n\nenv = HanoiEnv()\ntools = [as_tool(move_disk, env=env)]\n</code></pre> <p>In this example, <code>move_disk</code> is encapsulated into a Tool with <code>env</code> predefined, so only <code>from_peg</code> and <code>to_peg</code> are required.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def as_tool(func: Callable, **kwargs: Any) -&gt; Tool:\n    \"\"\"Wrap a given function with additional predefined arguments into a Tool.\n\n    This function allows converting a standard function into a 'Tool' by\n    specifying the function and any additional arguments that should be\n    pre-defined for it. These additional arguments are passed as keyword\n    arguments and will be bound to the function within the Tool object,\n    so that these arguments are not required when using this tool.\n\n    Args:\n        func (Callable):\n            The function to be converted into a Tool.\n        **kwargs:\n            Keyword arguments that will be predefined for the function in\n            the Tool object.\n\n    Returns:\n        Tool:\n            An object encapsulating the given function and its predefined\n            arguments, ready to be utilized as a Tool.\n\n    Examples:\n        Given a function `move_disk` that requires an environment and two\n        pegs to move a disk from one peg to another in the Tower of Hanoi\n        puzzle, one can create a tool with a predefined environment by:\n\n        ```python\n        def move_disk(env: HanoiEnv, from_peg: int, to_peg: int) -&gt; str:\n            pass\n\n        env = HanoiEnv()\n        tools = [as_tool(move_disk, env=env)]\n        ```\n\n        In this example, `move_disk` is encapsulated into a Tool with `env`\n        predefined, so only `from_peg` and `to_peg` are required.\n    \"\"\"\n    return Tool(func=func, **kwargs)\n</code></pre>"},{"location":"reference/func/#appl.func.as_tool_choice","title":"as_tool_choice","text":"<pre><code>as_tool_choice(obj: Union[str, Callable, BaseTool]) -&gt; dict\n</code></pre> <p>Build a tool choice argument for the OpenAI API from an object.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def as_tool_choice(obj: Union[str, Callable, BaseTool]) -&gt; dict:\n    \"\"\"Build a tool choice argument for the OpenAI API from an object.\"\"\"\n    if isinstance(obj, BaseTool):\n        name = obj.name\n    else:\n        name = getattr(obj, \"__name__\", str(obj))\n    return dict(type=\"function\", function=dict(name=name))\n</code></pre>"},{"location":"reference/func/#appl.func.auto_prime_gen","title":"auto_prime_gen","text":"<pre><code>auto_prime_gen(gen_func)\n</code></pre> <p>Decorate a generator to automatically prime the generator.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def auto_prime_gen(gen_func):\n    \"\"\"Decorate a generator to automatically prime the generator.\"\"\"\n\n    def wrapper(*args, **kwargs):\n        gen = gen_func(*args, **kwargs)\n        next(gen)  # prime the generator\n        return gen\n\n    return wrapper\n</code></pre>"},{"location":"reference/func/#appl.func.build_tools","title":"build_tools","text":"<pre><code>build_tools(\n    tools: OneOrMany[Union[BaseTool, Callable]]\n) -&gt; Sequence[BaseTool]\n</code></pre> <p>Build a list of tools from the given tools or functions.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def build_tools(tools: OneOrMany[Union[BaseTool, Callable]]) -&gt; Sequence[BaseTool]:\n    \"\"\"Build a list of tools from the given tools or functions.\"\"\"\n\n    def convert_to_tool(tool: Union[BaseTool, Callable]) -&gt; BaseTool:\n        if isinstance(tool, BaseTool):\n            return tool\n        if callable(tool):\n            return as_tool(tool)\n        raise ValueError(f\"Invalid tool: {tool}\")\n\n    # process tools\n    if isinstance(tools, BaseTool) or callable(tools):\n        return [convert_to_tool(tools)]\n    if isinstance(tools, Sequence):\n        return [convert_to_tool(tool) for tool in tools]\n    raise ValueError(f\"Invalid tools: {tools}\")\n</code></pre>"},{"location":"reference/func/#appl.func.call","title":"call","text":"<pre><code>call(\n    func: Callable,\n    *args: Any,\n    use_process: bool = False,\n    **kwargs: Any\n) -&gt; CallFuture\n</code></pre> <p>Create a CallFuture object from a function and its arguments.</p> <p>The CallFuture object will call the function in a separate thread or process, therefore the function need to be thread-safe or process-safe.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def call(\n    func: Callable, *args: Any, use_process: bool = False, **kwargs: Any\n) -&gt; CallFuture:\n    \"\"\"Create a CallFuture object from a function and its arguments.\n\n    The CallFuture object will call the function in a separate thread or process,\n    therefore the function need to be thread-safe or process-safe.\n    \"\"\"\n    return CallFuture(func, *args, use_process=use_process, **kwargs)\n</code></pre>"},{"location":"reference/func/#appl.func.convo","title":"convo","text":"<pre><code>convo(_ctx: Optional[PromptContext] = None) -&gt; Conversation\n</code></pre> <p>Return the full conversation in the context.</p> <p>Similar to globals() in Python in some sense.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>@need_ctx\ndef convo(_ctx: Optional[PromptContext] = None) -&gt; Conversation:\n    \"\"\"Return the full conversation in the context.\n\n    Similar to globals() in Python in some sense.\n    \"\"\"\n    # Added default value for _ctx to avoid the warning of type checker\n    if _ctx is None:\n        raise ValueError(\n            \"PromptContext is required for convo, \"\n            \"this function should be called within @ppl function.\"\n        )\n    return _ctx.messages\n</code></pre>"},{"location":"reference/func/#appl.func.empty_line","title":"empty_line","text":"<pre><code>empty_line(num_lines: int = 1) -&gt; PromptRecords\n</code></pre> <p>Create empty lines regardless of other compositor.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def empty_line(num_lines: int = 1) -&gt; PromptRecords:\n    \"\"\"Create empty lines regardless of other compositor.\"\"\"\n    records = PromptRecords()\n    records.record(PrinterPush(separator=\"\\n\", indexing=Indexing(), new_indent=\"\"))\n    for _ in range(num_lines):\n        records.record(\"\")\n    records.record(PrinterPop())\n    return records\n</code></pre>"},{"location":"reference/func/#appl.func.gen","title":"gen","text":"<pre><code>gen(\n    server: Optional[str] = None,\n    *,\n    max_tokens: Optional[int] = None,\n    stop: MaybeOneOrMany[str] = None,\n    temperature: Optional[float] = None,\n    top_p: Optional[float] = None,\n    n: Optional[int] = None,\n    tools: OneOrMany[Union[BaseTool, Callable]] = [],\n    tool_format: str = \"auto\",\n    stream: Optional[bool] = None,\n    mock_response: Optional[\n        Union[CompletionResponse, str]\n    ] = None,\n    _ctx: Optional[PromptContext] = None,\n    **kwargs: Any\n) -&gt; Generation\n</code></pre> <p>Send a generation request to the LLM backend.</p> <p>Parameters:</p> <ul> <li> <code>server</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>name of the backend server. Defaults to the default server set in the configs.</p> </li> <li> <code>max_tokens</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>maximum number of tokens to generate. Defaults to None.</p> </li> <li> <code>stop</code>             (<code>str | Sequence[str]</code>, default:                 <code>None</code> )         \u2013          <p>stop sequence(s). Defaults to None.</p> </li> <li> <code>temperature</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>temperature for sampling. Defaults to None.</p> </li> <li> <code>top_p</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>nucleus sampling parameter. Defaults to None.</p> </li> <li> <code>n</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>number of choices to generate. Defaults to 1.</p> </li> <li> <code>tools</code>             (<code>BaseTool | Callable | Sequence[BaseTool | Callable]</code>, default:                 <code>[]</code> )         \u2013          <p>tools can be used. Defaults to None.</p> </li> <li> <code>tool_format</code>             (<code>str</code>, default:                 <code>'auto'</code> )         \u2013          <p>format for the tools. Defaults to \"auto\".</p> </li> <li> <code>stream</code>             (<code>bool</code>, default:                 <code>None</code> )         \u2013          <p>whether to stream the results. Defaults to False.</p> </li> <li> <code>mock_response</code>             (<code>Union[CompletionResponse, str]</code>, default:                 <code>None</code> )         \u2013          <p>mock response for testing. Defaults to None.</p> </li> <li> <code>_ctx</code>             (<code>PromptContext</code>, default:                 <code>None</code> )         \u2013          <p>prompt context, will be automatically filled.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>extra arguments for the generation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Generation</code> (            <code>Generation</code> )        \u2013          <p>a future object representing the generation result</p> </li> </ul> Source code in <code>src\\appl\\func.py</code> <pre><code>@need_ctx\ndef gen(\n    server: Optional[str] = None,\n    *,\n    max_tokens: Optional[int] = None,\n    stop: MaybeOneOrMany[str] = None,\n    temperature: Optional[float] = None,\n    top_p: Optional[float] = None,\n    n: Optional[int] = None,\n    tools: OneOrMany[Union[BaseTool, Callable]] = [],\n    tool_format: str = \"auto\",\n    stream: Optional[bool] = None,\n    mock_response: Optional[Union[CompletionResponse, str]] = None,\n    _ctx: Optional[PromptContext] = None,\n    **kwargs: Any,\n) -&gt; Generation:\n    \"\"\"Send a generation request to the LLM backend.\n\n    Args:\n        server (str, optional):\n            name of the backend server. Defaults to the default server set in the configs.\n        max_tokens (int, optional): maximum number of tokens to generate. Defaults to None.\n        stop (str|Sequence[str], optional): stop sequence(s). Defaults to None.\n        temperature (float, optional): temperature for sampling. Defaults to None.\n        top_p (float, optional): nucleus sampling parameter. Defaults to None.\n        n (int, optional): number of choices to generate. Defaults to 1.\n        tools (BaseTool|Callable|Sequence[BaseTool|Callable], optional): tools can be used. Defaults to None.\n        tool_format (str, optional): format for the tools. Defaults to \"auto\".\n        stream (bool, optional): whether to stream the results. Defaults to False.\n        mock_response (Union[CompletionResponse, str], optional): mock response for testing. Defaults to None.\n        _ctx (PromptContext): prompt context, will be automatically filled.\n        kwargs (Any): extra arguments for the generation.\n\n    Returns:\n        Generation: a future object representing the generation result\n    \"\"\"\n    backend_server = server_manager.get_server(server)\n    if _ctx is None:\n        raise ValueError(\n            \"PromptContext is required for generation.\"\n            \"Normally, it should be automatically filled.\"\n        )\n    messages = _ctx.messages\n    messages.materialize()  # materialize the messages\n    # TODO: double check the correctness\n    messages = copy.deepcopy(messages)  # freeze the prompt for the generation\n\n    create_args = GenArgs(\n        model=backend_server.model_name,\n        messages=messages,\n        max_tokens=max_tokens,\n        stop=stop,\n        temperature=temperature,\n        top_p=top_p,\n        n=n,\n        tools=build_tools(tools),\n        tool_format=tool_format,  # type: ignore\n        stream=stream,\n    )\n\n    generation = Generation(\n        backend_server, create_args, mock_response=mock_response, _ctx=_ctx, **kwargs\n    )\n\n    @traceable(name=generation.id, metadata={\"appl\": \"gen\"})\n    def langsmith_trace(*args: Any, **kwargs: Any) -&gt; None:\n        pass\n\n    langsmith_trace(backend_server, create_args, _ctx=_ctx, **kwargs)\n    return generation\n</code></pre>"},{"location":"reference/func/#appl.func.get_var","title":"get_var","text":"<pre><code>get_var(name: str, _ctx: PromptContext) -&gt; Any\n</code></pre> <p>Get a variable by name from the prompt context.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>@need_ctx\ndef get_var(name: str, _ctx: PromptContext) -&gt; Any:\n    \"\"\"Get a variable by name from the prompt context.\"\"\"\n    return getattr(_ctx, name)\n</code></pre>"},{"location":"reference/func/#appl.func.need_ctx","title":"need_ctx","text":"<pre><code>need_ctx(func: Callable[P, T]) -&gt; Callable[P, T]\n</code></pre> <p>Decorate a function to mark it as needing a prompt context.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def need_ctx(func: Callable[P, T]) -&gt; Callable[P, T]:\n    \"\"\"Decorate a function to mark it as needing a prompt context.\"\"\"\n    setattr(func, \"__need_ctx__\", True)\n    return func\n</code></pre>"},{"location":"reference/func/#appl.func.openai_tool_schema","title":"openai_tool_schema","text":"<pre><code>openai_tool_schema(func: Callable) -&gt; dict\n</code></pre> <p>Build openai tool schema from a function.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def openai_tool_schema(func: Callable) -&gt; dict:\n    \"\"\"Build openai tool schema from a function.\"\"\"\n    return as_tool(func).openai_schema\n</code></pre>"},{"location":"reference/func/#appl.func.partial","title":"partial","text":"<pre><code>partial(func: Callable, *args: Any, **kwargs: Any) -&gt; Any\n</code></pre> <p>Create a new function with partial application of the given arguments and keywords.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def partial(func: Callable, *args: Any, **kwargs: Any) -&gt; Any:\n    \"\"\"Create a new function with partial application of the given arguments and keywords.\"\"\"\n    new_func = functools.partial(func, *args, **kwargs)\n    if getattr(func, \"__need_ctx__\", True):\n        new_func = need_ctx(new_func)  # type: ignore\n    return new_func\n</code></pre>"},{"location":"reference/func/#appl.func.ppl","title":"ppl","text":"<pre><code>ppl(\n    ctx: Union[str, F] = \"new\",\n    comp: Optional[Compositor] = None,\n    *,\n    default_return: Optional[Literal[prompt]] = None,\n    exclude_first_str: bool = False,\n    auto_prime: bool = False,\n    num_extra_wrappers: int = 0,\n    new_ctx_func: Callable = PromptContext\n) -&gt; Union[Callable[[F], F], F]\n</code></pre> <p>Decorate a function to mark it as an APPL function.</p> <p>The function contains a prompt context, which could be same as or copied from its caller function, or created from scratch, or resumed from the last run.</p> <p>Parameters:</p> <ul> <li> <code>ctx</code>             (<code>str</code>, default:                 <code>'new'</code> )         \u2013          <p>the method to deal with the child context, available methods includes:</p> <ul> <li>(default) \"new\" or \"new_ctx\": create a brand new context.</li> <li>\"copy\" or \"copy_ctx\":     copy from the parent's context, the change will not     affect the parent's context.</li> <li>\"same\" or \"same_ctx\":     use the same context as the parent's, the change will     affect the parent's context.</li> <li>\"resume\" or \"resume_ctx\":     resume its own context from the last run.     For the first run, it will use the parent's context.</li> </ul> </li> <li> <code>comp</code>             (<code>Compositor</code>, default:                 <code>None</code> )         \u2013          <p>the default compositor to be used. Defaults to None.</p> </li> <li> <code>default_return</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>The default return value, \"prompt\" means return the prompt within the function. Defaults to None.</p> </li> <li> <code>exclude_first_str</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>set to True to exclude the first string (liekly the docstring) from the prompt. Defaults to False.</p> </li> <li> <code>auto_prime</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>set to True to automatically prime the generator. Defaults to False.</p> </li> <li> <code>num_extra_wrappers</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>the number of extra wrappers to go back to the caller frame.</p> </li> <li> <code>new_ctx_func</code>             (<code>Callable</code>, default:                 <code>PromptContext</code> )         \u2013          <p>the function to create a new context. Defaults to PromptContext.</p> </li> </ul> Source code in <code>src\\appl\\func.py</code> <pre><code>def ppl(\n    ctx: Union[str, F] = \"new\",\n    comp: Optional[Compositor] = None,\n    *,\n    default_return: Optional[Literal[\"prompt\"]] = None,\n    exclude_first_str: bool = False,\n    auto_prime: bool = False,\n    num_extra_wrappers: int = 0,\n    new_ctx_func: Callable = PromptContext,\n) -&gt; Union[Callable[[F], F], F]:\n    \"\"\"Decorate a function to mark it as an APPL function.\n\n    The function contains a prompt context, which could be same as or\n    copied from its caller function, or created from scratch, or resumed\n    from the last run.\n\n    Args:\n        ctx (str):\n            the method to deal with the child context, available methods includes:\n\n            - (default) \"new\" or \"new_ctx\": create a brand new context.\n            - \"copy\" or \"copy_ctx\":\n                copy from the parent's context, the change will not\n                affect the parent's context.\n            - \"same\" or \"same_ctx\":\n                use the same context as the parent's, the change will\n                affect the parent's context.\n            - \"resume\" or \"resume_ctx\":\n                resume its own context from the last run.\n                For the first run, it will use the parent's context.\n\n        comp (Compositor, optional):\n            the default compositor to be used. Defaults to None.\n        default_return (str, optional):\n            The default return value, \"prompt\" means return the prompt within\n            the function. Defaults to None.\n        exclude_first_str (bool, optional):\n            set to True to exclude the first string (liekly the docstring)\n            from the prompt. Defaults to False.\n        auto_prime (bool, optional):\n            set to True to automatically prime the generator. Defaults to False.\n        num_extra_wrappers (int, optional):\n            the number of extra wrappers to go back to the caller frame.\n        new_ctx_func (Callable, optional):\n            the function to create a new context. Defaults to PromptContext.\n    \"\"\"\n    # The same doc string as PromptFunc (excluding the func argument)\n\n    ctx_method: str = \"new\"\n\n    def decorator(func: F) -&gt; F:\n        \"\"\"Decorate a function as prompt function.\"\"\"\n        _is_class_method = False\n        if \".\" in (qualname := func.__qualname__):\n            # NOTE: this is a workaround for class methods, may not cover all cases\n            qualnames = qualname.split(\".\")\n            if qualnames[-2] != \"&lt;locals&gt;\":\n                _is_class_method = True\n\n        # ? should disable such usage?\n        # if not _is_class_method and \"&lt;locals&gt;\" in qualname and ctx_method == \"resume\":\n        #     raise ValueError(\"Cannot use 'resume' with local functions.\")\n        prompt_func = PromptFunc(\n            func, ctx_method, comp, default_return, exclude_first_str, new_ctx_func\n        )\n\n        @need_ctx\n        @traceable(name=func.__name__, metadata={\"appl\": \"func\"})\n        @functools.wraps(func)\n        def wrapper(\n            *args: Any,\n            _globals: Optional[Dict] = None,\n            _locals: Optional[Dict] = None,\n            **kwargs: Any,\n        ) -&gt; Any:\n            # add to trace (function call)\n            func_name = f\"{prompt_func._name}_{prompt_func._run_cnt}\"\n            prompt_func._run_cnt += 1\n            add_to_trace(\n                FunctionCallEvent(\n                    name=func_name,\n                    args={\"args\": repr(args), \"kwargs\": repr(kwargs)},\n                )\n            )\n            # closure variables\n            freevars = prompt_func.compiled_func.freevars\n            if _locals is None:\n                # * Workaround for closure variables\n                # Default: use the locals from the caller\n                frame = inspect.currentframe()\n                num_wrappers = (3 if auto_prime else 2) + num_extra_wrappers\n                for _ in range(num_wrappers):\n                    if frame is None:\n                        raise RuntimeError(\"No caller frame found\")\n                    # back to @traceable frame, and the caller frame\n                    frame = frame.f_back\n                if frame is None:\n                    raise RuntimeError(\"No caller frame found\")\n                _locals = frame.f_locals\n\n                if len(freevars):\n                    vars = {var: _locals.get(var, \"NotFound\") for var in freevars}\n                    logger.debug(\n                        f\"For freevars of function {func.__name__}, \"\n                        f\"automatically using locals from the caller: {vars}\"\n                    )\n                    for var in freevars:\n                        if var not in _locals:\n                            logger.warning(\n                                f\"could not find variable {var} automatically from the caller frame.\"\n                            )\n            results = prompt_func(\n                *args,\n                _globals=_globals,\n                _locals=_locals,\n                _is_class_method=_is_class_method,\n                **kwargs,\n            )\n            # add to trace (function return)\n            add_to_trace(FunctionReturnEvent(name=func_name))  # ret=results\n            return results\n\n        if auto_prime:\n            wrapper = auto_prime_gen(wrapper)\n        setattr(wrapper, \"_prompt_func\", prompt_func)\n        return wrapper  # type: ignore\n\n    if isinstance(ctx, str):\n        ctx_method = ctx\n        # used as a decorator with arguments (e.g., @ppl(ctx=\"copy\"))\n        # returns a decorator that takes a function as input\n        return decorator\n    else:\n        # used as a single decorator (i.e., @ppl)\n        return decorator(func=ctx)  # returns a wrapper\n</code></pre>"},{"location":"reference/func/#appl.func.records","title":"records","text":"<pre><code>records(\n    _ctx: Optional[PromptContext] = None,\n) -&gt; PromptRecords\n</code></pre> <p>Return the prompt defined in the current function.</p> <p>Similar to locals() in Python in some sense.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>@need_ctx\ndef records(_ctx: Optional[PromptContext] = None) -&gt; PromptRecords:\n    \"\"\"Return the prompt defined in the current function.\n\n    Similar to locals() in Python in some sense.\n    \"\"\"\n    # add default value for _ctx to avoid the warning of type checker\n    if _ctx is None:\n        raise ValueError(\n            \"PromptContext is required for records, \"\n            \"this function should be called within @ppl function.\"\n        )\n    return _ctx.records\n</code></pre>"},{"location":"reference/func/#appl.func.str_future","title":"str_future","text":"<pre><code>str_future(obj: Any) -&gt; StringFuture\n</code></pre> <p>Convert an object to a StringFuture object.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def str_future(obj: Any) -&gt; StringFuture:\n    \"\"\"Convert an object to a StringFuture object.\"\"\"\n    return StringFuture(obj)\n</code></pre>"},{"location":"reference/func/#appl.func.wraps","title":"wraps","text":"<pre><code>wraps(func: F) -&gt; Callable[[F], F]\n</code></pre> <p>Replace the functools.wraps to take care of the type hint.</p> Source code in <code>src\\appl\\func.py</code> <pre><code>def wraps(func: F) -&gt; Callable[[F], F]:\n    \"\"\"Replace the functools.wraps to take care of the type hint.\"\"\"\n\n    def decorator(wrapper: F) -&gt; F:\n        return functools.wraps(func)(wrapper)\n\n    return decorator\n</code></pre>"},{"location":"reference/role_changer/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> role_changer","text":""},{"location":"reference/role_changer/#appl.role_changer","title":"role_changer","text":""},{"location":"reference/role_changer/#appl.role_changer.AIRole","title":"AIRole","text":"<pre><code>AIRole(name: Optional[str] = None, **kwargs: Any)\n</code></pre> <p>             Bases: <code>RoleChanger</code></p> <p>Change the role of the prompts to assistant.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The name of the assistant role. Defaults to None.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>The keyword arguments to pass to the Role</p> </li> </ul> Source code in <code>src\\appl\\role_changer.py</code> <pre><code>def __init__(self, name: Optional[str] = None, **kwargs: Any):\n    \"\"\"Initialize the AIRole object.\n\n    Args:\n        name: The name of the assistant role. Defaults to None.\n        **kwargs: The keyword arguments to pass to the Role\n    \"\"\"\n    role = MessageRole(ASSISTANT, name=name)\n    super().__init__(role=role, **kwargs)\n</code></pre>"},{"location":"reference/role_changer/#appl.role_changer.RoleChanger","title":"RoleChanger","text":"<pre><code>RoleChanger(\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>PrinterModifier</code></p> <p>The contextual role changer of the prompts.</p> <p>Parameters:</p> <ul> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The new role of the prompts. Defaults to None.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\role_changer.py</code> <pre><code>def __init__(\n    self, role: Optional[MessageRole] = None, _ctx: Optional[PromptContext] = None\n):\n    \"\"\"Initialize the RoleChanger object.\n\n    Args:\n        role: The new role of the prompts. Defaults to None.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/role_changer/#appl.role_changer.SystemRole","title":"SystemRole","text":"<pre><code>SystemRole(name: Optional[str] = None, **kwargs: Any)\n</code></pre> <p>             Bases: <code>RoleChanger</code></p> <p>Change the role of the prompts to system.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The name of the system role. Defaults to None.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>The keyword arguments to pass to the RoleChanger constructor.</p> </li> </ul> Source code in <code>src\\appl\\role_changer.py</code> <pre><code>def __init__(self, name: Optional[str] = None, **kwargs: Any):\n    \"\"\"Initialize the SystemRole object.\n\n    Args:\n        name: The name of the system role. Defaults to None.\n        **kwargs: The keyword arguments to pass to the RoleChanger constructor.\n    \"\"\"\n    role = MessageRole(SYSTEM, name=name)\n    super().__init__(role=role, **kwargs)\n</code></pre>"},{"location":"reference/role_changer/#appl.role_changer.ToolRole","title":"ToolRole","text":"<pre><code>ToolRole(name: Optional[str] = None, **kwargs: Any)\n</code></pre> <p>             Bases: <code>RoleChanger</code></p> <p>Change the role of the prompts to tool.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The name of the tool role. Defaults to None.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>The keyword arguments to pass to the RoleChanger constructor.</p> </li> </ul> Source code in <code>src\\appl\\role_changer.py</code> <pre><code>def __init__(self, name: Optional[str] = None, **kwargs: Any):\n    \"\"\"Initialize the ToolRole object.\n\n    Args:\n        name: The name of the tool role. Defaults to None.\n        **kwargs: The keyword arguments to pass to the RoleChanger constructor.\n    \"\"\"\n    role = MessageRole(TOOL, name=name)\n    super().__init__(role=role, **kwargs)\n</code></pre>"},{"location":"reference/role_changer/#appl.role_changer.UserRole","title":"UserRole","text":"<pre><code>UserRole(name: Optional[str] = None, **kwargs: Any)\n</code></pre> <p>             Bases: <code>RoleChanger</code></p> <p>Change the role of the prompts to user.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The name of the user role. Defaults to None.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>The keyword arguments to pass to the RoleChanger constructor.</p> </li> </ul> Source code in <code>src\\appl\\role_changer.py</code> <pre><code>def __init__(self, name: Optional[str] = None, **kwargs: Any):\n    \"\"\"Initialize the UserRole object.\n\n    Args:\n        name: The name of the user role. Defaults to None.\n        **kwargs: The keyword arguments to pass to the RoleChanger constructor.\n    \"\"\"\n    role = MessageRole(USER, name=name)\n    super().__init__(role=role, **kwargs)\n</code></pre>"},{"location":"reference/types/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> types","text":""},{"location":"reference/types/#appl.types","title":"types","text":""},{"location":"reference/utils/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> utils","text":""},{"location":"reference/utils/#appl.utils","title":"utils","text":""},{"location":"reference/utils/#appl.utils.LoguruFormatter","title":"LoguruFormatter","text":"<pre><code>LoguruFormatter(\n    fmt: Optional[str] = None,\n    max_length: Optional[int] = None,\n    suffix_length: int = 0,\n)\n</code></pre> <p>Custom formatter for loguru logger.</p> <p>Parameters:</p> <ul> <li> <code>fmt</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The format string for the log message.</p> </li> <li> <code>max_length</code>             (<code>Optional[int]</code>, default:                 <code>None</code> )         \u2013          <p>The maximum length of the message, truncate if longer.</p> </li> <li> <code>suffix_length</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>The length of the suffix to keep when truncating.</p> </li> </ul> Source code in <code>src\\appl\\utils.py</code> <pre><code>def __init__(\n    self,\n    fmt: Optional[str] = None,\n    max_length: Optional[int] = None,\n    suffix_length: int = 0,\n):\n    \"\"\"Initialize the formatter with the format string and max length of the message.\n\n    Args:\n        fmt: The format string for the log message.\n        max_length: The maximum length of the message, truncate if longer.\n        suffix_length: The length of the suffix to keep when truncating.\n    \"\"\"\n    if fmt is None:\n        fmt = configs.getattrs(\"settings.logging.format\")\n    self.fmt = fmt.rstrip()\n    self.max_length = max_length\n    self.suffix_length = suffix_length\n</code></pre>"},{"location":"reference/utils/#appl.utils.LoguruFormatter.loguru_format","title":"loguru_format","text":"<pre><code>loguru_format(record: Dict) -&gt; str\n</code></pre> <p>Format the log message with the record.</p> Source code in <code>src\\appl\\utils.py</code> <pre><code>def loguru_format(self, record: Dict) -&gt; str:\n    \"\"\"Format the log message with the record.\"\"\"\n    msg = record[\"message\"]\n    fmt = self.fmt\n    if self.max_length is not None and len(msg) &gt; self.max_length:\n        suffix_len = min(self.max_length, self.suffix_length)\n        truncated = msg[: self.max_length - suffix_len]\n        truncated += f\"...(snipped {len(msg) - self.max_length} chars)\"\n        if suffix_len &gt; 0:\n            truncated += \"...\" + msg[-suffix_len:]\n        record[\"trunc_message\"] = truncated\n        fmt = fmt.replace(\"{message}\", \"{trunc_message}\")\n    return fmt + \"\\n\"\n</code></pre>"},{"location":"reference/utils/#appl.utils.find_dotenv","title":"find_dotenv","text":"<pre><code>find_dotenv(\n    filename: str = \".env\",\n    raise_error_if_not_found: bool = False,\n    current_folder: Optional[str] = None,\n    usecwd: bool = False,\n) -&gt; str\n</code></pre> <p>Search in increasingly higher folders for the given file.</p> <p>Returns path to the file if found, or an empty string otherwise.</p> Source code in <code>src\\appl\\utils.py</code> <pre><code>def find_dotenv(\n    filename: str = \".env\",\n    raise_error_if_not_found: bool = False,\n    current_folder: Optional[str] = None,\n    usecwd: bool = False,\n) -&gt; str:\n    \"\"\"Search in increasingly higher folders for the given file.\n\n    Returns path to the file if found, or an empty string otherwise.\n    \"\"\"\n    # Rewrited the original function to add the option to start with a custom folder\n    folder = get_folder(current_folder, usecwd)\n    results = find_files(folder, [filename])\n    if results:\n        return results[0]\n\n    if raise_error_if_not_found:\n        raise IOError(\"File not found\")\n    return \"\"\n</code></pre>"},{"location":"reference/utils/#appl.utils.find_files","title":"find_files","text":"<pre><code>find_files(folder: str, filenames: list[str]) -&gt; list[str]\n</code></pre> <p>Find files in the folder or its parent folders.</p> Source code in <code>src\\appl\\utils.py</code> <pre><code>def find_files(folder: str, filenames: list[str]) -&gt; list[str]:\n    \"\"\"Find files in the folder or its parent folders.\"\"\"\n    results = []\n    for dirname in _walk_to_root(folder):\n        for filename in filenames:\n            check_path = os.path.join(dirname, filename)\n            if os.path.isfile(check_path):\n                results.append(check_path)\n                # return the first found file among the filenames\n                break\n    return results\n</code></pre>"},{"location":"reference/utils/#appl.utils.get_folder","title":"get_folder","text":"<pre><code>get_folder(\n    current_folder: Optional[str] = None,\n    usecwd: bool = False,\n) -&gt; str\n</code></pre> <p>Get the the current working directory.</p> Source code in <code>src\\appl\\utils.py</code> <pre><code>def get_folder(\n    current_folder: Optional[str] = None,\n    usecwd: bool = False,\n) -&gt; str:\n    \"\"\"Get the the current working directory.\"\"\"\n    if usecwd or _is_interactive() or getattr(sys, \"frozen\", False):\n        # Should work without __file__, e.g. in REPL or IPython notebook.\n        folder = os.getcwd()\n    elif current_folder is not None:  # [ADD] option to specify the folder\n        folder = current_folder\n    else:\n        # will work for .py files\n        frame = sys._getframe()\n        current_file = __file__\n\n        while frame.f_code.co_filename == current_file:\n            assert frame.f_back is not None\n            frame = frame.f_back\n        frame_filename = frame.f_code.co_filename\n        folder = os.path.dirname(os.path.abspath(frame_filename))\n\n    return folder\n</code></pre>"},{"location":"reference/utils/#appl.utils.get_meta_file","title":"get_meta_file","text":"<pre><code>get_meta_file(trace_file: str) -&gt; str\n</code></pre> <p>Get the meta file storing metadata of the trace file.</p> Source code in <code>src\\appl\\utils.py</code> <pre><code>def get_meta_file(trace_file: str) -&gt; str:\n    \"\"\"Get the meta file storing metadata of the trace file.\"\"\"\n    # meta file derived from trace_file: *.pkl -&gt; *_meta.json\n    return os.path.splitext(trace_file)[0] + \"_meta.json\"\n</code></pre>"},{"location":"reference/utils/#appl.utils.get_num_tokens","title":"get_num_tokens","text":"<pre><code>get_num_tokens(\n    prompt: str, encoding: str = \"cl100k_base\"\n) -&gt; int\n</code></pre> <p>Get the number of tokens in the prompt for the given encoding.</p> Source code in <code>src\\appl\\utils.py</code> <pre><code>def get_num_tokens(prompt: str, encoding: str = \"cl100k_base\") -&gt; int:\n    \"\"\"Get the number of tokens in the prompt for the given encoding.\"\"\"\n    return len(tiktoken.get_encoding(encoding).encode(prompt))\n</code></pre>"},{"location":"reference/utils/#appl.utils.timeit","title":"timeit","text":"<pre><code>timeit(func: Callable) -&gt; Callable\n</code></pre> <p>Decorator to time the execution of a function.</p> Source code in <code>src\\appl\\utils.py</code> <pre><code>def timeit(func: Callable) -&gt; Callable:\n    \"\"\"Decorator to time the execution of a function.\"\"\"\n\n    @functools.wraps(func)\n    def timer(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        logger.info(f\"{func.__name__} executed in {end - start:.2f} seconds.\")\n        return result\n\n    return timer\n</code></pre>"},{"location":"reference/core/","title":"Index","text":""},{"location":"reference/core/#appl.core","title":"core","text":""},{"location":"reference/core/compile/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> compile","text":""},{"location":"reference/core/compile/#appl.core.compile","title":"compile","text":""},{"location":"reference/core/compile/#appl.core.compile.APPLCompiled","title":"APPLCompiled","text":"<pre><code>APPLCompiled(\n    code: CodeType,\n    ast: AST,\n    original_func: Callable,\n    compile_info: Dict,\n)\n</code></pre> <p>A compiled APPL function that can be called with context.</p> <p>Parameters:</p> <ul> <li> <code>code</code>             (<code>CodeType</code>)         \u2013          <p>The compiled code object.</p> </li> <li> <code>ast</code>             (<code>AST</code>)         \u2013          <p>The AST of the compiled code.</p> </li> <li> <code>original_func</code>             (<code>Callable</code>)         \u2013          <p>The original function.</p> </li> <li> <code>compile_info</code>             (<code>Dict</code>)         \u2013          <p>The compile information.</p> </li> </ul> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def __init__(\n    self, code: CodeType, ast: AST, original_func: Callable, compile_info: Dict\n):\n    \"\"\"Initialize the compiled function.\n\n    Args:\n        code: The compiled code object.\n        ast: The AST of the compiled code.\n        original_func: The original function.\n        compile_info: The compile information.\n    \"\"\"\n    self._code = code\n    self._ast = ast\n    self._name = original_func.__name__\n    self._original_func = original_func\n    self._compile_info = compile_info\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.APPLCompiled.freevars","title":"freevars  <code>property</code>","text":"<pre><code>freevars: Tuple[str, ...]\n</code></pre> <p>Get the free variables of the compiled function.</p>"},{"location":"reference/core/compile/#appl.core.compile.AddCtxToArgs","title":"AddCtxToArgs","text":"<pre><code>AddCtxToArgs(compile_info: Dict, *args: Any, **kwargs: Any)\n</code></pre> <p>             Bases: <code>ApplNodeTransformer</code></p> <p>An AST node transformer that adds _ctx to the function arguments.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def __init__(self, compile_info: Dict, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the transformer with compile info.\"\"\"\n    super().__init__(*args, **kwargs)\n    self._compile_info = compile_info\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.AddCtxToArgs.visit_FunctionDef","title":"visit_FunctionDef","text":"<pre><code>visit_FunctionDef(node: FunctionDef) -&gt; FunctionDef\n</code></pre> <p>Add _ctx to the function arguments if not present.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def visit_FunctionDef(self, node: FunctionDef) -&gt; FunctionDef:\n    \"\"\"Add _ctx to the function arguments if not present.\"\"\"\n    # ! only add _ctx to outermost function def, not call generic_visit here.\n    # self.generic_visit(node) # !! do not call\n    args = node.args\n    # add _ctx to kwargs if not present\n    if not _has_arg(args.args, \"_ctx\") and not _has_arg(args.kwonlyargs, \"_ctx\"):\n        args.kwonlyargs.append(CTX_ARG)\n        # PromptContext() as default\n        args.kw_defaults.append(\n            Call(func=Name(id=\"PromptContext\", ctx=Load()), args=[], keywords=[])\n        )\n    for var in self._compile_info[\"freevars\"]:\n        args.kwonlyargs.append(ast.arg(arg=var))\n        args.kw_defaults.append(ast.Name(id=var, ctx=Load()))\n        logger.debug(f\"add freevar {var} to function {node.name} args.\")\n    return node\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.AddExecuteWrapper","title":"AddExecuteWrapper","text":"<pre><code>AddExecuteWrapper(\n    compile_info: Dict, *args: Any, **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>ApplNodeTransformer</code></p> <p>An AST node transformer that adds the appl.execute wrapper to expression statements.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def __init__(self, compile_info: Dict, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the transformer with compile info.\"\"\"\n    super().__init__(*args, **kwargs)\n    self._compile_info = compile_info\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.AddExecuteWrapper.visit_Expr","title":"visit_Expr","text":"<pre><code>visit_Expr(node: Expr) -&gt; Expr\n</code></pre> <p>Add appl.execute wrapper to expression statements.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def visit_Expr(self, node: Expr) -&gt; Expr:\n    \"\"\"Add appl.execute wrapper to expression statements.\"\"\"\n    return Expr(\n        Call(\n            func=Attribute(\n                value=Name(id=\"appl\", ctx=Load()),\n                attr=\"execute\",\n                ctx=Load(),\n            ),\n            args=[node.value],\n            keywords=[CTX_KEYWORD],  # , GLOBALS_KEYWORD, LOCALS_KEYWORD],\n        )\n    )\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.ApplNodeTransformer","title":"ApplNodeTransformer","text":"<pre><code>ApplNodeTransformer(\n    compile_info: Dict, *args: Any, **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>NodeTransformer</code></p> <p>A base class for AST node transformers in APPL.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def __init__(self, compile_info: Dict, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the transformer with compile info.\"\"\"\n    super().__init__(*args, **kwargs)\n    self._compile_info = compile_info\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.CallWithContext","title":"CallWithContext","text":"<pre><code>CallWithContext(\n    compile_info: Dict, *args: Any, **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>ApplNodeTransformer</code></p> <p>An AST node transformer provides the context to function calls.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def __init__(self, compile_info: Dict, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the transformer with compile info.\"\"\"\n    super().__init__(*args, **kwargs)\n    self._compile_info = compile_info\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.CallWithContext.visit_Call","title":"visit_Call","text":"<pre><code>visit_Call(node: Call) -&gt; Call\n</code></pre> <p>Provide context (_ctx) to function calls that needs ctx.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def visit_Call(self, node: Call) -&gt; Call:\n    \"\"\"Provide context (_ctx) to function calls that needs ctx.\"\"\"\n    self.generic_visit(node)\n    # logger.debug(f\"visit Call: {ast.dump(node, indent=4)}\")\n    # * use appl.with_ctx as wrapper for all functions,\n    # * pass _ctx to the function annotated with @need_ctx\n    new_node = Call(\n        Attribute(\n            value=Name(id=\"appl\", ctx=Load()),\n            attr=\"with_ctx\",\n            ctx=Load(),\n        ),\n        node.args,\n        node.keywords,\n    )\n    new_node.keywords.append(ast.keyword(arg=\"_func\", value=node.func))\n    # add _ctx to kwargs if not present\n    if not _has_arg(node.keywords, \"_ctx\"):\n        new_node.keywords.append(CTX_KEYWORD)\n    new_node.keywords.append(GLOBALS_KEYWORD)\n    new_node.keywords.append(LOCALS_KEYWORD)\n    return new_node\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.RemoveApplDecorator","title":"RemoveApplDecorator","text":"<pre><code>RemoveApplDecorator(*args: Any, **kwargs: Any)\n</code></pre> <p>             Bases: <code>ApplNodeTransformer</code></p> <p>An AST node transformer that removes the ppl decorator.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the transformer with the outmost flag.\"\"\"\n    super().__init__(*args, **kwargs)\n    self._outmost = True\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.RemoveApplDecorator.visit_FunctionDef","title":"visit_FunctionDef","text":"<pre><code>visit_FunctionDef(node)\n</code></pre> <p>Remove the ppl decorator from the function definition.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def visit_FunctionDef(self, node):\n    \"\"\"Remove the ppl decorator from the function definition.\"\"\"\n    if node.decorator_list:\n        for decorator in node.decorator_list:\n            if self._is_ppl_decorator(decorator):\n                if not self._outmost:\n                    self._raise_syntax_error(\n                        decorator.lineno,\n                        decorator.col_offset,\n                        \"Nested ppl decorator is not allowed yet for APPL.\",\n                    )\n        # all decorators should be removed\n        node.decorator_list = []\n    if self._outmost:\n        self._outmost = False\n    self.generic_visit(node)\n    return node\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.SplitString","title":"SplitString","text":"<pre><code>SplitString(compile_info: Dict, *args: Any, **kwargs: Any)\n</code></pre> <p>             Bases: <code>ApplNodeTransformer</code></p> <p>An AST node transformer that splits the f-string into multiple parts.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def __init__(self, compile_info: Dict, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the transformer with compile info.\"\"\"\n    super().__init__(*args, **kwargs)\n    self._compile_info = compile_info\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.SplitString.visit_Expr","title":"visit_Expr","text":"<pre><code>visit_Expr(node: Expr) -&gt; stmt\n</code></pre> <p>Split the f-string into multiple parts, so that we can add appl.execute wrapper to each part.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def visit_Expr(self, node: Expr) -&gt; stmt:\n    \"\"\"Split the f-string into multiple parts, so that we can add appl.execute wrapper to each part.\"\"\"\n    if isinstance(node.value, JoinedStr):\n        fstring = node.value\n        # logger.debug(f\"For joined string: {fstring}\")\n        body: List[stmt] = []\n        for value in fstring.values:\n            if isinstance(value, Constant):\n                body.append(Expr(value))\n            elif isinstance(value, FormattedValue):\n                body.extend(self._add_formatted_value(value))\n            else:\n                raise ValueError(\n                    f\"Unknown value type in a JoinedStr: {type(value)}\"\n                )\n        if len(body) == 0:  # empty string\n            return node\n        if len(body) == 1:  # single string\n            return body[0]\n        return With(\n            items=[\n                ast.withitem(\n                    context_expr=Call(\n                        func=Attribute(\n                            value=Name(id=\"appl\", ctx=Load()),\n                            attr=\"Str\",\n                            ctx=Load(),\n                        ),\n                        args=[],\n                        keywords=[],\n                    )\n                )\n            ],\n            body=body,\n        )\n    return node\n</code></pre>"},{"location":"reference/core/compile/#appl.core.compile.appl_compile","title":"appl_compile","text":"<pre><code>appl_compile(func: Callable) -&gt; APPLCompiled\n</code></pre> <p>Compile an APPL function.</p> Source code in <code>src\\appl\\core\\compile.py</code> <pre><code>def appl_compile(func: Callable) -&gt; APPLCompiled:\n    \"\"\"Compile an APPL function.\"\"\"\n    sourcefile = inspect.getsourcefile(func)\n    lines, lineno = inspect.getsourcelines(func)\n    source = textwrap.dedent(inspect.getsource(func))\n    key = f\"&lt;appl-compiled:{sourcefile}:{lineno}&gt;\"\n    linecache.cache[key] = (\n        len(source),\n        None,\n        [line + \"\\n\" for line in source.splitlines()],\n        key,\n    )\n\n    parsed_ast = ast.parse(source)\n    logger.debug(\n        f\"\\n{'-'*20} code BEFORE appl compile {'-'*20}\\n{ast.unparse(parsed_ast)}\"\n    )\n\n    transformers = [\n        RemoveApplDecorator,\n        SplitString,\n        CallWithContext,\n        AddCtxToArgs,\n        AddExecuteWrapper,\n    ]\n    compile_info = {\n        \"source\": source,\n        \"sourcefile\": sourcefile,\n        \"lineno\": lineno,\n        \"func_name\": func.__name__,\n        \"freevars\": func.__code__.co_freevars,\n    }\n    for transformer in transformers:\n        parsed_ast = transformer(compile_info).visit(parsed_ast)\n\n    parsed_ast = ast.fix_missing_locations(parsed_ast)\n    compiled_ast = compile(parsed_ast, filename=key, mode=\"exec\")\n    logger.debug(\n        f\"\\n{'-'*20} code AFTER appl compile {'-'*20}\\n{ast.unparse(parsed_ast)}\"\n    )\n\n    return APPLCompiled(compiled_ast, parsed_ast, func, compile_info)\n</code></pre>"},{"location":"reference/core/config/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> config","text":""},{"location":"reference/core/config/#appl.core.config","title":"config","text":""},{"location":"reference/core/config/#appl.core.config.DEFAULT_CONFIGS","title":"DEFAULT_CONFIGS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_CONFIGS = load_config(DEFAULT_CONFIG_FILE)\n</code></pre> <p>The static default configs loaded from the default config file.</p>"},{"location":"reference/core/config/#appl.core.config.configs","title":"configs  <code>module-attribute</code>","text":"<pre><code>configs = deepcopy()\n</code></pre> <p>The global configs</p>"},{"location":"reference/core/config/#appl.core.config.Configs","title":"Configs","text":"<p>             Bases: <code>Dict</code></p> <p>A Dictionary class that allows for dot notation access to nested dictionaries.</p>"},{"location":"reference/core/config/#appl.core.config.Configs.getattrs","title":"getattrs","text":"<pre><code>getattrs(key: str, default: Any = None) -&gt; Any\n</code></pre> <p>Get a value from a nested dictionary using a dot-separated key string.</p> Source code in <code>src\\appl\\core\\config.py</code> <pre><code>def getattrs(self, key: str, default: Any = None) -&gt; Any:\n    \"\"\"Get a value from a nested dictionary using a dot-separated key string.\"\"\"\n    if \".\" in key:\n        keys = key.split(\".\")\n    else:\n        keys = [key]\n    prefix = \".\"\n    v = self\n    try:\n        for k in keys:\n            v = getattr(v, k)\n            prefix += k + \".\"\n        return v\n    except KeyError as e:\n        msg = f\"{e} not found in prefix '{prefix}'\"\n\n        if default is None:  # check if key exists in default configs\n            try:\n                # fallback to default configs\n                default = DEFAULT_CONFIGS.getattrs(key)\n            except Exception:\n                pass\n\n        if default is not None:\n            logger.warning(f\"{msg}, using default: {default}\")\n            return default\n        logger.error(msg)\n        raise e\n</code></pre>"},{"location":"reference/core/config/#appl.core.config.Configs.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml() -&gt; str\n</code></pre> <p>Convert the Configs object to a YAML string.</p> Source code in <code>src\\appl\\core\\config.py</code> <pre><code>def to_yaml(self) -&gt; str:\n    \"\"\"Convert the Configs object to a YAML string.\"\"\"\n    return yaml.dump(self.to_dict())\n</code></pre>"},{"location":"reference/core/config/#appl.core.config.load_config","title":"load_config","text":"<pre><code>load_config(\n    file: str, *args: Any, **kwargs: Any\n) -&gt; Configs\n</code></pre> <p>Load a config file and return the data as a dictionary.</p> Source code in <code>src\\appl\\core\\config.py</code> <pre><code>def load_config(file: str, *args: Any, **kwargs: Any) -&gt; Configs:\n    \"\"\"Load a config file and return the data as a dictionary.\"\"\"\n    ext = get_ext(file)\n    if ext not in [\".json\", \".yaml\", \".yml\", \".toml\"]:\n        raise ValueError(f\"Unsupported config file type {ext}\")\n    content = load_file(file, *args, **kwargs)\n    return Configs(content)\n</code></pre>"},{"location":"reference/core/context/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> context","text":""},{"location":"reference/core/context/#appl.core.context","title":"context","text":""},{"location":"reference/core/context/#appl.core.context.PromptContext","title":"PromptContext","text":"<pre><code>PromptContext(globals_: Optional[Namespace] = None)\n</code></pre> <p>The context of the APPL function.</p> <p>Parameters:</p> <ul> <li> <code>globals_</code>             (<code>Optional[Namespace]</code>, default:                 <code>None</code> )         \u2013          <p>The global namespace of the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def __init__(self, globals_: Optional[Namespace] = None):\n    \"\"\"Initialize the PromptContext object.\n\n    Args:\n        globals_: The global namespace of the APPL function.\n    \"\"\"\n    if globals_ is None:\n        # create a new namespace (should inside __init__)\n        globals_ = Namespace()\n    self.globals = globals_\n    # set default values\n    if \"messages\" not in globals_:\n        self.messages = Conversation(system_messages=[], messages=[])\n    if \"printer\" not in globals_:\n        self.printer = PromptPrinter()\n    if \"is_outmost\" not in globals_:\n        self.is_outmost = True\n\n    # local vars start with \"_\"\n    self.locals = Namespace()\n    self._records = PromptRecords()\n    self._exclude_first_str = False\n    self._is_first_str = True\n</code></pre>"},{"location":"reference/core/context/#appl.core.context.PromptContext.records","title":"records  <code>property</code>","text":"<pre><code>records: PromptRecords\n</code></pre> <p>The prompt records of the context.</p>"},{"location":"reference/core/context/#appl.core.context.PromptContext.add_image","title":"add_image","text":"<pre><code>add_image(img: Image) -&gt; None\n</code></pre> <p>Add an image to the prompt context.</p> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def add_image(self, img: Image) -&gt; None:\n    \"\"\"Add an image to the prompt context.\"\"\"\n    self.messages.extend(self.printer(img))\n    self.records.record(img)\n</code></pre>"},{"location":"reference/core/context/#appl.core.context.PromptContext.add_message","title":"add_message","text":"<pre><code>add_message(message: BaseMessage) -&gt; None\n</code></pre> <p>Add a message to the prompt context.</p> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def add_message(self, message: BaseMessage) -&gt; None:\n    \"\"\"Add a message to the prompt context.\"\"\"\n    self.messages.extend(self.printer(message))\n    self.records.record(message)\n</code></pre>"},{"location":"reference/core/context/#appl.core.context.PromptContext.add_records","title":"add_records","text":"<pre><code>add_records(\n    records: PromptRecords, write_to_prompt: bool = True\n) -&gt; None\n</code></pre> <p>Add prompt records to the prompt context.</p> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def add_records(self, records: PromptRecords, write_to_prompt: bool = True) -&gt; None:\n    \"\"\"Add prompt records to the prompt context.\"\"\"\n    if write_to_prompt:\n        self.messages.extend(self.printer(records))\n    self.records.extend(records)\n</code></pre>"},{"location":"reference/core/context/#appl.core.context.PromptContext.add_string","title":"add_string","text":"<pre><code>add_string(string: String) -&gt; None\n</code></pre> <p>Add a string to the prompt context.</p> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def add_string(self, string: String) -&gt; None:\n    \"\"\"Add a string to the prompt context.\"\"\"\n    if isinstance(string, str):\n        string = StringFuture(string)\n    self.messages.extend(self.printer(string))\n    self.records.record(string)\n</code></pre>"},{"location":"reference/core/context/#appl.core.context.PromptContext.copy","title":"copy","text":"<pre><code>copy() -&gt; 'PromptContext'\n</code></pre> <p>Create a new prompt context that copies the globals.</p> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def copy(self) -&gt; \"PromptContext\":\n    \"\"\"Create a new prompt context that copies the globals.\"\"\"\n    return PromptContext(globals_=deepcopy(self.globals))\n</code></pre>"},{"location":"reference/core/context/#appl.core.context.PromptContext.inherit","title":"inherit","text":"<pre><code>inherit() -&gt; 'PromptContext'\n</code></pre> <p>Create a new prompt context that has the same globals.</p> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def inherit(self) -&gt; \"PromptContext\":\n    \"\"\"Create a new prompt context that has the same globals.\"\"\"\n    return PromptContext(globals_=self.globals)\n</code></pre>"},{"location":"reference/core/context/#appl.core.context.PromptContext.pop_printer","title":"pop_printer","text":"<pre><code>pop_printer() -&gt; None\n</code></pre> <p>Pop a printer state from the prompt context.</p> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def pop_printer(self) -&gt; None:\n    \"\"\"Pop a printer state from the prompt context.\"\"\"\n    self.printer.pop()\n    self.records.record(PrinterPop())\n</code></pre>"},{"location":"reference/core/context/#appl.core.context.PromptContext.push_printer","title":"push_printer","text":"<pre><code>push_printer(push_args: PrinterPush) -&gt; None\n</code></pre> <p>Push a new printer state to the prompt context.</p> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def push_printer(self, push_args: PrinterPush) -&gt; None:\n    \"\"\"Push a new printer state to the prompt context.\"\"\"\n    self.printer.push(push_args)\n    self.records.record(push_args)\n</code></pre>"},{"location":"reference/core/context/#appl.core.context.PromptContext.set_records","title":"set_records","text":"<pre><code>set_records(records: PromptRecords) -&gt; None\n</code></pre> <p>Set the prompt records of the context.</p> Source code in <code>src\\appl\\core\\context.py</code> <pre><code>def set_records(self, records: PromptRecords) -&gt; None:\n    \"\"\"Set the prompt records of the context.\"\"\"\n    self._records = records\n</code></pre>"},{"location":"reference/core/function/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> function","text":""},{"location":"reference/core/function/#appl.core.function","title":"function","text":""},{"location":"reference/core/function/#appl.core.function.PromptFunc","title":"PromptFunc","text":"<pre><code>PromptFunc(\n    func: Callable,\n    ctx_method: str = \"new\",\n    comp: Optional[Compositor] = None,\n    default_return: Optional[Literal[\"prompt\"]] = None,\n    exclude_first_str: bool = False,\n    new_ctx_func: Callable = PromptContext,\n)\n</code></pre> <p>A wrapper for an APPL function, can be called as a normal function.</p> <p>The function contains a prompt context, which could be same as or copied from its caller function, or created from scratch, or resumed from the last run.</p> <p>Parameters:</p> <ul> <li> <code>func</code>             (<code>Callable</code>)         \u2013          <p>the function being wrapped</p> </li> <li> <code>ctx_method</code>             (<code>str</code>, default:                 <code>'new'</code> )         \u2013          <p>the method to deal with the child context, available methods includes:</p> <ul> <li>(default) \"new\" or \"new_ctx\": create a brand new context.</li> <li>\"copy\" or \"copy_ctx\":     copy from the parent's context, the change will not     affect the parent's context.</li> <li>\"same\" or \"same_ctx\":     use the same context as the parent's, the change will     affect the parent's context.</li> <li>\"resume\" or \"resume_ctx\":     resume its own context from the last run.     For the first run, it will copy the parent's context.</li> </ul> </li> <li> <code>comp</code>             (<code>Compositor</code>, default:                 <code>None</code> )         \u2013          <p>the default compositor to be used. Defaults to None.</p> </li> <li> <code>default_return</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>The default return value, \"prompt\" means return the prompt within the function. Defaults to None.</p> </li> <li> <code>exclude_first_str</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>set to True to exclude the first string (liekly the docstring) from the prompt. Defaults to False.</p> </li> <li> <code>new_ctx_func</code>             (<code>Callable</code>, default:                 <code>PromptContext</code> )         \u2013          <p>the function to create a new context. Defaults to PromptContext.</p> </li> </ul> Source code in <code>src\\appl\\core\\function.py</code> <pre><code>def __init__(\n    self,\n    func: Callable,\n    ctx_method: str = \"new\",\n    comp: Optional[Compositor] = None,\n    default_return: Optional[Literal[\"prompt\"]] = None,\n    exclude_first_str: bool = False,\n    new_ctx_func: Callable = PromptContext,\n    # default_sep: Optional[str] = None,\n    # ? set the default printer behavior for the prompt function?\n):\n    \"\"\"Initialize the PromptFunc.\n\n    Args:\n        func (Callable): the function being wrapped\n        ctx_method (str):\n            the method to deal with the child context, available methods includes:\n\n            - (default) \"new\" or \"new_ctx\": create a brand new context.\n            - \"copy\" or \"copy_ctx\":\n                copy from the parent's context, the change will not\n                affect the parent's context.\n            - \"same\" or \"same_ctx\":\n                use the same context as the parent's, the change will\n                affect the parent's context.\n            - \"resume\" or \"resume_ctx\":\n                resume its own context from the last run.\n                For the first run, it will copy the parent's context.\n\n        comp (Compositor, optional):\n            the default compositor to be used. Defaults to None.\n        default_return (str, optional):\n            The default return value, \"prompt\" means return the prompt within\n            the function. Defaults to None.\n        exclude_first_str (bool, optional):\n            set to True to exclude the first string (liekly the docstring)\n            from the prompt. Defaults to False.\n        new_ctx_func (Callable, optional):\n            the function to create a new context. Defaults to PromptContext.\n    \"\"\"\n    self._func = appl_compile(func)\n    self._signature = inspect.signature(func)\n    self._doc = func.__doc__\n    self._name = func.__name__\n    self._default_ctx_method = self._process_ctx_method(ctx_method)\n    self._default_compositor = comp\n    if default_return is not None and default_return != \"prompt\":\n        raise NotImplementedError(\"Only support default_return='prompt' now.\")\n    self._default_return = default_return\n    self._exclude_first_str = exclude_first_str\n    self._new_ctx_func = new_ctx_func\n    self._persist_ctx: Optional[PromptContext] = None\n    self._run_cnt = 0\n</code></pre>"},{"location":"reference/core/function/#appl.core.function.PromptFunc.compiled_func","title":"compiled_func  <code>property</code>","text":"<pre><code>compiled_func\n</code></pre> <p>The compiled function.</p>"},{"location":"reference/core/generation/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> generation","text":""},{"location":"reference/core/generation/#appl.core.generation","title":"generation","text":""},{"location":"reference/core/generation/#appl.core.generation.Generation","title":"Generation","text":"<pre><code>Generation(\n    server: BaseServer,\n    args: GenArgs,\n    *,\n    mock_response: Optional[\n        Union[CompletionResponse, str]\n    ] = None,\n    lazy_eval: bool = False,\n    _ctx: Optional[PromptContext] = None,\n    **kwargs: Any\n)\n</code></pre> <p>Represents a generation call to the model.</p> <p>Parameters:</p> <ul> <li> <code>server</code>             (<code>BaseServer</code>)         \u2013          <p>An LLM server where the generation request will be sent.</p> </li> <li> <code>args</code>             (<code>GenArgs</code>)         \u2013          <p>The arguments of the generation call.</p> </li> <li> <code>mock_response</code>             (<code>Optional[Union[CompletionResponse, str]]</code>, default:                 <code>None</code> )         \u2013          <p>A mock response for the generation call.</p> </li> <li> <code>lazy_eval</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If True, the generation call will be evaluated lazily.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Extra arguments for the generation call.</p> </li> </ul> Source code in <code>src\\appl\\core\\generation.py</code> <pre><code>def __init__(\n    self,\n    server: BaseServer,\n    args: GenArgs,\n    *,\n    mock_response: Optional[Union[CompletionResponse, str]] = None,\n    lazy_eval: bool = False,\n    _ctx: Optional[PromptContext] = None,\n    **kwargs: Any,\n    # kwargs used for extra args for the create method\n) -&gt; None:\n    \"\"\"Initialize the Generation object.\n\n    Args:\n        server: An LLM server where the generation request will be sent.\n        args: The arguments of the generation call.\n        mock_response: A mock response for the generation call.\n        lazy_eval: If True, the generation call will be evaluated lazily.\n        _ctx: The prompt context filled automatically by the APPL function.\n        **kwargs: Extra arguments for the generation call.\n    \"\"\"\n    # name needs to be unique and ordered, so it has to be generated in the main thread\n    self._id = inc_global(\"gen_cnt\") - 1  # take the value before increment\n\n    self._server = server\n    self._args = args\n    self._ctx = _ctx\n    self._extra_args = kwargs\n\n    add_to_trace(GenerationInitEvent(name=self.id))\n    if isinstance(mock_response, CompletionResponse):\n        self._call = lambda: mock_response\n    else:\n        if mock_response:\n            # use litellm's mock response\n            kwargs.update({\"mock_response\": mock_response})\n        # TODO: supports custom postprocessing messages\n        self._call = CallFuture(\n            self._server.create,\n            lazy_eval=lazy_eval,\n            args=args,\n            gen_id=self.id,\n            **kwargs,\n        )\n\n    # tools\n    self._tools: Sequence[BaseTool] = args.tools\n    self._name2tools = {tool.name: tool for tool in self._tools}\n</code></pre>"},{"location":"reference/core/generation/#appl.core.generation.Generation.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>The unique ID of the generation.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.is_message","title":"is_message  <code>property</code>","text":"<pre><code>is_message: bool\n</code></pre> <p>Whether the response is a text message.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.is_obj","title":"is_obj  <code>property</code>","text":"<pre><code>is_obj: bool\n</code></pre> <p>Whether the response is an object.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.is_tool_call","title":"is_tool_call  <code>property</code>","text":"<pre><code>is_tool_call: bool\n</code></pre> <p>Whether the response is a tool call.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.message","title":"message  <code>property</code>","text":"<pre><code>message: Optional[str]\n</code></pre> <p>The message of the response.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.response","title":"response  <code>property</code>","text":"<pre><code>response: CompletionResponse\n</code></pre> <p>The response of the generation call.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.response_obj","title":"response_obj  <code>property</code>","text":"<pre><code>response_obj: Any\n</code></pre> <p>The object of the response.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.response_type","title":"response_type  <code>property</code>","text":"<pre><code>response_type: ResponseType\n</code></pre> <p>The type of the response.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.results","title":"results  <code>property</code>","text":"<pre><code>results: Any\n</code></pre> <p>The results of the response.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.str_future","title":"str_future  <code>property</code>","text":"<pre><code>str_future: StringFuture\n</code></pre> <p>The StringFuture representation of the response.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.tool_calls","title":"tool_calls  <code>property</code>","text":"<pre><code>tool_calls: List[ToolCall]\n</code></pre> <p>The tool calls of the response.</p>"},{"location":"reference/core/generation/#appl.core.generation.Generation.as_prompt","title":"as_prompt","text":"<pre><code>as_prompt() -&gt; Union[AIMessage, StringFuture]\n</code></pre> <p>Get the response of the generation as a promptable object.</p> Source code in <code>src\\appl\\core\\generation.py</code> <pre><code>def as_prompt(self) -&gt; Union[AIMessage, StringFuture]:\n    \"\"\"Get the response of the generation as a promptable object.\"\"\"\n    if self._args.tools:\n        if self.is_tool_call:\n            return AIMessage(tool_calls=self.tool_calls)\n    return StringFuture(self._call)\n</code></pre>"},{"location":"reference/core/generation/#appl.core.generation.Generation.run_tool_calls","title":"run_tool_calls","text":"<pre><code>run_tool_calls(\n    filter_fn: Optional[\n        Callable[[List[ToolCall]], List[ToolCall]]\n    ] = None,\n    parallel: bool = False,\n    use_process: bool = False,\n    log_results: Optional[bool] = None,\n) -&gt; List[ToolMessage]\n</code></pre> <p>Run all tool calls in the generation and return the results.</p> <p>Parameters:</p> <ul> <li> <code>filter_fn</code>             (<code>Optional[Callable[[List[ToolCall]], List[ToolCall]]]</code>, default:                 <code>None</code> )         \u2013          <p>A function that takes a list of ToolCall objects and returns a filtered list of ToolCall objects. This function can be used to filter the tool calls that will be run.</p> </li> <li> <code>parallel</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If True, run the tool calls in parallel. Default to False.</p> </li> <li> <code>use_process</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If True, run the tool calls in separate processes, effective when parallel is True. Default to False.</p> </li> <li> <code>log_results</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>If True, log the results of the tool calls. Note This will wait for the results to be ready. Default to use the setting in configs.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[ToolMessage]</code>         \u2013          <p>A list of ToolMessage objects.</p> </li> </ul> Source code in <code>src\\appl\\core\\generation.py</code> <pre><code>def run_tool_calls(\n    self,\n    filter_fn: Optional[Callable[[List[ToolCall]], List[ToolCall]]] = None,\n    parallel: bool = False,\n    use_process: bool = False,\n    log_results: Optional[bool] = None,\n) -&gt; List[ToolMessage]:\n    \"\"\"Run all tool calls in the generation and return the results.\n\n    Args:\n        filter_fn:\n            A function that takes a list of ToolCall objects and returns\n            a filtered list of ToolCall objects. This function can be\n            used to filter the tool calls that will be run.\n        parallel: If True, run the tool calls in parallel. Default to False.\n        use_process:\n            If True, run the tool calls in separate processes,\n            effective when parallel is True. Default to False.\n        log_results:\n            If True, log the results of the tool calls. Note This will wait for\n            the results to be ready. Default to use the setting in configs.\n\n    Returns:\n        A list of ToolMessage objects.\n    \"\"\"\n    if not self.is_tool_call:\n        raise ValueError(\"Error: The Generation is not a tool call\")\n    if log_results is None:\n        log_results = configs.getattrs(\"settings.logging.display.tool_results\")\n    tool_calls = self.tool_calls\n    if filter_fn:\n        tool_calls = filter_fn(tool_calls)\n    messages = []\n    for tc in tool_calls:\n        role = MessageRole(TOOL, tc.name)\n        try:\n            tool_result = self._call_tool(\n                tc.name, tc.args, parallel=parallel, use_process=use_process\n            )\n            msg = ToolMessage(\n                tool_result, role=role, tool_call_id=tc.id, has_error=False\n            )\n        except Exception as e:\n            logger.error(f\"Error running tool call: {tc.name}({tc.args})\")\n            logger.error(e)\n            msg = ToolMessage(str(e), role=role, tool_call_id=tc.id, has_error=True)\n        messages.append(msg)\n    if log_results:  # this will wait for the results to be ready\n        for msg in messages:\n            logger.info(f\"Tool call result: {msg}\")\n    return messages\n</code></pre>"},{"location":"reference/core/globals/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> globals","text":""},{"location":"reference/core/globals/#appl.core.globals","title":"globals","text":""},{"location":"reference/core/globals/#appl.core.globals.inc_global","title":"inc_global","text":"<pre><code>inc_global(name: str, delta: Union[int, float] = 1) -&gt; Any\n</code></pre> <p>Increment a global variable by a delta and return the new value.</p> Source code in <code>src\\appl\\core\\globals.py</code> <pre><code>def inc_global(name: str, delta: Union[int, float] = 1) -&gt; Any:\n    \"\"\"Increment a global variable by a delta and return the new value.\"\"\"\n    with global_vars.lock:\n        value = getattr(global_vars, name, 0)\n        value += delta\n        setattr(global_vars, name, value)\n    return value\n</code></pre>"},{"location":"reference/core/io/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> io","text":""},{"location":"reference/core/io/#appl.core.io","title":"io","text":""},{"location":"reference/core/io/#appl.core.io.dump_file","title":"dump_file","text":"<pre><code>dump_file(\n    data: Any,\n    file: str,\n    mode: str = \"w\",\n    ensure_folder_exists: bool = True,\n    file_type: Optional[str] = None,\n    *args: Any,\n    **kwargs: Any\n) -&gt; None\n</code></pre> <p>Write the data to a file based on the file extension.</p> Source code in <code>src\\appl\\core\\io.py</code> <pre><code>def dump_file(\n    data: Any,\n    file: str,\n    mode: str = \"w\",\n    ensure_folder_exists: bool = True,\n    file_type: Optional[str] = None,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Write the data to a file based on the file extension.\"\"\"\n    if file_type is None:\n        file_type = get_ext(file)\n    if ensure_folder_exists:\n        makedirs(file)\n\n    if file_type == \".json\":\n        dump_func: Callable = json.dump\n    elif file_type in [\".yaml\", \".yml\"]:\n        dump_func = yaml.dump\n    elif file_type == \".toml\":\n        dump_func = toml.dump\n    elif file_type in PLAIN_TEXT_FILES:\n\n        def dump_func(data, f, *args, **kwargs):\n            f.write(data)\n\n    else:\n        raise ValueError(f\"Unsupported file type {file_type}\")\n    with open(file, mode) as f:\n        dump_func(data, f, *args, **kwargs)\n</code></pre>"},{"location":"reference/core/io/#appl.core.io.get_ext","title":"get_ext","text":"<pre><code>get_ext(file: str) -&gt; str\n</code></pre> <p>Get the extension of a file.</p> Source code in <code>src\\appl\\core\\io.py</code> <pre><code>def get_ext(file: str) -&gt; str:\n    \"\"\"Get the extension of a file.\"\"\"\n    return os.path.splitext(file)[1]\n</code></pre>"},{"location":"reference/core/io/#appl.core.io.load_file","title":"load_file","text":"<pre><code>load_file(\n    file: str,\n    mode: str = \"r\",\n    file_type: Optional[str] = None,\n    *args: Any,\n    **kwargs: Any\n) -&gt; Any\n</code></pre> <p>Load a file based on the file extension and return the data.</p> Source code in <code>src\\appl\\core\\io.py</code> <pre><code>def load_file(\n    file: str,\n    mode: str = \"r\",\n    file_type: Optional[str] = None,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Load a file based on the file extension and return the data.\"\"\"\n    if file_type is None:\n        file_type = get_ext(file)\n    if file_type == \".json\":\n        load_func: Callable = json.load\n    elif file_type in [\".yaml\", \".yml\"]:\n        load_func = yaml.safe_load\n    elif file_type == \".toml\":\n        load_func = toml.load\n    # elif file_type == \".py\":\n    #     load_func = import_module\n    elif file_type in PLAIN_TEXT_FILES:\n\n        def load_func(f, *args, **kwargs):\n            return f.read()\n\n    else:\n        raise ValueError(f\"Unsupported file type {file_type}\")\n    with open(file, mode) as f:\n        return load_func(f, *args, **kwargs)\n</code></pre>"},{"location":"reference/core/io/#appl.core.io.makedirs","title":"makedirs","text":"<pre><code>makedirs(file: str) -&gt; None\n</code></pre> <p>Make the directory of the file if it does not exist.</p> Source code in <code>src\\appl\\core\\io.py</code> <pre><code>def makedirs(file: str) -&gt; None:\n    \"\"\"Make the directory of the file if it does not exist.\"\"\"\n    if folder := os.path.dirname(file):\n        os.makedirs(folder, exist_ok=True)\n</code></pre>"},{"location":"reference/core/message/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> message","text":""},{"location":"reference/core/message/#appl.core.message","title":"message","text":""},{"location":"reference/core/message/#appl.core.message.AIMessage","title":"AIMessage","text":"<pre><code>AIMessage(\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    tool_calls: Optional[List[ToolCall]] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>BaseMessage</code></p> <p>An assistant message in the conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def __init__(\n    self,\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    tool_calls: Optional[List[ToolCall]] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Create an assistant message with content and extra arguments.\"\"\"\n    if tool_calls is None:\n        tool_calls = []\n    super().__init__(content=content, role=role, tool_calls=tool_calls, **kwargs)\n    self.validate_role(ASSISTANT_ROLE)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.AIMessage.is_ai","title":"is_ai  <code>property</code>","text":"<pre><code>is_ai: bool\n</code></pre> <p>Whether the message is an assistant message.</p>"},{"location":"reference/core/message/#appl.core.message.AIMessage.is_system","title":"is_system  <code>property</code>","text":"<pre><code>is_system: bool\n</code></pre> <p>Whether the message is a system message.</p>"},{"location":"reference/core/message/#appl.core.message.AIMessage.is_tool","title":"is_tool  <code>property</code>","text":"<pre><code>is_tool: bool\n</code></pre> <p>Whether the message is a tool message.</p>"},{"location":"reference/core/message/#appl.core.message.AIMessage.is_user","title":"is_user  <code>property</code>","text":"<pre><code>is_user: bool\n</code></pre> <p>Whether the message is a user message.</p>"},{"location":"reference/core/message/#appl.core.message.AIMessage.get_content","title":"get_content","text":"<pre><code>get_content(as_str: bool = False) -&gt; Any\n</code></pre> <p>Get the content of the message.</p> <p>Materialize the content if it is a FutureValue.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_content(self, as_str: bool = False) -&gt; Any:\n    \"\"\"Get the content of the message.\n\n    Materialize the content if it is a FutureValue.\n    \"\"\"\n    content = self.content\n    if content is not None:\n        if isinstance(content, ContentList):\n            return content.get_contents()  # return a list of dict\n        if isinstance(content, FutureValue):\n            # materialize the content\n            content = content.val\n        if as_str:  # not apply to ContentList\n            content = str(content)\n    return content\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.AIMessage.get_dict","title":"get_dict","text":"<pre><code>get_dict(\n    default_role: Optional[MessageRole] = None,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return a dict representation of the message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_dict(self, default_role: Optional[MessageRole] = None) -&gt; Dict[str, Any]:\n    \"\"\"Return a dict representation of the message.\"\"\"\n    data = super().get_dict(default_role)\n    if len(self.tool_calls):\n        data[\"tool_calls\"] = [call.get_dict() for call in self.tool_calls]\n    return data\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.AIMessage.merge","title":"merge","text":"<pre><code>merge(other: 'BaseMessage') -&gt; Optional['Message']\n</code></pre> <p>Merge the message with another message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def merge(self: \"Message\", other: \"BaseMessage\") -&gt; Optional[\"Message\"]:\n    \"\"\"Merge the message with another message.\"\"\"\n    if self.should_merge(other):\n        # merge the content\n        res = self.model_copy()\n        if isinstance(other.content, ContentList) and not isinstance(\n            res.content, ContentList\n        ):\n            res.content = ContentList(contents=[res.content])\n        res.content += other.content\n        return res\n    return None\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.AIMessage.should_merge","title":"should_merge","text":"<pre><code>should_merge(other: 'BaseMessage') -&gt; bool\n</code></pre> <p>Whether the message should be merged with the other message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def should_merge(self, other: \"BaseMessage\") -&gt; bool:\n    \"\"\"Whether the message should be merged with the other message.\"\"\"\n    if self.is_tool or other.is_tool:\n        # not merge tool messages\n        return False\n    if self.content is None or other.content is None:\n        return False\n    return self.role == other.role\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.AIMessage.str_with_default_role","title":"str_with_default_role","text":"<pre><code>str_with_default_role(\n    default_role: Optional[MessageRole] = None,\n) -&gt; str\n</code></pre> <p>Return the string representation of the message with default role.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def str_with_default_role(self, default_role: Optional[MessageRole] = None) -&gt; str:\n    \"\"\"Return the string representation of the message with default role.\"\"\"\n    return self._get_colored_content(self.role or default_role)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.AIMessage.validate_role","title":"validate_role","text":"<pre><code>validate_role(target_role: MessageRole) -&gt; None\n</code></pre> <p>Validate the role of the message, fill the role if not provided.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def validate_role(self, target_role: MessageRole) -&gt; None:\n    \"\"\"Validate the role of the message, fill the role if not provided.\"\"\"\n    target_type = target_role.type\n    if target_type is None:\n        raise ValueError(\"Target role type must be provided.\")\n    if self.role is None:\n        self.role = target_role\n    elif self.role.type is None:\n        # fill the role type as the target type\n        self.role = MessageRole(type=target_type, name=self.role.name)\n    elif self.role.type != target_type:\n        raise ValueError(f\"Invalid role for {target_type} message: {self.role}\")\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.BaseMessage","title":"BaseMessage","text":"<pre><code>BaseMessage(content: Any = None, *args: Any, **kwargs: Any)\n</code></pre> <p>             Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>The base class for messages.</p> <p>Provides a more flexible way to create a message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def __init__(self, content: Any = None, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Create a message with content and extra arguments.\n\n    Provides a more flexible way to create a message.\n    \"\"\"\n    super().__init__(content=content, *args, **kwargs)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.is_ai","title":"is_ai  <code>property</code>","text":"<pre><code>is_ai: bool\n</code></pre> <p>Whether the message is an assistant message.</p>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.is_system","title":"is_system  <code>property</code>","text":"<pre><code>is_system: bool\n</code></pre> <p>Whether the message is a system message.</p>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.is_tool","title":"is_tool  <code>property</code>","text":"<pre><code>is_tool: bool\n</code></pre> <p>Whether the message is a tool message.</p>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.is_user","title":"is_user  <code>property</code>","text":"<pre><code>is_user: bool\n</code></pre> <p>Whether the message is a user message.</p>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.get_content","title":"get_content","text":"<pre><code>get_content(as_str: bool = False) -&gt; Any\n</code></pre> <p>Get the content of the message.</p> <p>Materialize the content if it is a FutureValue.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_content(self, as_str: bool = False) -&gt; Any:\n    \"\"\"Get the content of the message.\n\n    Materialize the content if it is a FutureValue.\n    \"\"\"\n    content = self.content\n    if content is not None:\n        if isinstance(content, ContentList):\n            return content.get_contents()  # return a list of dict\n        if isinstance(content, FutureValue):\n            # materialize the content\n            content = content.val\n        if as_str:  # not apply to ContentList\n            content = str(content)\n    return content\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.get_dict","title":"get_dict","text":"<pre><code>get_dict(\n    default_role: Optional[MessageRole] = None,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return a dict representation of the message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_dict(self, default_role: Optional[MessageRole] = None) -&gt; Dict[str, Any]:\n    \"\"\"Return a dict representation of the message.\"\"\"\n    # materialize the content using str()\n    role = self.role or default_role\n    if role is None:\n        raise ValueError(\"Role or default role must be provided.\")\n    if role.type is None:\n        if default_role and default_role.type:\n            role = MessageRole(type=default_role.type, name=role.name)\n        else:\n            raise ValueError(\"Role type must be provided.\")\n    data = {\"content\": self.get_content(as_str=True), **role.get_dict()}\n    return data\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.merge","title":"merge","text":"<pre><code>merge(other: 'BaseMessage') -&gt; Optional['Message']\n</code></pre> <p>Merge the message with another message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def merge(self: \"Message\", other: \"BaseMessage\") -&gt; Optional[\"Message\"]:\n    \"\"\"Merge the message with another message.\"\"\"\n    if self.should_merge(other):\n        # merge the content\n        res = self.model_copy()\n        if isinstance(other.content, ContentList) and not isinstance(\n            res.content, ContentList\n        ):\n            res.content = ContentList(contents=[res.content])\n        res.content += other.content\n        return res\n    return None\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.should_merge","title":"should_merge","text":"<pre><code>should_merge(other: 'BaseMessage') -&gt; bool\n</code></pre> <p>Whether the message should be merged with the other message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def should_merge(self, other: \"BaseMessage\") -&gt; bool:\n    \"\"\"Whether the message should be merged with the other message.\"\"\"\n    if self.is_tool or other.is_tool:\n        # not merge tool messages\n        return False\n    if self.content is None or other.content is None:\n        return False\n    return self.role == other.role\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.str_with_default_role","title":"str_with_default_role","text":"<pre><code>str_with_default_role(\n    default_role: Optional[MessageRole] = None,\n) -&gt; str\n</code></pre> <p>Return the string representation of the message with default role.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def str_with_default_role(self, default_role: Optional[MessageRole] = None) -&gt; str:\n    \"\"\"Return the string representation of the message with default role.\"\"\"\n    return self._get_colored_content(self.role or default_role)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.BaseMessage.validate_role","title":"validate_role","text":"<pre><code>validate_role(target_role: MessageRole) -&gt; None\n</code></pre> <p>Validate the role of the message, fill the role if not provided.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def validate_role(self, target_role: MessageRole) -&gt; None:\n    \"\"\"Validate the role of the message, fill the role if not provided.\"\"\"\n    target_type = target_role.type\n    if target_type is None:\n        raise ValueError(\"Target role type must be provided.\")\n    if self.role is None:\n        self.role = target_role\n    elif self.role.type is None:\n        # fill the role type as the target type\n        self.role = MessageRole(type=target_type, name=self.role.name)\n    elif self.role.type != target_type:\n        raise ValueError(f\"Invalid role for {target_type} message: {self.role}\")\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ChatMessage","title":"ChatMessage","text":"<pre><code>ChatMessage(\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>BaseMessage</code></p> <p>A message in the chat conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def __init__(\n    self,\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Create a chat message with content and extra arguments.\"\"\"\n    super().__init__(content=content, role=role, **kwargs)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.is_ai","title":"is_ai  <code>property</code>","text":"<pre><code>is_ai: bool\n</code></pre> <p>Whether the message is an assistant message.</p>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.is_system","title":"is_system  <code>property</code>","text":"<pre><code>is_system: bool\n</code></pre> <p>Whether the message is a system message.</p>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.is_tool","title":"is_tool  <code>property</code>","text":"<pre><code>is_tool: bool\n</code></pre> <p>Whether the message is a tool message.</p>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.is_user","title":"is_user  <code>property</code>","text":"<pre><code>is_user: bool\n</code></pre> <p>Whether the message is a user message.</p>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.get_content","title":"get_content","text":"<pre><code>get_content(as_str: bool = False) -&gt; Any\n</code></pre> <p>Get the content of the message.</p> <p>Materialize the content if it is a FutureValue.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_content(self, as_str: bool = False) -&gt; Any:\n    \"\"\"Get the content of the message.\n\n    Materialize the content if it is a FutureValue.\n    \"\"\"\n    content = self.content\n    if content is not None:\n        if isinstance(content, ContentList):\n            return content.get_contents()  # return a list of dict\n        if isinstance(content, FutureValue):\n            # materialize the content\n            content = content.val\n        if as_str:  # not apply to ContentList\n            content = str(content)\n    return content\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.get_dict","title":"get_dict","text":"<pre><code>get_dict(\n    default_role: Optional[MessageRole] = None,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return a dict representation of the message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_dict(self, default_role: Optional[MessageRole] = None) -&gt; Dict[str, Any]:\n    \"\"\"Return a dict representation of the message.\"\"\"\n    # materialize the content using str()\n    role = self.role or default_role\n    if role is None:\n        raise ValueError(\"Role or default role must be provided.\")\n    if role.type is None:\n        if default_role and default_role.type:\n            role = MessageRole(type=default_role.type, name=role.name)\n        else:\n            raise ValueError(\"Role type must be provided.\")\n    data = {\"content\": self.get_content(as_str=True), **role.get_dict()}\n    return data\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.merge","title":"merge","text":"<pre><code>merge(other: 'BaseMessage') -&gt; Optional['Message']\n</code></pre> <p>Merge the message with another message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def merge(self: \"Message\", other: \"BaseMessage\") -&gt; Optional[\"Message\"]:\n    \"\"\"Merge the message with another message.\"\"\"\n    if self.should_merge(other):\n        # merge the content\n        res = self.model_copy()\n        if isinstance(other.content, ContentList) and not isinstance(\n            res.content, ContentList\n        ):\n            res.content = ContentList(contents=[res.content])\n        res.content += other.content\n        return res\n    return None\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.should_merge","title":"should_merge","text":"<pre><code>should_merge(other: 'BaseMessage') -&gt; bool\n</code></pre> <p>Whether the message should be merged with the other message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def should_merge(self, other: \"BaseMessage\") -&gt; bool:\n    \"\"\"Whether the message should be merged with the other message.\"\"\"\n    if self.is_tool or other.is_tool:\n        # not merge tool messages\n        return False\n    if self.content is None or other.content is None:\n        return False\n    return self.role == other.role\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.str_with_default_role","title":"str_with_default_role","text":"<pre><code>str_with_default_role(\n    default_role: Optional[MessageRole] = None,\n) -&gt; str\n</code></pre> <p>Return the string representation of the message with default role.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def str_with_default_role(self, default_role: Optional[MessageRole] = None) -&gt; str:\n    \"\"\"Return the string representation of the message with default role.\"\"\"\n    return self._get_colored_content(self.role or default_role)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ChatMessage.validate_role","title":"validate_role","text":"<pre><code>validate_role(target_role: MessageRole) -&gt; None\n</code></pre> <p>Validate the role of the message, fill the role if not provided.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def validate_role(self, target_role: MessageRole) -&gt; None:\n    \"\"\"Validate the role of the message, fill the role if not provided.\"\"\"\n    target_type = target_role.type\n    if target_type is None:\n        raise ValueError(\"Target role type must be provided.\")\n    if self.role is None:\n        self.role = target_role\n    elif self.role.type is None:\n        # fill the role type as the target type\n        self.role = MessageRole(type=target_type, name=self.role.name)\n    elif self.role.type != target_type:\n        raise ValueError(f\"Invalid role for {target_type} message: {self.role}\")\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.Conversation","title":"Conversation","text":"<p>             Bases: <code>BaseModel</code></p> <p>A conversation containing messages.</p>"},{"location":"reference/core/message/#appl.core.message.Conversation.has_message_role","title":"has_message_role  <code>property</code>","text":"<pre><code>has_message_role: bool\n</code></pre> <p>Whether the conversation has message roles.</p>"},{"location":"reference/core/message/#appl.core.message.Conversation.append","title":"append","text":"<pre><code>append(message: Message) -&gt; None\n</code></pre> <p>Append a message to the conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def append(self, message: Message) -&gt; None:\n    \"\"\"Append a message to the conversation.\"\"\"\n    if message.is_system:\n        if len(self.messages):\n            # NOTE: Now allow appending system message after other messages\n            # raise ValueError(\"Cannot append system message after other messages.\")\n\n            # Added a warning instead\n            logger.warning(\n                \"Modifying system message after other types of messages.\"\n            )\n        self.system_messages.append(message)  # type: ignore\n    else:\n        self.messages.append(message)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.Conversation.as_list","title":"as_list","text":"<pre><code>as_list(\n    default_role: Optional[MessageRole] = USER_ROLE,\n) -&gt; List[Dict[str, str]]\n</code></pre> <p>Return a list of dict representation of the conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def as_list(\n    self, default_role: Optional[MessageRole] = USER_ROLE\n) -&gt; List[Dict[str, str]]:\n    \"\"\"Return a list of dict representation of the conversation.\"\"\"\n    self.collapse()\n    res = [m.get_dict() for m in self.system_messages]\n    res += [m.get_dict(default_role) for m in self.messages]\n    return res\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.Conversation.collapse","title":"collapse","text":"<pre><code>collapse() -&gt; 'Conversation'\n</code></pre> <p>Collapse the messages in the conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def collapse(self) -&gt; \"Conversation\":\n    \"\"\"Collapse the messages in the conversation.\"\"\"\n    self.system_messages = collapse_messages(self.system_messages)\n    if len(self.system_messages) &gt; 1:\n        raise ValueError(\"System messages cannot be fully collapsed.\")\n    self.messages = collapse_messages(self.messages)\n    return self\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.Conversation.extend","title":"extend","text":"<pre><code>extend(other: 'Conversation') -&gt; None\n</code></pre> <p>Extend the conversation with another conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def extend(self, other: \"Conversation\") -&gt; None:\n    \"\"\"Extend the conversation with another conversation.\"\"\"\n    for sys_m in other.system_messages:\n        self.append(sys_m)\n    for m in other.messages:\n        self.append(m)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.Conversation.make_copy","title":"make_copy","text":"<pre><code>make_copy()\n</code></pre> <p>Make a copy of the conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def make_copy(self):\n    \"\"\"Make a copy of the conversation.\"\"\"\n    return Conversation(\n        system_messages=self.system_messages.copy(),\n        messages=self.messages.copy(),\n    )\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.Conversation.materialize","title":"materialize","text":"<pre><code>materialize() -&gt; None\n</code></pre> <p>Materialize the messages in the conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def materialize(self) -&gt; None:\n    \"\"\"Materialize the messages in the conversation.\"\"\"\n    str(self)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.Conversation.set_system_messages","title":"set_system_messages","text":"<pre><code>set_system_messages(messages: List[SystemMessage]) -&gt; None\n</code></pre> <p>Set the system messages.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def set_system_messages(self, messages: List[SystemMessage]) -&gt; None:\n    \"\"\"Set the system messages.\"\"\"\n    if len(self.system_messages):\n        logger.warning(\"Overwriting system message.\")\n    self.system_messages = messages\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.SystemMessage","title":"SystemMessage","text":"<pre><code>SystemMessage(\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>BaseMessage</code></p> <p>A system message in the conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def __init__(\n    self,\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Create a system message with content and extra arguments.\"\"\"\n    super().__init__(content=content, role=role, **kwargs)\n    self.validate_role(SYSTEM_ROLE)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.is_ai","title":"is_ai  <code>property</code>","text":"<pre><code>is_ai: bool\n</code></pre> <p>Whether the message is an assistant message.</p>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.is_system","title":"is_system  <code>property</code>","text":"<pre><code>is_system: bool\n</code></pre> <p>Whether the message is a system message.</p>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.is_tool","title":"is_tool  <code>property</code>","text":"<pre><code>is_tool: bool\n</code></pre> <p>Whether the message is a tool message.</p>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.is_user","title":"is_user  <code>property</code>","text":"<pre><code>is_user: bool\n</code></pre> <p>Whether the message is a user message.</p>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.get_content","title":"get_content","text":"<pre><code>get_content(as_str: bool = False) -&gt; Any\n</code></pre> <p>Get the content of the message.</p> <p>Materialize the content if it is a FutureValue.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_content(self, as_str: bool = False) -&gt; Any:\n    \"\"\"Get the content of the message.\n\n    Materialize the content if it is a FutureValue.\n    \"\"\"\n    content = self.content\n    if content is not None:\n        if isinstance(content, ContentList):\n            return content.get_contents()  # return a list of dict\n        if isinstance(content, FutureValue):\n            # materialize the content\n            content = content.val\n        if as_str:  # not apply to ContentList\n            content = str(content)\n    return content\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.get_dict","title":"get_dict","text":"<pre><code>get_dict(\n    default_role: Optional[MessageRole] = None,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return a dict representation of the message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_dict(self, default_role: Optional[MessageRole] = None) -&gt; Dict[str, Any]:\n    \"\"\"Return a dict representation of the message.\"\"\"\n    # materialize the content using str()\n    role = self.role or default_role\n    if role is None:\n        raise ValueError(\"Role or default role must be provided.\")\n    if role.type is None:\n        if default_role and default_role.type:\n            role = MessageRole(type=default_role.type, name=role.name)\n        else:\n            raise ValueError(\"Role type must be provided.\")\n    data = {\"content\": self.get_content(as_str=True), **role.get_dict()}\n    return data\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.merge","title":"merge","text":"<pre><code>merge(other: 'BaseMessage') -&gt; Optional['Message']\n</code></pre> <p>Merge the message with another message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def merge(self: \"Message\", other: \"BaseMessage\") -&gt; Optional[\"Message\"]:\n    \"\"\"Merge the message with another message.\"\"\"\n    if self.should_merge(other):\n        # merge the content\n        res = self.model_copy()\n        if isinstance(other.content, ContentList) and not isinstance(\n            res.content, ContentList\n        ):\n            res.content = ContentList(contents=[res.content])\n        res.content += other.content\n        return res\n    return None\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.should_merge","title":"should_merge","text":"<pre><code>should_merge(other: 'BaseMessage') -&gt; bool\n</code></pre> <p>Whether the message should be merged with the other message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def should_merge(self, other: \"BaseMessage\") -&gt; bool:\n    \"\"\"Whether the message should be merged with the other message.\"\"\"\n    if self.is_tool or other.is_tool:\n        # not merge tool messages\n        return False\n    if self.content is None or other.content is None:\n        return False\n    return self.role == other.role\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.str_with_default_role","title":"str_with_default_role","text":"<pre><code>str_with_default_role(\n    default_role: Optional[MessageRole] = None,\n) -&gt; str\n</code></pre> <p>Return the string representation of the message with default role.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def str_with_default_role(self, default_role: Optional[MessageRole] = None) -&gt; str:\n    \"\"\"Return the string representation of the message with default role.\"\"\"\n    return self._get_colored_content(self.role or default_role)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.SystemMessage.validate_role","title":"validate_role","text":"<pre><code>validate_role(target_role: MessageRole) -&gt; None\n</code></pre> <p>Validate the role of the message, fill the role if not provided.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def validate_role(self, target_role: MessageRole) -&gt; None:\n    \"\"\"Validate the role of the message, fill the role if not provided.\"\"\"\n    target_type = target_role.type\n    if target_type is None:\n        raise ValueError(\"Target role type must be provided.\")\n    if self.role is None:\n        self.role = target_role\n    elif self.role.type is None:\n        # fill the role type as the target type\n        self.role = MessageRole(type=target_type, name=self.role.name)\n    elif self.role.type != target_type:\n        raise ValueError(f\"Invalid role for {target_type} message: {self.role}\")\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ToolMessage","title":"ToolMessage","text":"<pre><code>ToolMessage(\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>BaseMessage</code></p> <p>A tool message in the conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def __init__(\n    self,\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Create a tool message with content and extra arguments.\"\"\"\n    super().__init__(content=content, role=role, **kwargs)\n    self.validate_role(TOOL_ROLE)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.is_ai","title":"is_ai  <code>property</code>","text":"<pre><code>is_ai: bool\n</code></pre> <p>Whether the message is an assistant message.</p>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.is_system","title":"is_system  <code>property</code>","text":"<pre><code>is_system: bool\n</code></pre> <p>Whether the message is a system message.</p>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.is_tool","title":"is_tool  <code>property</code>","text":"<pre><code>is_tool: bool\n</code></pre> <p>Whether the message is a tool message.</p>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.is_user","title":"is_user  <code>property</code>","text":"<pre><code>is_user: bool\n</code></pre> <p>Whether the message is a user message.</p>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.get_content","title":"get_content","text":"<pre><code>get_content(as_str: bool = False) -&gt; Any\n</code></pre> <p>Get the content of the message.</p> <p>Materialize the content if it is a FutureValue.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_content(self, as_str: bool = False) -&gt; Any:\n    \"\"\"Get the content of the message.\n\n    Materialize the content if it is a FutureValue.\n    \"\"\"\n    content = self.content\n    if content is not None:\n        if isinstance(content, ContentList):\n            return content.get_contents()  # return a list of dict\n        if isinstance(content, FutureValue):\n            # materialize the content\n            content = content.val\n        if as_str:  # not apply to ContentList\n            content = str(content)\n    return content\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.get_dict","title":"get_dict","text":"<pre><code>get_dict(*args: Any, **kwargs: Any) -&gt; Dict[str, Any]\n</code></pre> <p>Return a dict representation of the message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_dict(self, *args: Any, **kwargs: Any) -&gt; Dict[str, Any]:\n    \"\"\"Return a dict representation of the message.\"\"\"\n    data = super().get_dict(*args, **kwargs)\n    data[\"tool_call_id\"] = self.tool_call_id\n    return data\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.merge","title":"merge","text":"<pre><code>merge(other: 'BaseMessage') -&gt; Optional['Message']\n</code></pre> <p>Merge the message with another message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def merge(self: \"Message\", other: \"BaseMessage\") -&gt; Optional[\"Message\"]:\n    \"\"\"Merge the message with another message.\"\"\"\n    if self.should_merge(other):\n        # merge the content\n        res = self.model_copy()\n        if isinstance(other.content, ContentList) and not isinstance(\n            res.content, ContentList\n        ):\n            res.content = ContentList(contents=[res.content])\n        res.content += other.content\n        return res\n    return None\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.should_merge","title":"should_merge","text":"<pre><code>should_merge(other: 'BaseMessage') -&gt; bool\n</code></pre> <p>Whether the message should be merged with the other message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def should_merge(self, other: \"BaseMessage\") -&gt; bool:\n    \"\"\"Whether the message should be merged with the other message.\"\"\"\n    if self.is_tool or other.is_tool:\n        # not merge tool messages\n        return False\n    if self.content is None or other.content is None:\n        return False\n    return self.role == other.role\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.str_with_default_role","title":"str_with_default_role","text":"<pre><code>str_with_default_role(\n    default_role: Optional[MessageRole] = None,\n) -&gt; str\n</code></pre> <p>Return the string representation of the message with default role.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def str_with_default_role(self, default_role: Optional[MessageRole] = None) -&gt; str:\n    \"\"\"Return the string representation of the message with default role.\"\"\"\n    return self._get_colored_content(self.role or default_role)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.ToolMessage.validate_role","title":"validate_role","text":"<pre><code>validate_role(target_role: MessageRole) -&gt; None\n</code></pre> <p>Validate the role of the message, fill the role if not provided.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def validate_role(self, target_role: MessageRole) -&gt; None:\n    \"\"\"Validate the role of the message, fill the role if not provided.\"\"\"\n    target_type = target_role.type\n    if target_type is None:\n        raise ValueError(\"Target role type must be provided.\")\n    if self.role is None:\n        self.role = target_role\n    elif self.role.type is None:\n        # fill the role type as the target type\n        self.role = MessageRole(type=target_type, name=self.role.name)\n    elif self.role.type != target_type:\n        raise ValueError(f\"Invalid role for {target_type} message: {self.role}\")\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.UserMessage","title":"UserMessage","text":"<pre><code>UserMessage(\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>BaseMessage</code></p> <p>A user message in the conversation.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def __init__(\n    self,\n    content: Any = None,\n    *,\n    role: Optional[MessageRole] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Create a user message with content and extra arguments.\"\"\"\n    super().__init__(content=content, role=role, **kwargs)\n    self.validate_role(USER_ROLE)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.UserMessage.is_ai","title":"is_ai  <code>property</code>","text":"<pre><code>is_ai: bool\n</code></pre> <p>Whether the message is an assistant message.</p>"},{"location":"reference/core/message/#appl.core.message.UserMessage.is_system","title":"is_system  <code>property</code>","text":"<pre><code>is_system: bool\n</code></pre> <p>Whether the message is a system message.</p>"},{"location":"reference/core/message/#appl.core.message.UserMessage.is_tool","title":"is_tool  <code>property</code>","text":"<pre><code>is_tool: bool\n</code></pre> <p>Whether the message is a tool message.</p>"},{"location":"reference/core/message/#appl.core.message.UserMessage.is_user","title":"is_user  <code>property</code>","text":"<pre><code>is_user: bool\n</code></pre> <p>Whether the message is a user message.</p>"},{"location":"reference/core/message/#appl.core.message.UserMessage.get_content","title":"get_content","text":"<pre><code>get_content(as_str: bool = False) -&gt; Any\n</code></pre> <p>Get the content of the message.</p> <p>Materialize the content if it is a FutureValue.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_content(self, as_str: bool = False) -&gt; Any:\n    \"\"\"Get the content of the message.\n\n    Materialize the content if it is a FutureValue.\n    \"\"\"\n    content = self.content\n    if content is not None:\n        if isinstance(content, ContentList):\n            return content.get_contents()  # return a list of dict\n        if isinstance(content, FutureValue):\n            # materialize the content\n            content = content.val\n        if as_str:  # not apply to ContentList\n            content = str(content)\n    return content\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.UserMessage.get_dict","title":"get_dict","text":"<pre><code>get_dict(\n    default_role: Optional[MessageRole] = None,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Return a dict representation of the message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def get_dict(self, default_role: Optional[MessageRole] = None) -&gt; Dict[str, Any]:\n    \"\"\"Return a dict representation of the message.\"\"\"\n    # materialize the content using str()\n    role = self.role or default_role\n    if role is None:\n        raise ValueError(\"Role or default role must be provided.\")\n    if role.type is None:\n        if default_role and default_role.type:\n            role = MessageRole(type=default_role.type, name=role.name)\n        else:\n            raise ValueError(\"Role type must be provided.\")\n    data = {\"content\": self.get_content(as_str=True), **role.get_dict()}\n    return data\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.UserMessage.merge","title":"merge","text":"<pre><code>merge(other: 'BaseMessage') -&gt; Optional['Message']\n</code></pre> <p>Merge the message with another message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def merge(self: \"Message\", other: \"BaseMessage\") -&gt; Optional[\"Message\"]:\n    \"\"\"Merge the message with another message.\"\"\"\n    if self.should_merge(other):\n        # merge the content\n        res = self.model_copy()\n        if isinstance(other.content, ContentList) and not isinstance(\n            res.content, ContentList\n        ):\n            res.content = ContentList(contents=[res.content])\n        res.content += other.content\n        return res\n    return None\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.UserMessage.should_merge","title":"should_merge","text":"<pre><code>should_merge(other: 'BaseMessage') -&gt; bool\n</code></pre> <p>Whether the message should be merged with the other message.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def should_merge(self, other: \"BaseMessage\") -&gt; bool:\n    \"\"\"Whether the message should be merged with the other message.\"\"\"\n    if self.is_tool or other.is_tool:\n        # not merge tool messages\n        return False\n    if self.content is None or other.content is None:\n        return False\n    return self.role == other.role\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.UserMessage.str_with_default_role","title":"str_with_default_role","text":"<pre><code>str_with_default_role(\n    default_role: Optional[MessageRole] = None,\n) -&gt; str\n</code></pre> <p>Return the string representation of the message with default role.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def str_with_default_role(self, default_role: Optional[MessageRole] = None) -&gt; str:\n    \"\"\"Return the string representation of the message with default role.\"\"\"\n    return self._get_colored_content(self.role or default_role)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.UserMessage.validate_role","title":"validate_role","text":"<pre><code>validate_role(target_role: MessageRole) -&gt; None\n</code></pre> <p>Validate the role of the message, fill the role if not provided.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def validate_role(self, target_role: MessageRole) -&gt; None:\n    \"\"\"Validate the role of the message, fill the role if not provided.\"\"\"\n    target_type = target_role.type\n    if target_type is None:\n        raise ValueError(\"Target role type must be provided.\")\n    if self.role is None:\n        self.role = target_role\n    elif self.role.type is None:\n        # fill the role type as the target type\n        self.role = MessageRole(type=target_type, name=self.role.name)\n    elif self.role.type != target_type:\n        raise ValueError(f\"Invalid role for {target_type} message: {self.role}\")\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.as_message","title":"as_message","text":"<pre><code>as_message(\n    role: Optional[MessageRole],\n    content: StrOrImg,\n    *args: Any,\n    **kwargs: Any\n) -&gt; BaseMessage\n</code></pre> <p>Create a message with role, content and extra arguments.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def as_message(\n    role: Optional[MessageRole],\n    content: StrOrImg,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; BaseMessage:\n    \"\"\"Create a message with role, content and extra arguments.\"\"\"\n    role_type = role.type if role else None\n    if role_type not in MESSAGE_CLASS_DICT:\n        raise ValueError(f\"Unknown role: {role}\")\n    cls = MESSAGE_CLASS_DICT[role_type]\n    if isinstance(content, Image):\n        content = ContentList(contents=[content])  # type: ignore\n    return cls(content=content, role=role, *args, **kwargs)\n</code></pre>"},{"location":"reference/core/message/#appl.core.message.collapse_messages","title":"collapse_messages","text":"<pre><code>collapse_messages(messages: List[Message]) -&gt; List[Message]\n</code></pre> <p>Collapse a list of the messages by merging the messages with the same sender.</p> Source code in <code>src\\appl\\core\\message.py</code> <pre><code>def collapse_messages(messages: List[Message]) -&gt; List[Message]:\n    \"\"\"Collapse a list of the messages by merging the messages with the same sender.\"\"\"\n    res = []\n    msg: Optional[Message] = None\n    for m in messages:\n        if msg is None:\n            msg = m\n        else:\n            if (tmp := msg.merge(m)) is not None:\n                # merge success, update the msg\n                msg = tmp\n            else:\n                # merge failed, append the old message to the list\n                res.append(msg)\n                # a new message starts\n                msg = m\n    if msg is not None:\n        res.append(msg)\n    return res\n</code></pre>"},{"location":"reference/core/modifiers/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> modifiers","text":""},{"location":"reference/core/modifiers/#appl.core.modifiers","title":"modifiers","text":""},{"location":"reference/core/modifiers/#appl.core.modifiers.ApplStr","title":"ApplStr","text":"<pre><code>ApplStr(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>Compositor</code></p> <p>A compositor that represents a string in the prompt.</p> <p>Attributes:</p> <ul> <li> <code>_sep</code>         \u2013          <p>The class default separator string is an empty string.</p> </li> <li> <code>_new_indent</code>         \u2013          <p>The class default new indentation string is an empty string.</p> </li> <li> <code>_is_inline</code>         \u2013          <p>The class default inline flag is True.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; with ApplStr():\n...     \"Hello, \"\n...     \"world!\"\n&lt;&lt;&lt; The prompt will be:\nHello, world!\n</code></pre> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/core/modifiers/#appl.core.modifiers.Compositor","title":"Compositor","text":"<pre><code>Compositor(\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n)\n</code></pre> <p>             Bases: <code>PrinterModifier</code></p> <p>The contextual compositor of the prompts.</p> <p>This class represents a contextual compositor that modifies the behavior of the printer. It provides various options for customizing the output format of the prompts within this context manager.</p> <p>Attributes:</p> <ul> <li> <code>_sep</code>             (<code>Optional[str]</code>)         \u2013          <p>The class default separator string is None, indicating inherit from the parent.</p> </li> <li> <code>_indexing</code>             (<code>Indexing</code>)         \u2013          <p>The class default indexing mode is empty indexing.</p> </li> <li> <code>_inc_indent</code>             (<code>str</code>)         \u2013          <p>The class default indentation string is empty string.</p> </li> <li> <code>_new_indent</code>             (<code>Optional[str]</code>)         \u2013          <p>The class default new indentation string is None, indicating not overwrite the indent.</p> </li> <li> <code>_is_inline</code>             (<code>bool</code>)         \u2013          <p>The class default inline flag is False.</p> </li> <li> <code>_new_role</code>             (<code>Optional[MessageRole]</code>)         \u2013          <p>The class default role of the modifier is None, indicating not overwrite the role.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>sep</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The separator string. Defaults to use the class default.</p> </li> <li> <code>indexing</code>             (<code>Union[Indexing, Optional[str]]</code>, default:                 <code>None</code> )         \u2013          <p>The indexing mode. Defaults to use the class default.</p> </li> <li> <code>indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The indentation string. Defaults to use the class default.</p> </li> <li> <code>new_indent</code>             (<code>Optional[Union[str, int]]</code>, default:                 <code>None</code> )         \u2013          <p>The new indentation string. Defaults to use the class default.</p> </li> <li> <code>is_inline</code>             (<code>Optional[bool]</code>, default:                 <code>None</code> )         \u2013          <p>Flag indicating if the modifier is inline. Defaults to use the class default.</p> </li> <li> <code>role</code>             (<code>Optional[MessageRole]</code>, default:                 <code>None</code> )         \u2013          <p>The role of the modifier. Defaults to use the class default.</p> </li> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(\n    self,\n    sep: Optional[str] = None,\n    indexing: Union[Indexing, Optional[str]] = None,\n    indent: Optional[Union[str, int]] = None,\n    new_indent: Optional[Union[str, int]] = None,\n    is_inline: Optional[bool] = None,\n    role: Optional[MessageRole] = None,\n    _ctx: Optional[PromptContext] = None,\n):\n    \"\"\"Initialize the Compositor object.\n\n    Args:\n        sep:\n            The separator string. Defaults to use the class default.\n        indexing:\n            The indexing mode. Defaults to use the class default.\n        indent:\n            The indentation string. Defaults to use the class default.\n        new_indent:\n            The new indentation string. Defaults to use the class default.\n        is_inline:\n            Flag indicating if the modifier is inline. Defaults to use the class default.\n        role:\n            The role of the modifier. Defaults to use the class default.\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    super().__init__(_ctx)\n    if sep is not None:\n        self._sep = sep\n    if indexing is not None:\n        if isinstance(indexing, str):\n            indexing = Indexing(indexing)\n        self._indexing = indexing\n    else:\n        if self._indexing is None:\n            raise ValueError(\"Indexing must be provided.\")\n        self._indexing = copy.copy(self._indexing)\n        # copy to avoid changing the class default\n    if indent is not None:\n        if isinstance(indent, int):\n            indent = \" \" * indent\n        self._inc_indent = indent\n    if new_indent is not None:\n        if isinstance(new_indent, int):\n            new_indent = \" \" * new_indent\n        self._new_indent = new_indent\n    if is_inline is not None:\n        self._is_inline = is_inline\n    if role is not None:\n        self._new_role = role\n</code></pre>"},{"location":"reference/core/modifiers/#appl.core.modifiers.PrinterModifier","title":"PrinterModifier","text":"<pre><code>PrinterModifier(_ctx: Optional[PromptContext] = None)\n</code></pre> <p>             Bases: <code>AbstractContextManager</code></p> <p>The contextual compositor of the prompt printer.</p> <p>Controls the behavior of the prompt printer within the context manager. Should only be used within the APPL function.</p> <p>Parameters:</p> <ul> <li> <code>_ctx</code>             (<code>Optional[PromptContext]</code>, default:                 <code>None</code> )         \u2013          <p>The prompt context filled automatically by the APPL function.</p> </li> </ul> Source code in <code>src\\appl\\core\\modifiers.py</code> <pre><code>def __init__(self, _ctx: Optional[PromptContext] = None):\n    \"\"\"Initialize the PrinterModifier object.\n\n    Args:\n        _ctx: The prompt context filled automatically by the APPL function.\n    \"\"\"\n    self._ctx = _ctx\n</code></pre>"},{"location":"reference/core/modifiers/#appl.core.modifiers.PrinterModifier.push_args","title":"push_args  <code>property</code>","text":"<pre><code>push_args: PrinterPush\n</code></pre> <p>The arguments to push to the printer.</p>"},{"location":"reference/core/printer/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> printer","text":""},{"location":"reference/core/printer/#appl.core.printer","title":"printer","text":""},{"location":"reference/core/printer/#appl.core.printer.RecordType","title":"RecordType  <code>module-attribute</code>","text":"<pre><code>RecordType = Union[\n    BaseMessage,\n    StringFuture,\n    Image,\n    PrinterPush,\n    PrinterPop,\n]\n</code></pre> <p>Types allowed in the prompt records.</p>"},{"location":"reference/core/printer/#appl.core.printer.Indexing","title":"Indexing","text":"<pre><code>Indexing(\n    method: Optional[str] = None,\n    ind: int = 0,\n    suffix: Optional[str] = None,\n)\n</code></pre> <p>The indexing method for the printer.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def __init__(\n    self, method: Optional[str] = None, ind: int = 0, suffix: Optional[str] = None\n):\n    \"\"\"Initialize the indexing method.\"\"\"\n    self._method = method\n    self._ind = ind\n    self._suffix = suffix\n</code></pre>"},{"location":"reference/core/printer/#appl.core.printer.Indexing.get_index","title":"get_index","text":"<pre><code>get_index(ind: Optional[int] = None) -&gt; str\n</code></pre> <p>Get the index string for the current or given index.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def get_index(self, ind: Optional[int] = None) -&gt; str:\n    \"\"\"Get the index string for the current or given index.\"\"\"\n    if ind is None:\n        ind = self._ind\n        self._ind += 1\n    if ind &lt; 0:\n        raise ValueError(\"Indexing method does not support negative indexing.\")\n    return self._get_index(ind)\n</code></pre>"},{"location":"reference/core/printer/#appl.core.printer.PrinterPop","title":"PrinterPop  <code>dataclass</code>","text":"<p>A record to pop the last printer state from the stack.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterPush","title":"PrinterPush  <code>dataclass</code>","text":"<p>A record to push a new printer state to the stack.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterPush.inc_indent","title":"inc_indent  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>inc_indent: str = ''\n</code></pre> <p>The increment of the indent.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterPush.indexing","title":"indexing  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>indexing: Optional[Indexing] = None\n</code></pre> <p>The indexing method to be used.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterPush.is_inline","title":"is_inline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_inline: Optional[bool] = False\n</code></pre> <p>Whether the state is inline.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterPush.new_indent","title":"new_indent  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>new_indent: Optional[str] = None\n</code></pre> <p>The new indent to be used.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterPush.new_role","title":"new_role  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>new_role: Optional[MessageRole] = None\n</code></pre> <p>The new role to be used for the message.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterPush.separator","title":"separator  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>separator: Optional[str] = None\n</code></pre> <p>The separator to be used between texts.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterState","title":"PrinterState  <code>dataclass</code>","text":"<p>A state of the printer.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterState.current_sep","title":"current_sep  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>current_sep: str = ''\n</code></pre> <p>The current separator to be used between texts.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterState.indent","title":"indent  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>indent: str = ''\n</code></pre> <p>The indent to be used in the beginning of each line.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterState.indexing","title":"indexing  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>indexing: Indexing = Indexing(None, 0)\n</code></pre> <p>The indexing method to be used.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterState.is_inline","title":"is_inline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_inline: bool = False\n</code></pre> <p>Whether the state is inline. Inline means the first indent and indexing is inherited from the previous non-inline state.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterState.is_start","title":"is_start  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_start: bool = True\n</code></pre> <p>Whether the state is at the start of the scope.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterState.role","title":"role  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>role: Optional[MessageRole] = None\n</code></pre> <p>The role to be used for the message.</p>"},{"location":"reference/core/printer/#appl.core.printer.PrinterState.separator","title":"separator  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>separator: str = '\\n'\n</code></pre> <p>The separator to be used between texts.</p>"},{"location":"reference/core/printer/#appl.core.printer.PromptPrinter","title":"PromptPrinter","text":"<pre><code>PromptPrinter(\n    states: Optional[List[PrinterState]] = None,\n    is_newline: bool = True,\n)\n</code></pre> <p>A class to print prompt records as conversation.</p> <p>The printer maintains a stack of printer states about the current role, separator, indexing, and indentation.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def __init__(\n    self, states: Optional[List[PrinterState]] = None, is_newline: bool = True\n) -&gt; None:\n    \"\"\"Initialize the prompt printer.\"\"\"\n    if states is None:\n        states = [PrinterState()]\n    self._states = states\n    self._is_newline = is_newline\n</code></pre>"},{"location":"reference/core/printer/#appl.core.printer.PromptPrinter.states","title":"states  <code>property</code>","text":"<pre><code>states: List[PrinterState]\n</code></pre> <p>The stack of printer states.</p>"},{"location":"reference/core/printer/#appl.core.printer.PromptPrinter.pop","title":"pop","text":"<pre><code>pop() -&gt; None\n</code></pre> <p>Pop the last printer state from the stack.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def pop(self) -&gt; None:\n    \"\"\"Pop the last printer state from the stack.\"\"\"\n    if len(self._states) == 1:\n        raise ValueError(\"Cannot pop the first state.\")\n    self._states.pop()\n</code></pre>"},{"location":"reference/core/printer/#appl.core.printer.PromptPrinter.push","title":"push","text":"<pre><code>push(data: PrinterPush) -&gt; None\n</code></pre> <p>Push a new printer state to the stack.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def push(self, data: PrinterPush) -&gt; None:\n    \"\"\"Push a new printer state to the stack.\"\"\"\n    self._push(**data.__dict__)\n</code></pre>"},{"location":"reference/core/printer/#appl.core.printer.PromptRecords","title":"PromptRecords","text":"<pre><code>PromptRecords()\n</code></pre> <p>A class represents a list of prompt records.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the prompt records.\"\"\"\n    self._records: List[RecordType] = []\n</code></pre>"},{"location":"reference/core/printer/#appl.core.printer.PromptRecords.records","title":"records  <code>property</code>","text":"<pre><code>records: List[RecordType]\n</code></pre> <p>The list of records.</p>"},{"location":"reference/core/printer/#appl.core.printer.PromptRecords.as_convo","title":"as_convo","text":"<pre><code>as_convo() -&gt; Conversation\n</code></pre> <p>Convert the prompt records to a conversation.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def as_convo(self) -&gt; Conversation:\n    \"\"\"Convert the prompt records to a conversation.\"\"\"\n    return PromptPrinter()(self)\n</code></pre>"},{"location":"reference/core/printer/#appl.core.printer.PromptRecords.copy","title":"copy","text":"<pre><code>copy() -&gt; 'PromptRecords'\n</code></pre> <p>Copy the prompt records.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def copy(self) -&gt; \"PromptRecords\":\n    \"\"\"Copy the prompt records.\"\"\"\n    return copy.deepcopy(self)\n</code></pre>"},{"location":"reference/core/printer/#appl.core.printer.PromptRecords.extend","title":"extend","text":"<pre><code>extend(record: 'PromptRecords') -&gt; None\n</code></pre> <p>Extend the prompt records with another prompt records.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def extend(self, record: \"PromptRecords\") -&gt; None:\n    \"\"\"Extend the prompt records with another prompt records.\"\"\"\n    self._records.extend(record._records)\n</code></pre>"},{"location":"reference/core/printer/#appl.core.printer.PromptRecords.record","title":"record","text":"<pre><code>record(record: Union[str, RecordType]) -&gt; None\n</code></pre> <p>Record a string, message, image, printer push or printer pop.</p> Source code in <code>src\\appl\\core\\printer.py</code> <pre><code>def record(self, record: Union[str, RecordType]) -&gt; None:\n    \"\"\"Record a string, message, image, printer push or printer pop.\"\"\"\n    if isinstance(record, str):  # compatible to str\n        record = StringFuture(record)\n    if (\n        isinstance(record, StringFuture)\n        or isinstance(record, Image)\n        or isinstance(record, BaseMessage)\n        or isinstance(record, PrinterPush)\n        or isinstance(record, PrinterPop)\n    ):\n        self._records.append(record)\n    else:\n        raise ValueError(\"Can only record Message, PrinterPush or PrinterPop\")\n</code></pre>"},{"location":"reference/core/response/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> response","text":""},{"location":"reference/core/response/#appl.core.response","title":"response","text":""},{"location":"reference/core/response/#appl.core.response.CompletionResponse","title":"CompletionResponse","text":"<p>             Bases: <code>BaseModel</code></p> <p>A class wrapping the response from the LLM model.</p> <p>For a streaming response, it tracks the chunks of the response and builds the complete response when the streaming is finished.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.chunks","title":"chunks  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>chunks: List[Union[ModelResponse, ChatCompletionChunk]] = (\n    Field(\n        [],\n        description=\"The chunks of the response when streaming\",\n    )\n)\n</code></pre> <p>The chunks of the response when streaming.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.complete_response","title":"complete_response  <code>property</code>","text":"<pre><code>complete_response: Union[ModelResponse, ChatCompletion]\n</code></pre> <p>The complete response from the model. This will block until the response is finished.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.cost","title":"cost  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost: Optional[float] = Field(\n    None, description=\"The cost of the completion\"\n)\n</code></pre> <p>The cost of the completion.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.is_finished","title":"is_finished  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_finished: bool = Field(\n    False,\n    description=\"Whether the response stream is finished\",\n)\n</code></pre> <p>Whether the response stream is finished.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.is_stream","title":"is_stream  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_stream: bool = Field(\n    False, description=\"Whether the response is a stream\"\n)\n</code></pre> <p>Whether the response is a stream.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.message","title":"message  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>message: Optional[str] = Field(\n    None,\n    description=\"The top-choice message from the completion\",\n)\n</code></pre> <p>The top-choice message from the completion.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.post_finish_callbacks","title":"post_finish_callbacks  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>post_finish_callbacks: List[Callable] = Field(\n    [], description=\"The post finish callbacks\"\n)\n</code></pre> <p>The post finish callbacks.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.raw_response","title":"raw_response  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_response: Any = Field(\n    None, description=\"The raw response from the model\"\n)\n</code></pre> <p>The raw response from the model.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.response_model","title":"response_model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>response_model: Any = Field(\n    None, description=\"The given response model\"\n)\n</code></pre> <p>The given response model.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.response_obj","title":"response_obj  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>response_obj: Any = Field(\n    None,\n    description=\"The response object of response model, could be a stream\",\n)\n</code></pre> <p>The response object of response model, could be a stream.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.results","title":"results  <code>property</code>","text":"<pre><code>results: Any\n</code></pre> <p>The results of the response.</p> <p>Returns:</p> <ul> <li> <code>message</code> (            <code>str</code> )        \u2013          <p>The message if the response is a text completion.</p> </li> <li> <code>tool_calls</code> (            <code>List[ToolCall]</code> )        \u2013          <p>The tool calls if the response is a list of tool calls.</p> </li> <li> <code>response_obj</code> (            <code>Any</code> )        \u2013          <p>The object if the response is a response object.</p> </li> </ul>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.tool_calls","title":"tool_calls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tool_calls: List[ToolCall] = Field(\n    [], description=\"The tool calls\"\n)\n</code></pre> <p>The tool calls.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.type","title":"type  <code>property</code>","text":"<pre><code>type: ResponseType\n</code></pre> <p>The type of the response.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.usage","title":"usage  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>usage: Optional[CompletionUsage] = Field(\n    None, description=\"The usage of the completion\"\n)\n</code></pre> <p>The usage of the completion.</p>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.register_post_finish_callback","title":"register_post_finish_callback","text":"<pre><code>register_post_finish_callback(callback: Callable) -&gt; None\n</code></pre> <p>Register a post finish callback.</p> <p>The callback will be called after the response is finished.</p> Source code in <code>src\\appl\\core\\response.py</code> <pre><code>def register_post_finish_callback(self, callback: Callable) -&gt; None:\n    \"\"\"Register a post finish callback.\n\n    The callback will be called after the response is finished.\n    \"\"\"\n    if self.is_finished:\n        callback(self)\n    else:\n        self.post_finish_callbacks.append(callback)\n</code></pre>"},{"location":"reference/core/response/#appl.core.response.CompletionResponse.streaming","title":"streaming","text":"<pre><code>streaming(display: bool = True) -&gt; CompletionResponse\n</code></pre> <p>Stream the response object and finish the response.</p> Source code in <code>src\\appl\\core\\response.py</code> <pre><code>def streaming(self, display: bool = True) -&gt; \"CompletionResponse\":\n    \"\"\"Stream the response object and finish the response.\"\"\"\n    if not self.is_stream:\n        raise ValueError(\"Cannot iterate over non-streaming response\")\n    if self.is_finished:\n        return self\n    if self.response_obj is not None:\n        if display:\n            interval = configs.getattrs(\"settings.logging.display.stream_interval\")\n            pbar = tqdm(self.response_obj, desc=\"Streaming\", dynamic_ncols=True)\n            current_time = time.time()\n            for chunk in pbar:\n                if time.time() - current_time &gt; interval:\n                    current_time = time.time()\n                    pbar.set_description(str(chunk.model_dump()))\n            logger.info(\n                f\"Response object streaming finished with:\\n{chunk.model_dump()}\"\n            )\n            pbar.close()\n        else:\n            for chunk in self.response_obj:\n                pass\n        self.response_obj = chunk.model_dump()\n    else:\n        if display:\n            print(\"===== APPL BEGIN STREAMING =====\", flush=True)\n            suffix = \"\"\n            for chunk in iter(self):\n                suffix = self._print_chunk(chunk, suffix)\n            print(suffix, flush=True)\n            print(\"===== APPL END STREAMING =====\", flush=True)\n        else:\n            for chunk in iter(self):\n                pass\n    return self\n</code></pre>"},{"location":"reference/core/runtime/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> runtime","text":""},{"location":"reference/core/runtime/#appl.core.runtime","title":"runtime","text":"<p>helper functions for runtime execution within the compiled function.</p>"},{"location":"reference/core/runtime/#appl.core.runtime.appl_execute","title":"appl_execute","text":"<pre><code>appl_execute(\n    s: Any, _ctx: PromptContext = PromptContext()\n) -&gt; None\n</code></pre> <p>Interact with the prompt context using the given value.</p> Source code in <code>src\\appl\\core\\runtime.py</code> <pre><code>def appl_execute(\n    s: Any,\n    _ctx: PromptContext = PromptContext(),\n) -&gt; None:\n    \"\"\"Interact with the prompt context using the given value.\"\"\"\n    if s is None:\n        return\n    if isinstance(s, str):\n        if _ctx._exclude_first_str and _ctx._is_first_str:\n            logger.debug(f'The first string \"\"\"{s}\"\"\" is excluded from prompt.')\n        else:\n            _ctx.add_string(StringFuture(s))\n        _ctx._is_first_str = False\n    elif isinstance(s, StringFuture):\n        _ctx.add_string(s)\n    elif isinstance(s, PromptRecords):\n        _ctx.add_records(s)\n    elif isinstance(s, BaseMessage):\n        _ctx.add_message(s)\n    elif isinstance(s, Image):\n        _ctx.add_image(s)\n    elif isinstance(s, Generation):\n        appl_execute(s.as_prompt(), _ctx)\n    elif isinstance(s, Promptable):\n        # recursively apply\n        appl_execute(promptify(s), _ctx)\n    elif isinstance(s, Sequence):\n        # sequence of items, recursively apply\n        for x in s:\n            appl_execute(x, _ctx)\n    elif isinstance(s, Namespace):  # for advanced usage only\n        logger.info(f\"updating context variables using the namespace: {s}\")\n        _ctx._set_vars(s)\n    else:\n        logger.warning(f\"Cannot convert {s} of type {type(s)} to prompt, ignore.\")\n</code></pre>"},{"location":"reference/core/runtime/#appl.core.runtime.appl_format","title":"appl_format","text":"<pre><code>appl_format(\n    value: Any, format_spec: str = \"\", conversion: int = -1\n) -&gt; StringFuture\n</code></pre> <p>Create a StringFuture object that represents the formatted string.</p> Source code in <code>src\\appl\\core\\runtime.py</code> <pre><code>def appl_format(\n    value: Any, format_spec: str = \"\", conversion: int = -1\n) -&gt; StringFuture:\n    \"\"\"Create a StringFuture object that represents the formatted string.\"\"\"\n    if conversion &gt;= 0:\n        conversion_func: Dict[str, Callable] = {\"s\": str, \"r\": repr, \"a\": ascii}\n        if (c := chr(conversion)) not in conversion_func:\n            raise ValueError(f\"Invalid conversion character: {c}\")\n        value = StringFuture(CallFuture(conversion_func[c], value))\n\n    return StringFuture(CallFuture(format, value, format_spec))\n</code></pre>"},{"location":"reference/core/runtime/#appl.core.runtime.appl_with_ctx","title":"appl_with_ctx","text":"<pre><code>appl_with_ctx(\n    *args: Any,\n    _func: Callable,\n    _ctx: PromptContext = PromptContext(),\n    _globals: Any = None,\n    _locals: Any = None,\n    **kwargs: Any\n) -&gt; Any\n</code></pre> <p>Forward context to prompt functions.</p> Source code in <code>src\\appl\\core\\runtime.py</code> <pre><code>def appl_with_ctx(\n    *args: Any,\n    _func: Callable,\n    _ctx: PromptContext = PromptContext(),\n    _globals: Any = None,\n    _locals: Any = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Forward context to prompt functions.\"\"\"\n    if _func is globals:\n        # use the globals when calling the function\n        return _globals\n    if _func is locals:\n        # use the locals when calling the function\n        return _locals\n    if _func in (exec, eval):\n        # fix the globals and locals for exec and eval\n        if len(args) &lt; 2 and \"globals\" not in kwargs:\n            args = args + (_globals,)\n        elif len(args) &lt; 3 and \"locals\" not in kwargs:\n            args = args + (_locals,)\n    if getattr(_func, \"__need_ctx__\", False):\n        kwargs[\"_ctx\"] = _ctx  # add the context to the kwargs\n    return _func(*args, **kwargs)\n</code></pre>"},{"location":"reference/core/server/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> server","text":""},{"location":"reference/core/server/#appl.core.server","title":"server","text":""},{"location":"reference/core/server/#appl.core.server.BaseServer","title":"BaseServer","text":"<p>             Bases: <code>ABC</code></p> <p>The base class for all servers.</p> <p>Servers are responsible for communicating with the underlying model.</p>"},{"location":"reference/core/server/#appl.core.server.BaseServer.model_name","title":"model_name  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>model_name: str\n</code></pre> <p>The name of the model used by the server.</p>"},{"location":"reference/core/server/#appl.core.server.BaseServer.close","title":"close  <code>abstractmethod</code>","text":"<pre><code>close()\n</code></pre> <p>Close the server.</p> Source code in <code>src\\appl\\core\\server.py</code> <pre><code>@abstractmethod\ndef close(self):\n    \"\"\"Close the server.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/core/server/#appl.core.server.BaseServer.create","title":"create","text":"<pre><code>create(\n    args: GenArgs, gen_id: str, **kwargs: Any\n) -&gt; CompletionResponse\n</code></pre> <p>Create a CompletionResponse from the model with given arguments.</p> <p>Parameters:</p> <ul> <li> <code>args</code>             (<code>GenArgs</code>)         \u2013          <p>The arguments for generating the response</p> </li> <li> <code>gen_id</code>             (<code>str</code>)         \u2013          <p>The ID of the generation</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments</p> </li> </ul> <p>Returns:     The response from the model.</p> Source code in <code>src\\appl\\core\\server.py</code> <pre><code>def create(self, args: GenArgs, gen_id: str, **kwargs: Any) -&gt; CompletionResponse:\n    \"\"\"Create a CompletionResponse from the model with given arguments.\n\n    Args:\n        args: The arguments for generating the response\n        gen_id: The ID of the generation\n        **kwargs: Additional keyword arguments\n    Returns:\n        The response from the model.\n    \"\"\"\n    log_llm_call_args = configs.getattrs(\"settings.logging.display.llm_call_args\")\n    log_llm_response = configs.getattrs(\"settings.logging.display.llm_response\")\n\n    create_args = self._get_create_args(args, **kwargs)\n    if log_llm_call_args:\n        logger.info(f\"Call generation [{gen_id}] with args: {create_args}\")\n\n    results = self._create(gen_id=gen_id, **create_args)\n    if log_llm_response:\n        logger.info(f\"Generation [{gen_id}] results: {results}\")\n    if results.cost:\n        if \"mock_response\" in create_args:\n            if configs.getattrs(\"settings.logging.display.llm_cost\"):\n                logger.info(\n                    f\"Mock response, estimated cost for real request: {results.cost:.4f}\"\n                )\n        else:\n            _update_cost(\n                self.model_name,\n                results.cost,\n                getattr(self, \"_cost_currency\", \"USD\"),\n            )\n\n    dump_args = create_args.copy()\n    if \"response_model\" in dump_args:\n        v = dump_args[\"response_model\"]\n        if issubclass(v, BaseModel):\n            dump_args[\"response_model\"] = json.dumps(\n                v.model_json_schema(), indent=4\n            )\n\n    def trace_gen_response(response: CompletionResponse) -&gt; None:\n        add_to_trace(\n            GenerationResponseEvent(name=gen_id, args=dump_args, ret=str(response))\n        )\n\n    results.register_post_finish_callback(trace_gen_response)\n    return results\n</code></pre>"},{"location":"reference/core/server/#appl.core.server.DummyServer","title":"DummyServer","text":"<p>             Bases: <code>BaseServer</code></p> <p>A dummy server for testing purposes.</p>"},{"location":"reference/core/server/#appl.core.server.DummyServer.create","title":"create","text":"<pre><code>create(\n    args: GenArgs, gen_id: str, **kwargs: Any\n) -&gt; CompletionResponse\n</code></pre> <p>Create a CompletionResponse from the model with given arguments.</p> <p>Parameters:</p> <ul> <li> <code>args</code>             (<code>GenArgs</code>)         \u2013          <p>The arguments for generating the response</p> </li> <li> <code>gen_id</code>             (<code>str</code>)         \u2013          <p>The ID of the generation</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments</p> </li> </ul> <p>Returns:     The response from the model.</p> Source code in <code>src\\appl\\core\\server.py</code> <pre><code>def create(self, args: GenArgs, gen_id: str, **kwargs: Any) -&gt; CompletionResponse:\n    \"\"\"Create a CompletionResponse from the model with given arguments.\n\n    Args:\n        args: The arguments for generating the response\n        gen_id: The ID of the generation\n        **kwargs: Additional keyword arguments\n    Returns:\n        The response from the model.\n    \"\"\"\n    log_llm_call_args = configs.getattrs(\"settings.logging.display.llm_call_args\")\n    log_llm_response = configs.getattrs(\"settings.logging.display.llm_response\")\n\n    create_args = self._get_create_args(args, **kwargs)\n    if log_llm_call_args:\n        logger.info(f\"Call generation [{gen_id}] with args: {create_args}\")\n\n    results = self._create(gen_id=gen_id, **create_args)\n    if log_llm_response:\n        logger.info(f\"Generation [{gen_id}] results: {results}\")\n    if results.cost:\n        if \"mock_response\" in create_args:\n            if configs.getattrs(\"settings.logging.display.llm_cost\"):\n                logger.info(\n                    f\"Mock response, estimated cost for real request: {results.cost:.4f}\"\n                )\n        else:\n            _update_cost(\n                self.model_name,\n                results.cost,\n                getattr(self, \"_cost_currency\", \"USD\"),\n            )\n\n    dump_args = create_args.copy()\n    if \"response_model\" in dump_args:\n        v = dump_args[\"response_model\"]\n        if issubclass(v, BaseModel):\n            dump_args[\"response_model\"] = json.dumps(\n                v.model_json_schema(), indent=4\n            )\n\n    def trace_gen_response(response: CompletionResponse) -&gt; None:\n        add_to_trace(\n            GenerationResponseEvent(name=gen_id, args=dump_args, ret=str(response))\n        )\n\n    results.register_post_finish_callback(trace_gen_response)\n    return results\n</code></pre>"},{"location":"reference/core/server/#appl.core.server.GenArgs","title":"GenArgs","text":"<p>             Bases: <code>BaseModel</code></p> <p>Common arguments for generating a response from a model.</p>"},{"location":"reference/core/server/#appl.core.server.GenArgs.preprocess","title":"preprocess","text":"<pre><code>preprocess(\n    convert_func: Callable, is_openai: bool = False\n) -&gt; dict\n</code></pre> <p>Convert the GenArgs into a dictionary for creating the response.</p> Source code in <code>src\\appl\\core\\server.py</code> <pre><code>def preprocess(self, convert_func: Callable, is_openai: bool = False) -&gt; dict:\n    \"\"\"Convert the GenArgs into a dictionary for creating the response.\"\"\"\n    # build dict, filter out the None values\n    args = self.model_dump(exclude_none=True)\n\n    # messages\n    args[\"messages\"] = convert_func(self.messages)\n\n    # format the tool\n    tools = self.tools\n    tool_format = args.pop(\"tool_format\")\n    if len(tools):\n        if tool_format == \"auto\":\n            tool_format = \"openai\" if is_openai else \"str\"\n        formatted_tools = []\n        for tool in tools:\n            tool_str: Any = None\n            if tool_format == \"openai\":\n                tool_str = tool.openai_schema\n            else:  # TODO: supports more formats\n                tool_str = str(tool)\n            formatted_tools.append(tool_str)\n        args[\"tools\"] = formatted_tools\n    else:\n        args.pop(\"tools\", None)\n    return args\n</code></pre>"},{"location":"reference/core/tool/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> tool","text":""},{"location":"reference/core/tool/#appl.core.tool","title":"tool","text":""},{"location":"reference/core/tool/#appl.core.tool.BaseTool","title":"BaseTool","text":"<pre><code>BaseTool(func: Callable, **predefined: Any)\n</code></pre> <p>             Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>The base class for a Tool.</p> Source code in <code>src\\appl\\core\\tool.py</code> <pre><code>def __init__(self, func: Callable, **predefined: Any):\n    \"\"\"Create a tool from a function.\"\"\"\n    name = func.__name__\n    sig = inspect.signature(func)\n    doc = func.__doc__\n    super().__init__(name=name, **self.parse_data(sig, doc, predefined))\n    self._predefined = predefined\n    self._func = func\n    self.__name__ = name\n    self.__signature__ = sig  # type: ignore\n    self.__doc__ = doc  # overwrite the doc string\n</code></pre>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.examples","title":"examples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>examples: List[str] = Field(\n    [], description=\"The examples of the Tool\"\n)\n</code></pre> <p>The examples of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.info","title":"info  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>info: Dict = Field(\n    {}, description=\"Additional information of the Tool\"\n)\n</code></pre> <p>Additional information of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.long_desc","title":"long_desc  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>long_desc: str = Field(\n    \"\", description=\"The long description of the Tool\"\n)\n</code></pre> <p>The long description of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: str = Field(..., description='The name of the Tool')\n</code></pre> <p>The name of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.openai_schema","title":"openai_schema  <code>property</code>","text":"<pre><code>openai_schema: dict\n</code></pre> <p>Get the OpenAI schema of the tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.params","title":"params  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>params: type[BaseModel] = Field(\n    ..., description=\"The parameters of the Tool\"\n)\n</code></pre> <p>The parameters of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.raises","title":"raises  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raises: List[Dict[str, Optional[str]]] = Field(\n    [], description=\"The exceptions raised by the Tool\"\n)\n</code></pre> <p>The exceptions raised by the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.returns","title":"returns  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>returns: type[BaseModel] = Field(\n    ..., description=\"The return of the Tool\"\n)\n</code></pre> <p>The return of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.short_desc","title":"short_desc  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>short_desc: str = Field(\n    \"\", description=\"The short description of the Tool\"\n)\n</code></pre> <p>The short description of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.parse_data","title":"parse_data  <code>classmethod</code>","text":"<pre><code>parse_data(\n    sig: Signature,\n    docstring: Optional[str],\n    predefined: Dict[str, Any],\n) -&gt; Dict[str, Any]\n</code></pre> <p>Parse data from the signature and docstring of a function.</p> Source code in <code>src\\appl\\core\\tool.py</code> <pre><code>@classmethod\ndef parse_data(\n    cls, sig: Signature, docstring: Optional[str], predefined: Dict[str, Any]\n) -&gt; Dict[str, Any]:\n    \"\"\"Parse data from the signature and docstring of a function.\"\"\"\n    doc = parse(docstring or \"\")\n    data: Dict[str, Any] = {\n        \"short_desc\": doc.short_description or \"\",\n        \"long_desc\": doc.long_description or \"\",\n    }\n\n    # build params\n    params = {}\n    doc_param = {p.arg_name: p for p in doc.params}\n    for name, param in sig.parameters.items():\n        anno = param.annotation\n        default = param.default\n\n        if default is param.empty:\n            default = ...  # required\n        if name in doc_param:\n            # fill in desc for the param\n            default = Field(default, description=doc_param[name].description)\n            # fill in type annotation if not annotated in the function\n            if (anno is param.empty) and (doc_param[name].type_name is not None):\n                # use type annotation from docstring\n                anno = doc_param[name].type_name\n        # replace empty annotation with Any\n        if anno is param.empty:\n            anno = Any\n        if name not in predefined:\n            params[name] = (anno, default)\n    data[\"params\"] = create_model(\"parameters\", **params)  # type: ignore\n\n    # build returns\n    anno = sig.return_annotation\n    if anno is sig.empty:\n        if (doc.returns is not None) and (doc.returns.type_name is not None):\n            # use type annotation from docstring\n            anno = doc.returns.type_name\n        else:\n            anno = Any\n    default = ...  # required\n    if doc.returns is not None:\n        # fill in desc for the return\n        default = Field(..., description=doc.returns.description)\n    data[\"returns\"] = create_model(\"returns\", returns=(anno, default))\n\n    # build raises\n    data[\"raises\"] = [\n        {\"type\": exc.type_name, \"desc\": exc.description} for exc in doc.raises\n    ]\n\n    # build examples\n    data[\"examples\"] = doc.examples\n    return data\n</code></pre>"},{"location":"reference/core/tool/#appl.core.tool.BaseTool.to_str","title":"to_str","text":"<pre><code>to_str() -&gt; str\n</code></pre> <p>Represent the tool as a string.</p> Source code in <code>src\\appl\\core\\tool.py</code> <pre><code>def to_str(self) -&gt; str:\n    \"\"\"Represent the tool as a string.\"\"\"\n    s = f\"def {self.name}{self.__signature__}:\\n\"\n    s += f'    \"\"\"{self.__doc__}\"\"\"'\n    return s\n</code></pre>"},{"location":"reference/core/tool/#appl.core.tool.Tool","title":"Tool","text":"<pre><code>Tool(\n    func: Callable,\n    use_short_desc: bool = False,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>BaseTool</code></p> <p>The Tool class that can be called by LLMs.</p> <p>Parameters:</p> <ul> <li> <code>func</code>             (<code>Callable</code>)         \u2013          <p>The function to create the tool from.</p> </li> <li> <code>use_short_desc</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to use the short description instead of the full description.</p> </li> <li> <code>kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional arguments for the tool.</p> </li> </ul> Source code in <code>src\\appl\\core\\tool.py</code> <pre><code>def __init__(self, func: Callable, use_short_desc: bool = False, **kwargs: Any):\n    \"\"\"Create a tool from a function.\n\n    Args:\n        func: The function to create the tool from.\n        use_short_desc:\n            Whether to use the short description instead of the full description.\n        kwargs: Additional arguments for the tool.\n    \"\"\"\n    super().__init__(func=func, **kwargs)\n    self._use_short_desc = use_short_desc\n</code></pre>"},{"location":"reference/core/tool/#appl.core.tool.Tool.examples","title":"examples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>examples: List[str] = Field(\n    [], description=\"The examples of the Tool\"\n)\n</code></pre> <p>The examples of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.Tool.info","title":"info  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>info: Dict = Field(\n    {}, description=\"Additional information of the Tool\"\n)\n</code></pre> <p>Additional information of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.Tool.long_desc","title":"long_desc  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>long_desc: str = Field(\n    \"\", description=\"The long description of the Tool\"\n)\n</code></pre> <p>The long description of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.Tool.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: str = Field(..., description='The name of the Tool')\n</code></pre> <p>The name of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.Tool.openai_schema","title":"openai_schema  <code>property</code>","text":"<pre><code>openai_schema: dict\n</code></pre> <p>Get the OpenAI schema of the tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.Tool.params","title":"params  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>params: type[BaseModel] = Field(\n    ..., description=\"The parameters of the Tool\"\n)\n</code></pre> <p>The parameters of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.Tool.raises","title":"raises  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raises: List[Dict[str, Optional[str]]] = Field(\n    [], description=\"The exceptions raised by the Tool\"\n)\n</code></pre> <p>The exceptions raised by the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.Tool.returns","title":"returns  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>returns: type[BaseModel] = Field(\n    ..., description=\"The return of the Tool\"\n)\n</code></pre> <p>The return of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.Tool.short_desc","title":"short_desc  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>short_desc: str = Field(\n    \"\", description=\"The short description of the Tool\"\n)\n</code></pre> <p>The short description of the Tool.</p>"},{"location":"reference/core/tool/#appl.core.tool.Tool.parse_data","title":"parse_data  <code>classmethod</code>","text":"<pre><code>parse_data(\n    sig: Signature,\n    docstring: Optional[str],\n    predefined: Dict[str, Any],\n) -&gt; Dict[str, Any]\n</code></pre> <p>Parse data from the signature and docstring of a function.</p> Source code in <code>src\\appl\\core\\tool.py</code> <pre><code>@classmethod\ndef parse_data(\n    cls, sig: Signature, docstring: Optional[str], predefined: Dict[str, Any]\n) -&gt; Dict[str, Any]:\n    \"\"\"Parse data from the signature and docstring of a function.\"\"\"\n    doc = parse(docstring or \"\")\n    data: Dict[str, Any] = {\n        \"short_desc\": doc.short_description or \"\",\n        \"long_desc\": doc.long_description or \"\",\n    }\n\n    # build params\n    params = {}\n    doc_param = {p.arg_name: p for p in doc.params}\n    for name, param in sig.parameters.items():\n        anno = param.annotation\n        default = param.default\n\n        if default is param.empty:\n            default = ...  # required\n        if name in doc_param:\n            # fill in desc for the param\n            default = Field(default, description=doc_param[name].description)\n            # fill in type annotation if not annotated in the function\n            if (anno is param.empty) and (doc_param[name].type_name is not None):\n                # use type annotation from docstring\n                anno = doc_param[name].type_name\n        # replace empty annotation with Any\n        if anno is param.empty:\n            anno = Any\n        if name not in predefined:\n            params[name] = (anno, default)\n    data[\"params\"] = create_model(\"parameters\", **params)  # type: ignore\n\n    # build returns\n    anno = sig.return_annotation\n    if anno is sig.empty:\n        if (doc.returns is not None) and (doc.returns.type_name is not None):\n            # use type annotation from docstring\n            anno = doc.returns.type_name\n        else:\n            anno = Any\n    default = ...  # required\n    if doc.returns is not None:\n        # fill in desc for the return\n        default = Field(..., description=doc.returns.description)\n    data[\"returns\"] = create_model(\"returns\", returns=(anno, default))\n\n    # build raises\n    data[\"raises\"] = [\n        {\"type\": exc.type_name, \"desc\": exc.description} for exc in doc.raises\n    ]\n\n    # build examples\n    data[\"examples\"] = doc.examples\n    return data\n</code></pre>"},{"location":"reference/core/tool/#appl.core.tool.Tool.to_str","title":"to_str","text":"<pre><code>to_str() -&gt; str\n</code></pre> <p>Represent the tool as a string.</p> Source code in <code>src\\appl\\core\\tool.py</code> <pre><code>def to_str(self) -&gt; str:\n    \"\"\"Represent the tool as a string.\"\"\"\n    s = f\"def {self.name}{self.__signature__}:\\n\"\n    s += f'    \"\"\"{self.__doc__}\"\"\"'\n    return s\n</code></pre>"},{"location":"reference/core/tool/#appl.core.tool.ToolCall","title":"ToolCall","text":"<p>             Bases: <code>BaseModel</code></p> <p>The class representing a tool call.</p>"},{"location":"reference/core/tool/#appl.core.tool.ToolCall.args","title":"args  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>args: str = Field(\n    ...,\n    description=\"The arguments to call the function with.\",\n)\n</code></pre> <p>The arguments to call the function with.</p>"},{"location":"reference/core/tool/#appl.core.tool.ToolCall.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: str = Field(..., description=\"The ID of the tool call.\")\n</code></pre> <p>The ID of the tool call.</p>"},{"location":"reference/core/tool/#appl.core.tool.ToolCall.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: str = Field(\n    ..., description=\"The name of the function to call.\"\n)\n</code></pre> <p>The name of the function to call.</p>"},{"location":"reference/core/tool/#appl.core.tool.ToolCall.from_openai_tool_call","title":"from_openai_tool_call  <code>classmethod</code>","text":"<pre><code>from_openai_tool_call(\n    call: ChatCompletionMessageToolCall,\n) -&gt; ToolCall\n</code></pre> <p>Create a ToolCall from an OpenAI tool call.</p> Source code in <code>src\\appl\\core\\tool.py</code> <pre><code>@classmethod\ndef from_openai_tool_call(cls, call: ChatCompletionMessageToolCall) -&gt; \"ToolCall\":\n    \"\"\"Create a ToolCall from an OpenAI tool call.\"\"\"\n    return cls(\n        id=call.id,\n        name=call.function.name,\n        args=call.function.arguments,\n    )\n</code></pre>"},{"location":"reference/core/tool/#appl.core.tool.ToolCall.get_dict","title":"get_dict","text":"<pre><code>get_dict()\n</code></pre> <p>Get the OpenAI format dictionary representation of the tool call.</p> Source code in <code>src\\appl\\core\\tool.py</code> <pre><code>def get_dict(self):\n    \"\"\"Get the OpenAI format dictionary representation of the tool call.\"\"\"\n    return {\n        \"id\": self.id,\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": self.name,\n            \"arguments\": self.args,\n        },\n    }\n</code></pre>"},{"location":"reference/core/trace/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> trace","text":""},{"location":"reference/core/trace/#appl.core.trace","title":"trace","text":""},{"location":"reference/core/trace/#appl.core.trace.CompletionRequestEvent","title":"CompletionRequestEvent","text":"<p>             Bases: <code>TraceEventBase</code></p> <p>A class representing a completion request event.</p>"},{"location":"reference/core/trace/#appl.core.trace.CompletionResponseEvent","title":"CompletionResponseEvent","text":"<p>             Bases: <code>TraceEventBase</code></p> <p>A class representing a completion response event.</p>"},{"location":"reference/core/trace/#appl.core.trace.CompletionResponseEvent.args","title":"args  <code>instance-attribute</code>","text":"<pre><code>args: Dict\n</code></pre> <p>The arguments of the completion call.</p>"},{"location":"reference/core/trace/#appl.core.trace.CompletionResponseEvent.cost","title":"cost  <code>instance-attribute</code>","text":"<pre><code>cost: Optional[float]\n</code></pre> <p>The api cost of the completion call.</p>"},{"location":"reference/core/trace/#appl.core.trace.CompletionResponseEvent.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the event.</p>"},{"location":"reference/core/trace/#appl.core.trace.CompletionResponseEvent.ret","title":"ret  <code>instance-attribute</code>","text":"<pre><code>ret: Any\n</code></pre> <p>The return value of the completion call.</p>"},{"location":"reference/core/trace/#appl.core.trace.CompletionResponseEvent.time_stamp","title":"time_stamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time_stamp: float = None\n</code></pre> <p>The time stamp of the event.</p>"},{"location":"reference/core/trace/#appl.core.trace.FunctionCallEvent","title":"FunctionCallEvent","text":"<p>             Bases: <code>TraceEventBase</code></p> <p>A class representing a function call event.</p>"},{"location":"reference/core/trace/#appl.core.trace.FunctionCallEvent.args","title":"args  <code>instance-attribute</code>","text":"<pre><code>args: Dict\n</code></pre> <p>The arguments of the function call.</p>"},{"location":"reference/core/trace/#appl.core.trace.FunctionCallEvent.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the event.</p>"},{"location":"reference/core/trace/#appl.core.trace.FunctionCallEvent.time_stamp","title":"time_stamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time_stamp: float = None\n</code></pre> <p>The time stamp of the event.</p>"},{"location":"reference/core/trace/#appl.core.trace.FunctionReturnEvent","title":"FunctionReturnEvent","text":"<p>             Bases: <code>TraceEventBase</code></p> <p>A class representing a function return event.</p>"},{"location":"reference/core/trace/#appl.core.trace.GenerationInitEvent","title":"GenerationInitEvent","text":"<p>             Bases: <code>TraceEventBase</code></p> <p>A class representing a generation init event.</p>"},{"location":"reference/core/trace/#appl.core.trace.GenerationResponseEvent","title":"GenerationResponseEvent","text":"<p>             Bases: <code>TraceEventBase</code></p> <p>A class representing a generation response event.</p>"},{"location":"reference/core/trace/#appl.core.trace.GenerationResponseEvent.args","title":"args  <code>instance-attribute</code>","text":"<pre><code>args: Dict\n</code></pre> <p>The arguments of the generation call.</p>"},{"location":"reference/core/trace/#appl.core.trace.GenerationResponseEvent.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the event.</p>"},{"location":"reference/core/trace/#appl.core.trace.GenerationResponseEvent.ret","title":"ret  <code>instance-attribute</code>","text":"<pre><code>ret: Any\n</code></pre> <p>The return value of the generation call.</p>"},{"location":"reference/core/trace/#appl.core.trace.GenerationResponseEvent.time_stamp","title":"time_stamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time_stamp: float = None\n</code></pre> <p>The time stamp of the event.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceEngineBase","title":"TraceEngineBase","text":"<p>             Bases: <code>ABC</code></p> <p>A base class for trace engines.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceEngineBase.events","title":"events  <code>property</code>","text":"<pre><code>events: List[TraceEventBase]\n</code></pre> <p>The list of events in the trace.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceEngineBase.min_timestamp","title":"min_timestamp  <code>cached</code> <code>property</code>","text":"<pre><code>min_timestamp: float\n</code></pre> <p>The minimum time stamp of the events in the trace.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceEngineBase.trace_nodes","title":"trace_nodes  <code>property</code>","text":"<pre><code>trace_nodes: Dict[str, TraceNode]\n</code></pre> <p>The dictionary of trace nodes in the trace.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceEngineBase.append","title":"append","text":"<pre><code>append(event: TraceEventBase) -&gt; None\n</code></pre> <p>Append an event to the trace.</p> Source code in <code>src\\appl\\core\\trace.py</code> <pre><code>@abstractmethod\ndef append(self, event: TraceEventBase) -&gt; None:\n    \"\"\"Append an event to the trace.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/core/trace/#appl.core.trace.TraceEngineBase.find_cache","title":"find_cache","text":"<pre><code>find_cache(name: str, args: Dict) -&gt; Any\n</code></pre> <p>Find a completion result in the cache.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the completion.</p> </li> <li> <code>args</code>             (<code>Dict</code>)         \u2013          <p>The arguments of the completion.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>The completion result if found, otherwise None.</p> </li> </ul> Source code in <code>src\\appl\\core\\trace.py</code> <pre><code>@abstractmethod\ndef find_cache(self, name: str, args: Dict) -&gt; Any:\n    \"\"\"Find a completion result in the cache.\n\n    Args:\n        name: The name of the completion.\n        args: The arguments of the completion.\n\n    Returns:\n        The completion result if found, otherwise None.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/core/trace/#appl.core.trace.TraceEventBase","title":"TraceEventBase","text":"<p>             Bases: <code>BaseModel</code></p> <p>A base class for trace events.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceEventBase.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the event.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceEventBase.time_stamp","title":"time_stamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time_stamp: float = None\n</code></pre> <p>The time stamp of the event.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode","title":"TraceNode","text":"<p>             Bases: <code>BaseModel</code></p> <p>The node of a trace tree containing information about trace events.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.args","title":"args  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>args: Optional[Dict] = None\n</code></pre> <p>The arguments of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.children","title":"children  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>children: List[TraceNode] = []\n</code></pre> <p>The children of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.end_time","title":"end_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_time: float = 0.0\n</code></pre> <p>The end time of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.info","title":"info  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>info: Dict = {}\n</code></pre> <p>The extra information of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.parent","title":"parent  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>parent: Optional[TraceNode] = None\n</code></pre> <p>The parent of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.ret","title":"ret  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ret: Any = None\n</code></pre> <p>The return value of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.runtime","title":"runtime  <code>property</code>","text":"<pre><code>runtime: float\n</code></pre> <p>The runtime of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.start_time","title":"start_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_time: float = 0.0\n</code></pre> <p>The start time of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TraceNode.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: str\n</code></pre> <p>The type of the trace node.</p>"},{"location":"reference/core/trace/#appl.core.trace.TracePrinterBase","title":"TracePrinterBase","text":"<p>             Bases: <code>ABC</code></p> <p>A base class for trace printers.</p>"},{"location":"reference/core/trace/#appl.core.trace.TracePrinterBase.print","title":"print","text":"<pre><code>print(\n    trace: TraceEngineBase,\n    meta_data: Optional[Configs] = None,\n) -&gt; Any\n</code></pre> <p>Print the trace.</p> Source code in <code>src\\appl\\core\\trace.py</code> <pre><code>@abstractmethod\ndef print(self, trace: TraceEngineBase, meta_data: Optional[Configs] = None) -&gt; Any:\n    \"\"\"Print the trace.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/core/trace/#appl.core.trace.add_to_trace","title":"add_to_trace","text":"<pre><code>add_to_trace(event: TraceEventBase) -&gt; None\n</code></pre> <p>Add an event to the trace.</p> Source code in <code>src\\appl\\core\\trace.py</code> <pre><code>def add_to_trace(event: TraceEventBase) -&gt; None:\n    \"\"\"Add an event to the trace.\"\"\"\n    if global_vars.trace_engine:\n        global_vars.trace_engine.append(event)\n</code></pre>"},{"location":"reference/core/trace/#appl.core.trace.find_in_cache","title":"find_in_cache","text":"<pre><code>find_in_cache(\n    name: str,\n    args: Dict,\n    cache: Optional[TraceEngineBase] = None,\n) -&gt; Any\n</code></pre> <p>Find a completion result in the cache.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the completion.</p> </li> <li> <code>args</code>             (<code>Dict</code>)         \u2013          <p>The arguments of the completion.</p> </li> <li> <code>cache</code>             (<code>Optional[TraceEngineBase]</code>, default:                 <code>None</code> )         \u2013          <p>The cache to search in. Defaults to the global resume cache.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>The completion result if found, otherwise None.</p> </li> </ul> Source code in <code>src\\appl\\core\\trace.py</code> <pre><code>def find_in_cache(\n    name: str, args: Dict, cache: Optional[TraceEngineBase] = None\n) -&gt; Any:\n    \"\"\"Find a completion result in the cache.\n\n    Args:\n        name: The name of the completion.\n        args: The arguments of the completion.\n        cache: The cache to search in. Defaults to the global resume cache.\n\n    Returns:\n        The completion result if found, otherwise None.\n    \"\"\"\n    if cache is None:\n        if \"resume_cache\" in global_vars:\n            cache = global_vars.resume_cache\n    if cache is not None:\n        return cache.find_cache(name, args)\n    return None\n</code></pre>"},{"location":"reference/core/promptable/","title":"Index","text":""},{"location":"reference/core/promptable/#appl.core.promptable","title":"promptable","text":""},{"location":"reference/core/promptable/base/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> base","text":""},{"location":"reference/core/promptable/base/#appl.core.promptable.base","title":"base","text":""},{"location":"reference/core/promptable/base/#appl.core.promptable.base.Promptable","title":"Promptable","text":"<p>             Bases: <code>ABC</code></p> <p>Interface for objects that can be converted to a prompt string.</p>"},{"location":"reference/core/promptable/base/#appl.core.promptable.base.promptify","title":"promptify","text":"<pre><code>promptify(obj: Any) -&gt; Any\n</code></pre> <p>Convert an object to a prompt object if it is promptable.</p> Source code in <code>src\\appl\\core\\promptable\\base.py</code> <pre><code>def promptify(obj: Any) -&gt; Any:\n    \"\"\"Convert an object to a prompt object if it is promptable.\"\"\"\n    if isinstance(obj, Promptable):\n        s = obj.__prompt__()\n        if isinstance(s, str):\n            s = StringFuture(s)\n        return s\n\n    return StringFuture(str(obj))\n</code></pre>"},{"location":"reference/core/promptable/definition/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> definition","text":""},{"location":"reference/core/promptable/definition/#appl.core.promptable.definition","title":"definition","text":""},{"location":"reference/core/promptable/definition/#appl.core.promptable.definition.BracketedDefinition","title":"BracketedDefinition","text":"<pre><code>BracketedDefinition(\n    name: Optional[String] = None,\n    desc: Optional[String] = None,\n    *,\n    sep: String = \": \",\n    details: Any = None,\n    fstr: Optional[str] = None,\n    var_name: Optional[str] = None\n)\n</code></pre> <p>             Bases: <code>Definition</code></p> <p>A Definition that is formatted with square brackets.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>Optional[String]</code>, default:                 <code>None</code> )         \u2013          <p>The name of the definition.</p> </li> <li> <code>desc</code>             (<code>Optional[String]</code>, default:                 <code>None</code> )         \u2013          <p>A description of the definition.</p> </li> <li> <code>sep</code>             (<code>String</code>, default:                 <code>': '</code> )         \u2013          <p>The separator between the name and description.</p> </li> <li> <code>details</code>             (<code>Any</code>, default:                 <code>None</code> )         \u2013          <p>Additional details about the definition.</p> </li> <li> <code>fstr</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The format string for the definition.</p> </li> <li> <code>var_name</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The name of the variable that the definition is stored in.</p> </li> </ul> Source code in <code>src\\appl\\core\\promptable\\definition.py</code> <pre><code>def __init__(\n    self,\n    name: Optional[String] = None,\n    desc: Optional[String] = None,\n    *,\n    sep: String = \": \",\n    details: Any = None,\n    fstr: Optional[str] = None,\n    var_name: Optional[str] = None,\n):\n    \"\"\"Initialize the Definition with the given name and description.\n\n    Args:\n        name: The name of the definition.\n        desc: A description of the definition.\n        sep: The separator between the name and description.\n        details: Additional details about the definition.\n        fstr: The format string for the definition.\n        var_name: The name of the variable that the definition is stored in.\n    \"\"\"\n    self.name = name or self.name or self.__doc__\n    if self.name is None:\n        raise ValueError(\"Name must be provided for Definition.\")\n\n    if desc is not None:\n        self.desc = desc\n    self.sep = sep\n    self.details = details\n    if fstr is not None:\n        self.fstr = fstr\n    self.var_name = var_name or self.name\n\n    self._forks.append(self)\n</code></pre>"},{"location":"reference/core/promptable/definition/#appl.core.promptable.definition.Definition","title":"Definition","text":"<pre><code>Definition(\n    name: Optional[String] = None,\n    desc: Optional[String] = None,\n    *,\n    sep: String = \": \",\n    details: Any = None,\n    fstr: Optional[str] = None,\n    var_name: Optional[str] = None\n)\n</code></pre> <p>             Bases: <code>Promptable</code>, <code>Formattable</code></p> <p>Represent a definition of a concept.</p> <p>Attributes:</p> <ul> <li> <code>fstr</code>             (<code>str</code>)         \u2013          <p>The format string for the definition.</p> </li> <li> <code>name</code>             (<code>Optional[String]</code>)         \u2013          <p>The name of the definition.</p> </li> <li> <code>desc</code>             (<code>String</code>)         \u2013          <p>A description of the definition.</p> </li> <li> <code>_forks</code>             (<code>List[Definition]</code>)         \u2013          <p>A list of all instances of this class.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>Optional[String]</code>, default:                 <code>None</code> )         \u2013          <p>The name of the definition.</p> </li> <li> <code>desc</code>             (<code>Optional[String]</code>, default:                 <code>None</code> )         \u2013          <p>A description of the definition.</p> </li> <li> <code>sep</code>             (<code>String</code>, default:                 <code>': '</code> )         \u2013          <p>The separator between the name and description.</p> </li> <li> <code>details</code>             (<code>Any</code>, default:                 <code>None</code> )         \u2013          <p>Additional details about the definition.</p> </li> <li> <code>fstr</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The format string for the definition.</p> </li> <li> <code>var_name</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The name of the variable that the definition is stored in.</p> </li> </ul> Source code in <code>src\\appl\\core\\promptable\\definition.py</code> <pre><code>def __init__(\n    self,\n    name: Optional[String] = None,\n    desc: Optional[String] = None,\n    *,\n    sep: String = \": \",\n    details: Any = None,\n    fstr: Optional[str] = None,\n    var_name: Optional[str] = None,\n):\n    \"\"\"Initialize the Definition with the given name and description.\n\n    Args:\n        name: The name of the definition.\n        desc: A description of the definition.\n        sep: The separator between the name and description.\n        details: Additional details about the definition.\n        fstr: The format string for the definition.\n        var_name: The name of the variable that the definition is stored in.\n    \"\"\"\n    self.name = name or self.name or self.__doc__\n    if self.name is None:\n        raise ValueError(\"Name must be provided for Definition.\")\n\n    if desc is not None:\n        self.desc = desc\n    self.sep = sep\n    self.details = details\n    if fstr is not None:\n        self.fstr = fstr\n    self.var_name = var_name or self.name\n\n    self._forks.append(self)\n</code></pre>"},{"location":"reference/core/promptable/definition/#appl.core.promptable.definition.define","title":"define","text":"<pre><code>define(def_name: str, format_str: str = '{}') -&gt; type\n</code></pre> <p>Create a new Definition subclass with the given name and format string.</p> Source code in <code>src\\appl\\core\\promptable\\definition.py</code> <pre><code>def define(def_name: str, format_str: str = \"{}\") -&gt; type:\n    \"\"\"Create a new Definition subclass with the given name and format string.\"\"\"\n\n    class CustomDef(Definition):\n        name = def_name\n        fstr = format_str\n\n    return CustomDef\n</code></pre>"},{"location":"reference/core/promptable/definition/#appl.core.promptable.definition.define_bracketed","title":"define_bracketed","text":"<pre><code>define_bracketed(def_name: str) -&gt; type\n</code></pre> <p>Create a new BracketedDefinition subclass with the given name.</p> Source code in <code>src\\appl\\core\\promptable\\definition.py</code> <pre><code>def define_bracketed(def_name: str) -&gt; type:\n    \"\"\"Create a new BracketedDefinition subclass with the given name.\"\"\"\n\n    class CustomDef(BracketedDefinition):\n        name = def_name\n\n    return CustomDef\n</code></pre>"},{"location":"reference/core/promptable/formatter/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> formatter","text":""},{"location":"reference/core/promptable/formatter/#appl.core.promptable.formatter","title":"formatter","text":""},{"location":"reference/core/promptable/formatter/#appl.core.promptable.formatter.Formattable","title":"Formattable","text":"<p>Base class for class objects that can be formatted.</p> Example <pre><code>&gt;&gt;&gt; class Example(Formattable):\n...     fstr: str = \"[{}]\"\n...     name: str = \"example\"\n&gt;&gt;&gt; print(f\"{Example}\")\n[example]\n</code></pre>"},{"location":"reference/core/promptable/formatter/#appl.core.promptable.formatter.FormatterMeta","title":"FormatterMeta","text":"<p>             Bases: <code>ABCMeta</code></p> <p>Metaclass for classes that can be formatted.</p>"},{"location":"reference/core/types/","title":"Index","text":""},{"location":"reference/core/types/#appl.core.types","title":"types","text":""},{"location":"reference/core/types/basic/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> basic","text":""},{"location":"reference/core/types/basic/#appl.core.types.basic","title":"basic","text":""},{"location":"reference/core/types/basic/#appl.core.types.basic.MaybeOneOrMany","title":"MaybeOneOrMany  <code>module-attribute</code>","text":"<pre><code>MaybeOneOrMany = Union[_T, Sequence[_T], None]\n</code></pre> <p>A type that can be either a single item, a sequence of items, or None.</p>"},{"location":"reference/core/types/basic/#appl.core.types.basic.OneOrMany","title":"OneOrMany  <code>module-attribute</code>","text":"<pre><code>OneOrMany = Union[_T, Sequence[_T]]\n</code></pre> <p>A type that can be either a single item or a sequence of items.</p>"},{"location":"reference/core/types/content/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> content","text":""},{"location":"reference/core/types/content/#appl.core.types.content","title":"content","text":""},{"location":"reference/core/types/content/#appl.core.types.content.StrOrImg","title":"StrOrImg  <code>module-attribute</code>","text":"<pre><code>StrOrImg = Union[String, Image]\n</code></pre> <p>A type that can be either a string or an image.</p>"},{"location":"reference/core/types/content/#appl.core.types.content.ContentList","title":"ContentList","text":"<p>             Bases: <code>BaseModel</code></p> <p>Represent a list of contents containing text and images.</p>"},{"location":"reference/core/types/content/#appl.core.types.content.ContentList.append","title":"append","text":"<pre><code>append(content: StrOrImg) -&gt; None\n</code></pre> <p>Append a content to the list.</p> <p>If the last content is a string, it will be concatenated with the new content.</p> Source code in <code>src\\appl\\core\\types\\content.py</code> <pre><code>def append(self, content: StrOrImg) -&gt; None:\n    \"\"\"Append a content to the list.\n\n    If the last content is a string, it will be concatenated with the new content.\n    \"\"\"\n    if is_string(content) and len(self.contents) and is_string(self.contents[-1]):\n        self.contents[-1] += content  # type: ignore\n    else:\n        self.contents.append(content)\n</code></pre>"},{"location":"reference/core/types/content/#appl.core.types.content.ContentList.extend","title":"extend","text":"<pre><code>extend(contents: list[StrOrImg]) -&gt; None\n</code></pre> <p>Extend the list with multiple contents.</p> Source code in <code>src\\appl\\core\\types\\content.py</code> <pre><code>def extend(self, contents: list[StrOrImg]) -&gt; None:\n    \"\"\"Extend the list with multiple contents.\"\"\"\n    for content in contents:\n        self.append(content)\n</code></pre>"},{"location":"reference/core/types/content/#appl.core.types.content.ContentList.get_contents","title":"get_contents","text":"<pre><code>get_contents() -&gt; List[Dict[str, Any]]\n</code></pre> <p>Return the contents as a list of dictionaries.</p> Source code in <code>src\\appl\\core\\types\\content.py</code> <pre><code>def get_contents(self) -&gt; List[Dict[str, Any]]:\n    \"\"\"Return the contents as a list of dictionaries.\"\"\"\n\n    def get_dict(content):\n        if isinstance(content, Image):\n            image_args = {\"url\": content.url}\n            if content.detail:\n                image_args[\"detail\"] = content.detail\n            return {\"type\": \"image_url\", \"image_url\": image_args}\n        return {\"type\": \"text\", \"text\": str(content)}\n\n    return [get_dict(c) for c in self.contents]\n</code></pre>"},{"location":"reference/core/types/content/#appl.core.types.content.Image","title":"Image","text":"<pre><code>Image(url: str, detail: Optional[str] = None)\n</code></pre> <p>             Bases: <code>BaseModel</code></p> <p>Represent an image in the message.</p> <p>See the guide for more information about the detail level.</p> Source code in <code>src\\appl\\core\\types\\content.py</code> <pre><code>def __init__(self, url: str, detail: Optional[str] = None) -&gt; None:\n    \"\"\"Initialize the image with the URL and detail level.\n\n    See [the guide](https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding)\n    for more information about the detail level.\n    \"\"\"\n    super().__init__(url=url, detail=detail)\n</code></pre>"},{"location":"reference/core/types/custom/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> custom","text":""},{"location":"reference/core/types/custom/#appl.core.types.custom","title":"custom","text":""},{"location":"reference/core/types/custom/#appl.core.types.custom.ResponseType","title":"ResponseType","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>The type of generation response.</p>"},{"location":"reference/core/types/custom/#appl.core.types.custom.ResponseType.IMAGE","title":"IMAGE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>IMAGE = 'image'\n</code></pre> <p>An image.</p>"},{"location":"reference/core/types/custom/#appl.core.types.custom.ResponseType.OBJECT","title":"OBJECT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>OBJECT = 'obj'\n</code></pre> <p>An instance of a response model.</p>"},{"location":"reference/core/types/custom/#appl.core.types.custom.ResponseType.TEXT","title":"TEXT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEXT = 'text'\n</code></pre> <p>A text completion.</p>"},{"location":"reference/core/types/custom/#appl.core.types.custom.ResponseType.TOOL_CALL","title":"TOOL_CALL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TOOL_CALL = 'tool_calls'\n</code></pre> <p>A list of tool calls.</p>"},{"location":"reference/core/types/custom/#appl.core.types.custom.ResponseType.UNFINISHED","title":"UNFINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNFINISHED = 'unfinished'\n</code></pre> <p>The response is not finished.</p>"},{"location":"reference/core/types/deps/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> deps","text":""},{"location":"reference/core/types/deps/#appl.core.types.deps","title":"deps","text":"<p>Import types from dependencies</p>"},{"location":"reference/core/types/futures/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> futures","text":""},{"location":"reference/core/types/futures/#appl.core.types.futures","title":"futures","text":""},{"location":"reference/core/types/futures/#appl.core.types.futures.String","title":"String  <code>module-attribute</code>","text":"<pre><code>String = Union[StringFuture, str]\n</code></pre> <p>String is a type alias for StringFuture or str.</p>"},{"location":"reference/core/types/futures/#appl.core.types.futures.CallFuture","title":"CallFuture","text":"<pre><code>CallFuture(\n    func: Callable,\n    *args: Any,\n    use_process: bool = False,\n    lazy_eval: bool = False,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>FutureValue</code></p> <p>Represent a function call that may not be ready yet.</p> <p>Parameters:</p> <ul> <li> <code>func</code>             (<code>Callable</code>)         \u2013          <p>The function to call.</p> </li> <li> <code>*args</code>             (<code>Any</code>, default:                 <code>()</code> )         \u2013          <p>The arguments of the function.</p> </li> <li> <code>use_process</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to use a process pool executor.</p> </li> <li> <code>lazy_eval</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to delay the start of the call until needed.</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>The keyword arguments of the function.</p> </li> </ul> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def __init__(\n    self,\n    func: Callable,\n    *args: Any,\n    use_process: bool = False,\n    lazy_eval: bool = False,\n    **kwargs: Any,\n):\n    \"\"\"Initialize the CallFuture.\n\n    Args:\n        func: The function to call.\n        *args: The arguments of the function.\n        use_process: Whether to use a process pool executor.\n        lazy_eval: Whether to delay the start of the call until needed.\n        **kwargs: The keyword arguments of the function.\n    \"\"\"\n    # TODO: maybe use a global executor from the config\n    self._executor = (\n        ProcessPoolExecutor(max_workers=1)\n        if use_process\n        else ThreadPoolExecutor(max_workers=1)\n    )\n    self._submit_fn = lambda: self._executor.submit(func, *args, **kwargs)\n    self._submitted = False\n    self._info = func.__name__\n    # self._debug = False\n    # if self._debug:\n    #     # arg and kwargs might contains future objects\n    #     args_list = [f\"{arg}\" for arg in args] + [\n    #         f\"{k}={v!r}\" for k, v in kwargs.items()\n    #     ]\n    #     args_str = \", \".join(args_list)\n    #     self._info += f\"({args_str})\"\n    if not lazy_eval:\n        # delay the start of the call until needed\n        self._submit()\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.CallFuture.future","title":"future  <code>property</code>","text":"<pre><code>future\n</code></pre> <p>The future object of the call.</p>"},{"location":"reference/core/types/futures/#appl.core.types.futures.CallFuture.val","title":"val  <code>property</code>","text":"<pre><code>val\n</code></pre> <p>The value of the future.</p>"},{"location":"reference/core/types/futures/#appl.core.types.futures.CallFuture.cancel","title":"cancel","text":"<pre><code>cancel() -&gt; bool\n</code></pre> <p>Cancel the call.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def cancel(self) -&gt; bool:\n    \"\"\"Cancel the call.\"\"\"\n    # Attempt to cancel the call\n    return self.future.cancel()\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.CallFuture.done","title":"done","text":"<pre><code>done() -&gt; bool\n</code></pre> <p>Check if the call has completed.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def done(self) -&gt; bool:\n    \"\"\"Check if the call has completed.\"\"\"\n    # Check if the future has completed\n    return self.future.done()\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.CallFuture.result","title":"result","text":"<pre><code>result() -&gt; Any\n</code></pre> <p>Get the result of the call.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def result(self) -&gt; Any:\n    \"\"\"Get the result of the call.\"\"\"\n    # This will block until the result is available\n    return self.future.result()\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.CmpStringFuture","title":"CmpStringFuture","text":"<pre><code>CmpStringFuture(\n    a: StringFuture,\n    b: StringFuture,\n    op: Callable[[str, str], bool],\n)\n</code></pre> <p>             Bases: <code>FutureValue</code></p> <p>Represent a comparison between a StringFuture and another value.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def __init__(\n    self, a: \"StringFuture\", b: \"StringFuture\", op: Callable[[str, str], bool]\n):\n    \"\"\"Initialize the CmpStringFuture.\"\"\"\n    self._a = a\n    self._b = b\n    self._op = op\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.CmpStringFuture.val","title":"val  <code>property</code>","text":"<pre><code>val\n</code></pre> <p>The value of the future.</p>"},{"location":"reference/core/types/futures/#appl.core.types.futures.FutureValue","title":"FutureValue","text":"<p>             Bases: <code>ABC</code></p> <p>Represents a value that may not be ready yet.</p>"},{"location":"reference/core/types/futures/#appl.core.types.futures.FutureValue.val","title":"val  <code>property</code>","text":"<pre><code>val\n</code></pre> <p>The value of the future.</p>"},{"location":"reference/core/types/futures/#appl.core.types.futures.StringFuture","title":"StringFuture","text":"<pre><code>StringFuture(content: Any = '', set_value: bool = False)\n</code></pre> <p>             Bases: <code>FutureValue</code>, <code>BaseModel</code></p> <p>StringFuture is a string that may not be ready yet.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def __init__(self, content: Any = \"\", set_value: bool = False):\n    \"\"\"Initialize the StringFuture.\"\"\"\n    if set_value:\n        if not isinstance(content, List):\n            raise ValueError(\"Cannot set value to non-list.\")\n        s = content\n    else:\n        s = [content]\n    super().__init__(s=s)\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.StringFuture.val","title":"val  <code>property</code>","text":"<pre><code>val\n</code></pre> <p>The value of the future.</p>"},{"location":"reference/core/types/futures/#appl.core.types.futures.StringFuture.from_list","title":"from_list  <code>classmethod</code>","text":"<pre><code>from_list(content: List[Any]) -&gt; StringFuture\n</code></pre> <p>Create a StringFuture from a list of content.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>@classmethod\ndef from_list(cls, content: List[Any]) -&gt; \"StringFuture\":\n    \"\"\"Create a StringFuture from a list of content.\"\"\"\n    return cls(content, set_value=True)\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.StringFuture.join","title":"join","text":"<pre><code>join(iterable: Iterable[StringFuture]) -&gt; StringFuture\n</code></pre> <p>Concatenate any number of strings.</p> <p>The StringFuture whose method is called is inserted in between each given StringFuture. The result is returned as a new StringFuture.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def join(self, iterable: Iterable[\"StringFuture\"]) -&gt; \"StringFuture\":\n    \"\"\"Concatenate any number of strings.\n\n    The StringFuture whose method is called is inserted in between each\n    given StringFuture. The result is returned as a new StringFuture.\"\"\"\n    result = []\n    for i, x in enumerate(iterable):\n        if i != 0:\n            result.append(self)\n        result.append(x)\n    return StringFuture.from_list(result)\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.StringFuture.materialized","title":"materialized","text":"<pre><code>materialized() -&gt; StringFuture\n</code></pre> <p>Materialize the StringFuture.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def materialized(self) -&gt; \"StringFuture\":\n    \"\"\"Materialize the StringFuture.\"\"\"\n    self.s = [self._collapse()]\n    return self\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.StringFuture.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; str\n</code></pre> <p>Serialize the StringFuture.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def serialize(self) -&gt; str:\n    \"\"\"Serialize the StringFuture.\"\"\"\n    return str(self)\n</code></pre>"},{"location":"reference/core/types/futures/#appl.core.types.futures.is_string","title":"is_string","text":"<pre><code>is_string(s: Any) -&gt; bool\n</code></pre> <p>Check if the object is a StringFuture or str.</p> Source code in <code>src\\appl\\core\\types\\futures.py</code> <pre><code>def is_string(s: Any) -&gt; bool:\n    \"\"\"Check if the object is a StringFuture or str.\"\"\"\n    return isinstance(s, StringFuture) or isinstance(s, str)\n</code></pre>"},{"location":"reference/core/types/role/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> role","text":""},{"location":"reference/core/types/role/#appl.core.types.role","title":"role","text":""},{"location":"reference/core/types/role/#appl.core.types.role.ASSISTANT_ROLE","title":"ASSISTANT_ROLE  <code>module-attribute</code>","text":"<pre><code>ASSISTANT_ROLE = MessageRole(ASSISTANT)\n</code></pre> <p>The assistant role with name not specified.</p>"},{"location":"reference/core/types/role/#appl.core.types.role.SYSTEM_ROLE","title":"SYSTEM_ROLE  <code>module-attribute</code>","text":"<pre><code>SYSTEM_ROLE = MessageRole(SYSTEM)\n</code></pre> <p>The system role with name not specified.</p>"},{"location":"reference/core/types/role/#appl.core.types.role.TOOL_ROLE","title":"TOOL_ROLE  <code>module-attribute</code>","text":"<pre><code>TOOL_ROLE = MessageRole(TOOL)\n</code></pre> <p>The tool role with name not specified.</p>"},{"location":"reference/core/types/role/#appl.core.types.role.USER_ROLE","title":"USER_ROLE  <code>module-attribute</code>","text":"<pre><code>USER_ROLE = MessageRole(USER)\n</code></pre> <p>The user role with name not specified.</p>"},{"location":"reference/core/types/role/#appl.core.types.role.MessageRole","title":"MessageRole","text":"<pre><code>MessageRole(\n    type: Optional[str] = None, name: Optional[str] = None\n)\n</code></pre> <p>             Bases: <code>BaseModel</code></p> <p>The role of the message owner.</p> <p>Parameters:</p> <ul> <li> <code>type</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>The type of the role.</p> </li> <li> <code>name</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>An optional name for the role, differentiate between roles of the same type.\"</p> </li> </ul> Source code in <code>src\\appl\\core\\types\\role.py</code> <pre><code>def __init__(self, type: Optional[str] = None, name: Optional[str] = None):\n    \"\"\"Initialize the MessageRole object.\n\n    Args:\n        type: The type of the role.\n        name: An optional name for the role, differentiate between roles of the same type.\"\n    \"\"\"\n    super().__init__(type=type, name=name)\n</code></pre>"},{"location":"reference/core/types/role/#appl.core.types.role.MessageRole.is_assistant","title":"is_assistant  <code>property</code>","text":"<pre><code>is_assistant: bool\n</code></pre> <p>Whether the role is an assistant role.</p>"},{"location":"reference/core/types/role/#appl.core.types.role.MessageRole.is_system","title":"is_system  <code>property</code>","text":"<pre><code>is_system: bool\n</code></pre> <p>Whether the role is a system role.</p>"},{"location":"reference/core/types/role/#appl.core.types.role.MessageRole.is_tool","title":"is_tool  <code>property</code>","text":"<pre><code>is_tool: bool\n</code></pre> <p>Whether the role is a tool role.</p>"},{"location":"reference/core/types/role/#appl.core.types.role.MessageRole.is_user","title":"is_user  <code>property</code>","text":"<pre><code>is_user: bool\n</code></pre> <p>Whether the role is a user role.</p>"},{"location":"reference/core/types/role/#appl.core.types.role.MessageRole.get_dict","title":"get_dict","text":"<pre><code>get_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Get the role as a dictionary.</p> Source code in <code>src\\appl\\core\\types\\role.py</code> <pre><code>def get_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Get the role as a dictionary.\"\"\"\n    data = {\"role\": self.type}\n    if self.name:\n        data[\"name\"] = self.name\n    return data\n</code></pre>"},{"location":"reference/servers/","title":"Index","text":""},{"location":"reference/servers/#appl.servers","title":"servers","text":""},{"location":"reference/servers/api/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> api","text":""},{"location":"reference/servers/api/#appl.servers.api","title":"api","text":""},{"location":"reference/servers/api/#appl.servers.api.APIServer","title":"APIServer","text":"<pre><code>APIServer(\n    model: str,\n    base_url: Optional[str] = None,\n    api_key: Optional[str] = None,\n    custom_llm_provider: Optional[str] = None,\n    wrap_mode: Optional[Mode] = Mode.TOOLS,\n    cost_currency: str = \"USD\",\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>BaseServer</code></p> <p>The server for API models. It is a wrapper of litellm.completion.</p> <p>See LiteLLM for available models and providers. See completion for available options.</p> Source code in <code>src\\appl\\servers\\api.py</code> <pre><code>def __init__(\n    self,\n    model: str,\n    base_url: Optional[str] = None,\n    api_key: Optional[str] = None,\n    custom_llm_provider: Optional[str] = None,\n    wrap_mode: Optional[Mode] = Mode.TOOLS,\n    cost_currency: str = \"USD\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the API server.\n\n    See [LiteLLM](https://docs.litellm.ai/docs/providers)\n    for available models and providers.\n    See [completion](https://docs.litellm.ai/docs/completion/input#input-params-1)\n    for available options.\n    \"\"\"\n    super().__init__()\n    self._wrap_mode = wrap_mode\n    self._model = model\n    self._base_url = base_url\n    self._api_key = api_key\n    self._custom_llm_provider = custom_llm_provider\n    self._cost_currency = cost_currency\n    self._default_args = kwargs\n</code></pre>"},{"location":"reference/servers/api/#appl.servers.api.APIServer.model_name","title":"model_name  <code>property</code>","text":"<pre><code>model_name\n</code></pre> <p>The model name.</p>"},{"location":"reference/servers/api/#appl.servers.api.APIServer.close","title":"close","text":"<pre><code>close()\n</code></pre> <p>Close the server.</p> Source code in <code>src\\appl\\servers\\api.py</code> <pre><code>def close(self):\n    \"\"\"Close the server.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/servers/api/#appl.servers.api.APIServer.create","title":"create","text":"<pre><code>create(\n    args: GenArgs, gen_id: str, **kwargs: Any\n) -&gt; CompletionResponse\n</code></pre> <p>Create a CompletionResponse from the model with given arguments.</p> <p>Parameters:</p> <ul> <li> <code>args</code>             (<code>GenArgs</code>)         \u2013          <p>The arguments for generating the response</p> </li> <li> <code>gen_id</code>             (<code>str</code>)         \u2013          <p>The ID of the generation</p> </li> <li> <code>**kwargs</code>             (<code>Any</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments</p> </li> </ul> <p>Returns:     The response from the model.</p> Source code in <code>src\\appl\\core\\server.py</code> <pre><code>def create(self, args: GenArgs, gen_id: str, **kwargs: Any) -&gt; CompletionResponse:\n    \"\"\"Create a CompletionResponse from the model with given arguments.\n\n    Args:\n        args: The arguments for generating the response\n        gen_id: The ID of the generation\n        **kwargs: Additional keyword arguments\n    Returns:\n        The response from the model.\n    \"\"\"\n    log_llm_call_args = configs.getattrs(\"settings.logging.display.llm_call_args\")\n    log_llm_response = configs.getattrs(\"settings.logging.display.llm_response\")\n\n    create_args = self._get_create_args(args, **kwargs)\n    if log_llm_call_args:\n        logger.info(f\"Call generation [{gen_id}] with args: {create_args}\")\n\n    results = self._create(gen_id=gen_id, **create_args)\n    if log_llm_response:\n        logger.info(f\"Generation [{gen_id}] results: {results}\")\n    if results.cost:\n        if \"mock_response\" in create_args:\n            if configs.getattrs(\"settings.logging.display.llm_cost\"):\n                logger.info(\n                    f\"Mock response, estimated cost for real request: {results.cost:.4f}\"\n                )\n        else:\n            _update_cost(\n                self.model_name,\n                results.cost,\n                getattr(self, \"_cost_currency\", \"USD\"),\n            )\n\n    dump_args = create_args.copy()\n    if \"response_model\" in dump_args:\n        v = dump_args[\"response_model\"]\n        if issubclass(v, BaseModel):\n            dump_args[\"response_model\"] = json.dumps(\n                v.model_json_schema(), indent=4\n            )\n\n    def trace_gen_response(response: CompletionResponse) -&gt; None:\n        add_to_trace(\n            GenerationResponseEvent(name=gen_id, args=dump_args, ret=str(response))\n        )\n\n    results.register_post_finish_callback(trace_gen_response)\n    return results\n</code></pre>"},{"location":"reference/servers/api/#appl.servers.api.chat_completion","title":"chat_completion","text":"<pre><code>chat_completion(**kwargs: Any) -&gt; CompletionResponse\n</code></pre> <p>Wrap the litellm.completion function to add tracing and logging.</p> Source code in <code>src\\appl\\servers\\api.py</code> <pre><code>@wraps(litellm.completion)\ndef chat_completion(**kwargs: Any) -&gt; CompletionResponse:\n    \"\"\"Wrap the litellm.completion function to add tracing and logging.\"\"\"\n    if \"gen_id\" not in kwargs:\n        raise ValueError(\"gen_id is required for tracing completion generation.\")\n    gen_id = kwargs.pop(\"gen_id\")\n    add_to_trace(CompletionRequestEvent(name=gen_id))\n\n    log_llm_call_args = configs.getattrs(\"settings.logging.display.llm_raw_call_args\")\n    log_llm_response = configs.getattrs(\"settings.logging.display.llm_raw_response\")\n    log_llm_usage = configs.getattrs(\"settings.logging.display.llm_raw_usage\")\n    log_llm_cache = configs.getattrs(\"settings.logging.display.llm_cache\")\n    if log_llm_call_args:\n        logger.info(f\"Call completion [{gen_id}] with args: {kwargs}\")\n\n    @traceable(\n        name=f\"ChatCompletion_{gen_id}\",\n        run_type=\"llm\",\n        metadata={\"appl\": \"completion\", \"appl_version\": __version__},\n    )\n    def wrapped(**inner_kwargs: Any) -&gt; Tuple[Any, bool]:\n        if cache_ret := find_in_cache(gen_id, inner_kwargs):\n            if log_llm_cache:\n                logger.info(\"Found in cache, using cached response...\")\n            if inner_kwargs.get(\"stream\", False):\n                raise ValueError(\"Not support stream using cache yet.\")\n                # TODO: support rebuild the stream from cached response\n            raw_response = cache_ret\n        else:\n            if log_llm_cache:\n                logger.info(\"Not found in cache, creating response...\")\n            raw_response = litellm.completion(**inner_kwargs)\n        return raw_response, cache_ret is not None\n\n    raw_response, use_cache = wrapped(**kwargs)\n\n    def post_completion(response: CompletionResponse) -&gt; None:\n        raw_response = response.complete_response\n        cost = 0.0 if use_cache else response.cost\n        response.cost = cost  # update the cost\n        add_to_trace(\n            CompletionResponseEvent(\n                name=gen_id, args=kwargs, ret=raw_response, cost=cost\n            )\n        )\n        if log_llm_response:\n            logger.info(f\"Completion [{gen_id}] response: {response}\")\n        if log_llm_usage and response.usage is not None:\n            logger.info(f\"Completion [{gen_id}] usage: {response.usage}\")\n\n    return CompletionResponse(\n        raw_response=raw_response, post_finish_callbacks=[post_completion]\n    )  # type: ignore\n</code></pre>"},{"location":"reference/servers/manager/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> manager","text":""},{"location":"reference/servers/manager/#appl.servers.manager","title":"manager","text":""},{"location":"reference/servers/manager/#appl.servers.manager.ServerManager","title":"ServerManager","text":"<pre><code>ServerManager()\n</code></pre> <p>The manager for all servers.</p> Source code in <code>src\\appl\\servers\\manager.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the server manager.\"\"\"\n    self._servers: Dict[str, BaseServer] = {}\n</code></pre>"},{"location":"reference/servers/manager/#appl.servers.manager.ServerManager.default_server","title":"default_server  <code>property</code>","text":"<pre><code>default_server: BaseServer\n</code></pre> <p>The default server.</p>"},{"location":"reference/servers/manager/#appl.servers.manager.ServerManager.close_server","title":"close_server","text":"<pre><code>close_server(name: str) -&gt; None\n</code></pre> <p>Close a server by name.</p> Source code in <code>src\\appl\\servers\\manager.py</code> <pre><code>def close_server(self, name: str) -&gt; None:\n    \"\"\"Close a server by name.\"\"\"\n    if name in self._servers:\n        self._servers[name].close()\n        del self._servers[name]\n</code></pre>"},{"location":"reference/servers/manager/#appl.servers.manager.ServerManager.get_server","title":"get_server","text":"<pre><code>get_server(name: Optional[str]) -&gt; BaseServer\n</code></pre> <p>Get a server by name. If name is None, get the default server.</p> Source code in <code>src\\appl\\servers\\manager.py</code> <pre><code>def get_server(self, name: Optional[str]) -&gt; BaseServer:\n    \"\"\"Get a server by name. If name is None, get the default server.\"\"\"\n    if name is None:\n        name = configs.getattrs(\"servers.default\")\n\n    if name not in self._servers:\n        server_configs = _get_server_configs(name)\n        server = _init_server(**server_configs)\n        self.register_server(name, server)\n    return self._servers[name]\n</code></pre>"},{"location":"reference/servers/manager/#appl.servers.manager.ServerManager.register_server","title":"register_server","text":"<pre><code>register_server(name: str, server: BaseServer) -&gt; None\n</code></pre> <p>Register a server with a name.</p> Source code in <code>src\\appl\\servers\\manager.py</code> <pre><code>def register_server(self, name: str, server: BaseServer) -&gt; None:\n    \"\"\"Register a server with a name.\"\"\"\n    self._servers[name] = server\n</code></pre>"},{"location":"reference/tracing/","title":"Index","text":""},{"location":"reference/tracing/#appl.tracing","title":"tracing","text":""},{"location":"reference/tracing/engine/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> engine","text":""},{"location":"reference/tracing/engine/#appl.tracing.engine","title":"engine","text":""},{"location":"reference/tracing/engine/#appl.tracing.engine.TraceEngine","title":"TraceEngine","text":"<pre><code>TraceEngine(\n    filename: str, mode: str = \"write\", strict: bool = True\n)\n</code></pre> <p>             Bases: <code>TraceEngineBase</code></p> <p>The engine used to record the trace of a program execution.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>str</code>)         \u2013          <p>The filename storing the trace.</p> </li> <li> <code>mode</code>             (<code>str</code>, default:                 <code>'write'</code> )         \u2013          <p>The mode of the trace, \"write\" or \"read\". Defaults to \"write\".</p> </li> <li> <code>strict</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to match strictly when used as a cache. Defaults to True.</p> <ul> <li>True: matching according to the generation id, prompts, and     parameters. And cache stops to work whenever a match failed.</li> <li>False: only matching prompts and parameters.</li> </ul> </li> </ul> Source code in <code>src\\appl\\tracing\\engine.py</code> <pre><code>def __init__(self, filename: str, mode: str = \"write\", strict: bool = True) -&gt; None:\n    \"\"\"Initialize the TraceEngine.\n\n    Args:\n        filename: The filename storing the trace.\n        mode: The mode of the trace, \"write\" or \"read\". Defaults to \"write\".\n        strict:\n            Whether to match strictly when used as a cache. Defaults to True.\n\n            - True: matching according to the generation id, prompts, and\n                parameters. And cache stops to work whenever a match failed.\n            - False: only matching prompts and parameters.\n    \"\"\"\n    self._mode = mode\n    self._strict = strict\n    self._events: List[TraceEventBase] = []  # events read from the file\n    self._trace_nodes: Dict[str, TraceNode] = {}\n    self._gen_cache: Dict[str, List[Any]] = {}\n    self._lock = Lock()\n    self._func_stack: List[str] = []\n\n    if mode == \"write\":\n        if os.path.exists(filename):\n            logger.warning(f\"Trace file {filename} already exists, overwriting\")\n        self._file = open(filename, \"wb+\")\n    elif mode == \"read\":\n        if not os.path.exists(filename):\n            raise FileNotFoundError(f\"Trace file {filename} not found\")\n        self._file = open(filename, \"rb+\")\n        self._read()\n    else:\n        raise ValueError(f\"Invalid mode {mode}, only 'write' or 'read' allowed.\")\n</code></pre>"},{"location":"reference/tracing/engine/#appl.tracing.engine.TraceEngine.events","title":"events  <code>property</code>","text":"<pre><code>events: List[TraceEventBase]\n</code></pre> <p>The list of events in the trace.</p>"},{"location":"reference/tracing/engine/#appl.tracing.engine.TraceEngine.min_timestamp","title":"min_timestamp  <code>cached</code> <code>property</code>","text":"<pre><code>min_timestamp: float\n</code></pre> <p>The minimum time stamp of the events in the trace.</p>"},{"location":"reference/tracing/engine/#appl.tracing.engine.TraceEngine.trace_nodes","title":"trace_nodes  <code>property</code>","text":"<pre><code>trace_nodes: Dict[str, TraceNode]\n</code></pre> <p>The dictionary of trace nodes.</p>"},{"location":"reference/tracing/engine/#appl.tracing.engine.TraceEngine.append","title":"append","text":"<pre><code>append(event: TraceEventBase) -&gt; None\n</code></pre> <p>Append an event to the trace.</p> Source code in <code>src\\appl\\tracing\\engine.py</code> <pre><code>def append(self, event: TraceEventBase) -&gt; None:\n    \"\"\"Append an event to the trace.\"\"\"\n    if self._mode == \"write\":\n        with self._lock:\n            logger.debug(f\"add to trace {event}\")\n            pickle.dump(event, self._file)\n            self._file.flush()\n\n    self._events.append(event)\n    name, time_stamp = event.name, event.time_stamp\n    assert name is not None\n    if isinstance(event, FunctionCallEvent):\n        newnode = self._add_node(name, self._last_func, type=\"func\")\n        newnode.start_time = time_stamp\n        newnode.args = event.args\n        self._func_stack.append(name)\n    elif isinstance(event, FunctionReturnEvent):\n        node = self._get_node(name)\n        if node:\n            node.end_time = time_stamp\n        self._pop_func()\n    elif isinstance(event, GenerationInitEvent):\n        newnode = self._add_node(name, self._last_func)\n        newnode.start_time = time_stamp\n    elif isinstance(event, GenerationResponseEvent):\n        node = self._get_node(name)\n        if node:\n            node.end_time = time_stamp\n            node.args = event.args\n            node.ret = event.ret\n    elif isinstance(event, CompletionRequestEvent):\n        # Use name + \"_raw\" to represent the raw completion request\n        newnode = self._add_node(name + \"_raw\", name)\n        newnode.start_time = time_stamp\n    elif isinstance(event, CompletionResponseEvent):\n        node = self._get_node(name + \"_raw\")\n        if node:\n            node.end_time = time_stamp\n            node.args = event.args\n            node.ret = event.ret\n            node.info[\"cost\"] = event.cost\n\n        # cached for raw completion response\n        key = self._cache_key(name, event.args)\n        if key not in self._gen_cache:\n            self._gen_cache[key] = []\n        self._gen_cache[key].append(event.ret)\n</code></pre>"},{"location":"reference/tracing/engine/#appl.tracing.engine.TraceEngine.find_cache","title":"find_cache","text":"<pre><code>find_cache(name: str, args: Dict) -&gt; Any\n</code></pre> <p>Find a cached response for a generation request.</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the generation request.</p> </li> <li> <code>args</code>             (<code>Dict</code>)         \u2013          <p>The arguments of the generation request.</p> </li> </ul> Source code in <code>src\\appl\\tracing\\engine.py</code> <pre><code>def find_cache(self, name: str, args: Dict) -&gt; Any:\n    \"\"\"Find a cached response for a generation request.\n\n    Args:\n        name: The name of the generation request.\n        args: The arguments of the generation request.\n    \"\"\"\n    with self._lock:\n        entry_list = self._gen_cache.get(self._cache_key(name, args), None)\n        if not entry_list or len(entry_list) == 0:\n            return None\n        entry = entry_list.pop(0)\n        return entry\n</code></pre>"},{"location":"reference/tracing/printer/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> printer","text":""},{"location":"reference/tracing/printer/#appl.tracing.printer","title":"printer","text":""},{"location":"reference/tracing/printer/#appl.tracing.printer.TraceHTMLPrinter","title":"TraceHTMLPrinter","text":"<pre><code>TraceHTMLPrinter()\n</code></pre> <p>             Bases: <code>TracePrinterBase</code></p> <p>The printer used to print the trace in the format of HTML.</p> Source code in <code>src\\appl\\tracing\\printer.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the printer.\"\"\"\n    super().__init__()\n    self._generation_style = \"text-success-emphasis bg-Success-subtle list-group-item d-flex justify-content-between align-items-center\"\n    self._time_style = \"position-absolute top-0 start-100 translate-middle badge rounded-pill bg-info\"\n    self._cost_style = \"position-absolute bottom-0 start-100 translate-middle badge rounded-pill bg-warning\"\n    self._longest_shown_output = 70\n\n    self._head = load_file(os.path.join(folder, \"header.html\"))\n    self._color_map = {\n        \"user\": \"text-bg-info\",\n        \"assistant\": \"text-bg-warning\",\n        \"system\": \"text-bg-success\",\n    }\n</code></pre>"},{"location":"reference/tracing/printer/#appl.tracing.printer.TraceHTMLPrinter.print","title":"print","text":"<pre><code>print(\n    trace: TraceEngineBase,\n    meta_data: Optional[Configs] = None,\n) -&gt; str\n</code></pre> <p>Print the trace in the format of HTML.</p> Source code in <code>src\\appl\\tracing\\printer.py</code> <pre><code>@ppl(exclude_first_str=True)\ndef print(self, trace: TraceEngineBase, meta_data: Optional[Configs] = None) -&gt; str:\n    \"\"\"Print the trace in the format of HTML.\"\"\"\n    with Tagged(\"html\"):\n        self._head\n        with Tagged(\"body\"):\n            for node in trace.trace_nodes.values():\n                if node.parent is None:\n                    self._print_node(node, trace.min_timestamp)\n    if meta_data:\n        with Tagged(\"table\", attrs={\"class\": \"table small\"}):\n            if start_time := meta_data.getattrs(\"info.start_time\"):\n                self._make_line(\"Start Time\", start_time)\n            self._make_line(\"Full Configs\", f\"&lt;pre&gt;{meta_data.to_yaml()}&lt;/pre&gt;\")\n    return str(records())\n</code></pre>"},{"location":"reference/tracing/printer/#appl.tracing.printer.TraceProfilePrinter","title":"TraceProfilePrinter","text":"<pre><code>TraceProfilePrinter(display_functions: bool = False)\n</code></pre> <p>             Bases: <code>TracePrinterBase</code></p> <p>The printer used to print the trace in the format of profile.</p> <p>Parameters:</p> <ul> <li> <code>display_functions</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to display the function calls.</p> </li> </ul> Source code in <code>src\\appl\\tracing\\printer.py</code> <pre><code>def __init__(self, display_functions: bool = False):\n    \"\"\"Initialize the printer.\n\n    Args:\n        display_functions: Whether to display the function calls.\n    \"\"\"\n    self._display_functions = display_functions\n</code></pre>"},{"location":"reference/tracing/printer/#appl.tracing.printer.TraceProfilePrinter.build_event","title":"build_event","text":"<pre><code>build_event(\n    event: TraceEventBase, min_timestamp: float\n) -&gt; Dict\n</code></pre> <p>Build the event for the trace.</p> Source code in <code>src\\appl\\tracing\\printer.py</code> <pre><code>def build_event(self, event: TraceEventBase, min_timestamp: float) -&gt; Dict:\n    \"\"\"Build the event for the trace.\"\"\"\n    ts = str((event.time_stamp - min_timestamp) * 1e6)\n    data = {\"pid\": 0, \"tid\": 0, \"name\": event.name, \"ts\": ts}\n    # TODO: add args to the trace\n    if isinstance(event, CompletionRequestEvent):\n        data[\"cat\"] = \"gen\"\n        data[\"ph\"] = \"b\"\n        data[\"id\"] = event.name\n    elif isinstance(event, CompletionResponseEvent):\n        data[\"cat\"] = \"gen\"\n        data[\"ph\"] = \"e\"\n        data[\"id\"] = event.name\n        data[\"cost\"] = event.cost\n        data[\"output\"] = event.ret.dict()\n    elif self._display_functions:\n        if isinstance(event, FunctionCallEvent):\n            data[\"cat\"] = \"func\"\n            data[\"ph\"] = \"B\"\n            data[\"tid\"] = \"main\"\n        elif isinstance(event, FunctionReturnEvent):\n            data[\"cat\"] = \"func\"\n            data[\"ph\"] = \"E\"\n            data[\"tid\"] = \"main\"\n    return data\n</code></pre>"},{"location":"reference/tracing/printer/#appl.tracing.printer.TraceProfilePrinter.print","title":"print","text":"<pre><code>print(\n    trace: TraceEngineBase,\n    meta_data: Optional[Configs] = None,\n) -&gt; Dict\n</code></pre> <p>Print the trace in the format of Chrome tracing.</p> Source code in <code>src\\appl\\tracing\\printer.py</code> <pre><code>def print(\n    self, trace: TraceEngineBase, meta_data: Optional[Configs] = None\n) -&gt; Dict:\n    \"\"\"Print the trace in the format of Chrome tracing.\"\"\"\n    events = []\n    for event in trace.events:\n        if data := self.build_event(event, trace.min_timestamp):\n            events.append(data)\n    return {\"traceEvents\": events}\n</code></pre>"},{"location":"tutorials/","title":"Welcome to APPL Tutorial","text":"<p>Welcome to APPL: A Prompt Programming Language. This tutorial will guide you through the basics of APPL, help you understand the core concepts, and get you started with writing your first APPL program.</p>"},{"location":"tutorials/#what-is-appl","title":"What is APPL?","text":"<p>APPL is designed to enhance Python with prompt programming capabilities, making it easier to interact with language models (LMs). It provides a set of tools and abstractions to streamline prompt creation, LM interaction, concurrent execution, and more.</p>"},{"location":"tutorials/#audience","title":"Audience","text":"<p>APPL is based on Python, so it is suitable for Python developers who want to leverage language models in their applications. It is also useful for data scientists, researchers, and anyone interested in exploring the capabilities of language models.</p> <p>Please get yourself familiar with Python before diving into APPL. If you are new to Python, you can start with the official Python tutorial.</p>"},{"location":"tutorials/1_get_started/","title":"Getting Started with APPL","text":"<p>In this section, we will set up your environment and run your first APPL program.</p>"},{"location":"tutorials/1_get_started/#installation","title":"Installation","text":"<p>You can simply install APPL from PyPI using pip: <pre><code>pip install -U applang\n</code></pre> More installation options can be found in the installation guide.</p>"},{"location":"tutorials/1_get_started/#setup","title":"Setup","text":"<p>You need to set up API keys or your own backends to interact with language models (LMs).</p> <p>In this guide, we use OpenAI API as the default backend. You can set your OpenAI API key in the <code>.env</code> file in the root directory of your project: <pre><code>OPENAI_API_KEY=&lt;your openai api key&gt;\n</code></pre> or export it as an environment variable: <pre><code>export OPENAI_API_KEY=&lt;your openai api key&gt;\n</code></pre></p> <p>For setting up other backends, please refer to the setup guide.</p>"},{"location":"tutorials/1_get_started/#hello-world","title":"Hello World","text":"<p>Let's create a simple function that uses LM to respond to a greeting.</p> <pre><code>@ppl  # the @ppl decorator marks the function as an `APPL function`\ndef greeting(name: str):\n    f\"Hello World! My name is {name}.\"  # Add text to the prompt\n    return gen()  # call the default LM with the current prompt\n</code></pre> <p>In this example, the <code>@ppl</code> decorator (<code>@</code> stands for <code>a</code> here) marks the <code>hello_world</code> function as an APPL function. Within such a function, the standalone string <code>f\"Hello World! My name is {name}.\"</code> is added to the prompt, and the <code>gen()</code> function calls LM to generate responses using the current prompt.</p> <p>Below is a complete code snippet that demonstrates the usage of the <code>greeting</code> function:</p> <pre><code>import appl\nfrom appl import gen, ppl\n\nappl.init()  # initialize APPL\n\n@ppl\ndef greeting(name: str):\n    f\"Hello World! My name is {name}.\"\n    return gen()\n\n# call `greeting` as a normal Python function\nprint(greeting(\"APPL\"))\n</code></pre> <p>The prompt for the generation is: <pre><code>Hello World! My name is APPL.\n</code></pre></p> <p>The output will look like <pre><code>Nice to meet you, APPL!\n</code></pre></p>"},{"location":"tutorials/2_qa_example/","title":"Explaining Concepts with QA Examples","text":"<p>In this section, we will explain the core concepts of APPL using question-answering examples. These examples demonstrate how to use APPL to manage prompts, request and retrieve LM responses, and embed LM interactions in Python workflows.</p>"},{"location":"tutorials/2_qa_example/#extract-name-from-quotation","title":"Extract Name from Quotation","text":"<p>Let's begin with a simple task used in this cookbook that involves extracting the author's name from a quotation.</p> <pre><code>@ppl # marks APPL function\ndef get_author_name(quotation: str):\n    # string literal as a prompt statement\n    \"Extract the name of the author from the quotation below.\"\n    # string variable as a prompt statement\n    quotation\n    # use the current prompts to call the LM to generate responses\n    response = gen()\n    # return the generated response as the answer to the question\n    return response\n</code></pre> <p>The <code>@ppl</code> decorator marks the <code>get_author_name</code> function as an APPL function. Within the function, the string literal <code>\"Extract the name of the author from the quotation below.\"</code> and variable <code>quotation</code> are added to the prompt. The <code>gen()</code> function is then called to generate responses using the current prompt. Finally, the generated response is returned as the answer to the question. This APPL function can be called like a normal Python function, as shown in the complete code snippet below.</p> <pre><code>import appl\nfrom appl import gen, ppl\n\nappl.init()\n\n@ppl\ndef get_author_name(quotation: str):\n    \"Extract the name of the author from the quotation below.\"\n    quotation\n    return gen()\n\nquotation = '\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci'\nprint(get_author_name(quotation))\n</code></pre> <p>In this code, the call to the <code>get_author_name</code> function is equivalent to querying the LM with the prompt:</p> Role Message User Extract the name of the author from the quotation below.\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci <p>The output may looks like: <pre><code>The name of the author is Leonardo da Vinci.\n</code></pre></p>"},{"location":"tutorials/2_qa_example/#specify-prefix-for-response","title":"Specify Prefix for Response","text":"<p>Further, you may want to guide the response following a specific prefix so that the generated response is just the author's name like <code>Leonardo da Vinci</code> in the previous example.</p> <p>To achieve this, you can specify the prefix in the prompt as shown below:</p> <pre><code>@ppl\ndef get_author_name(quotation: str):\n    \"Extract the name of the author from the quotation.\"\n    quotation\n    with AIRole():  # specify the role of the prompt within this scope\n        # specify the prefix for the response and then call the generation function\n        f\"The name of the author is {(answer := gen(stop='.'))}\"\n    return answer\n</code></pre> <p>Notably, the f-string is processed part by part, so the <code>gen</code> function inside the f-string intuitively uses the contents before that. The warlus operator <code>:=</code> is used to store the generated response in the <code>answer</code> variable and return it as the answer to the question.</p> <p>The prompt to the LM includes the prefix <code>The name of the author is</code> as an assistant message, and the generated response (in bold) is also added to the conversation as part of the f-string:</p> Before <code>gen()</code>After <code>gen()</code> Role Message User Extract the name of the author from the quotation below.\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci Assistant The name of the author is Role Message User Extract the name of the author from the quotation below.\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci Assistant The name of the author is Leonardo da Vinci Using <code>AIRole</code> context manager <p>The <code>AIRole</code> context manager is used to specify the message role of the prompts within its scope. That saying, the prompts within the <code>AIRole</code> block is treated as assistant messages. Similarly, you can use <code>SystemRole</code> to specify system messages. You can use <code>from appl import AIRole, SystemRole</code> to import these context managers.</p>"},{"location":"tutorials/2_qa_example/#answer-follow-up-questions","title":"Answer Follow-up Questions","text":"<p>Let's extend the previous example to answer multiple independent follow-up questions about the author. The following code demonstrates how to answer questions about the author's era based on the extracted name.</p> <pre><code>import appl\nfrom appl import AIRole, gen, ppl\nfrom appl.const import NEWLINE\n\nappl.init()\n\n@ppl(ctx=\"copy\")  # copy the context from caller\ndef get_answer(question: str):\n    question # only affect the prompt in the current context since the context is copied\n    return gen()\n\n@ppl\ndef answer_questions(quotation: str, questions: list[str]):\n    \"Extract the name of the author from the quotation below and answer questions.\"\n    quotation\n    with AIRole():\n        f\"The name of the author is {gen(stop=NEWLINE)}\"\n    # call sub-functions to answer questions independently\n    return [get_answer(q) for q in questions]\n\nquotation = '\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci'\nquestions = [\n    \"In what era did the author live?\",\n    \"What is the most famous painting of the author?\",\n    # more questions can be added here\n]\nfor ans in answer_questions(quotation, questions):\n    print(ans)\n</code></pre> <p>Note the <code>@ppl(ctx=\"copy\")</code> decorator in the <code>get_answer</code> function, which specify the method to obtain the context from its caller is by copying (more options explained in context passing). This ensures that the context of the caller is not affected by the prompts in the <code>get_answer</code> function. The resulting conversation (convo) for the first and second question would look like (generated responses are in bold):</p> Convo of <code>get_answer</code> (first)Convo of <code>get_answer</code> (second)Convo of <code>answer_questions</code> Role Message User Extract the name of the author from the quotation below and answer questions.\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci Assistant The name of the author is Leonardo da Vinci. User In what era did the author live? Assistant Leonardo da Vinci lived during the Renaissance era. Role Message User Extract the name of the author from the quotation below and answer questions.\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci Assistant The name of the author is Leonardo da Vinci. User What is the most famous painting of the author? Assistant The most famous painting of Leonardo da Vinci is the Mona Lisa. Role Message User Extract the name of the author from the quotation below and answer questions.\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci Assistant The name of the author is Leonardo da Vinci. <p>The output of the code snippet would look like: <pre><code>Leonardo da Vinci lived during the Renaissance era.\nThe most famous painting of Leonardo da Vinci is the Mona Lisa.\n</code></pre></p>"},{"location":"tutorials/2_qa_example/#automatic-parallelization","title":"Automatic Parallelization","text":"<p>Thanks to the asynchronous design of APPL, the indenpendent <code>gen</code> function calls in the <code>answer_questions</code> function can be executed in parallel, without introducing extra code for parallelization. See more details in concurrent execution.</p>"},{"location":"tutorials/2_qa_example/#sequential-question-answering","title":"Sequential Question Answering","text":"<p>In some cases, you may want to answer questions sequentially, where the answer to a question depends on the previous answers. The following code demonstrates how to answer questions sequentially by iterating over the questions and generating responses one by one.</p> <pre><code>@ppl\ndef answer_questions(quotation: str, questions: list[str]):\n    \"Extract the name of the author from the quotation below and answer questions.\"\n    quotation\n    with AIRole():\n        f\"The name of the author is {gen(stop=NEWLINE)}\"\n    answers = []\n    for q in questions:\n        q\n        with AIRole():\n            (answer := gen())\n            # obtain the gen response and add to the prompt, equivalent to\n            # answer = gen()\n            # answer\n        answers.append(answer)\n    return answers\n</code></pre> <p>The resulting conversation would look like (generated responses are in bold):</p> Role Message User Extract the name of the author from the quotation below and answer questions.\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci Assistant The name of the author is Leonardo da Vinci. User In what era did the author live? Assistant Leonardo da Vinci lived during the Renaissance era. User What is the most famous painting of the author? Assistant The most famous painting of Leonardo da Vinci is the Mona Lisa."},{"location":"tutorials/3_appl_function/","title":"Understanding APPL Function","text":"<p>APPL functions are the fundamental building blocks of APPL, marked by the <code>@ppl</code> decorator. As seen in the QA examples, each APPL function is a self-contained module encapsulating LM prompts and Python workflows to realize the functionality.</p>"},{"location":"tutorials/3_appl_function/#difference-to-python-functions","title":"Difference to Python functions","text":"<p>APPL functions are extended from Python functions while designed to seamlessly blend LM prompts with Python codes. You can use Python syntax and libraries in APPL functions as you would in normal Python functions. Beyond normal Python functions, APPL function essentially provides a Prompt Context that specially tailored for LM interactions to a Python function. New features of APPL functions include:</p> <ol> <li>Prompt Capturing: You can easily define prompts with expression statements within APPL functions.</li> <li>Prompt Retrieval: prompts are automatically retrieved when making LM calls. You may also retrieve prompts in the context by predefined functions.</li> <li>Context Passing: The prompt context can be passed to other APPL functions with configurable options.</li> </ol>"},{"location":"tutorials/3_appl_function/#prompt-context","title":"Prompt Context","text":"<p>Each APPL function has a prompt context, which is an object that stores the prompts and other information. The context is automatically managed by the APPL framework, and you don't need to worry about it in most cases.</p>"},{"location":"tutorials/3_appl_function/#prompt-capturing","title":"Prompt Capturing","text":"<p>As you have seen in the QA examples, you can define prompts with expression statements within APPL functions, including string literals (e.g., <code>\"Hello\"</code>), formatted strings (e.g., <code>f\"My name is {name}\"</code>), or more complex expressions. For types that subclass <code>Sequence</code>, such as <code>list</code> and <code>tuple</code>, the elements are recursively captured as prompts one by one. You may also define custom types and the ways to convert them to prompts by subclassing <code>Promptable</code> and implementing the <code>__prompt__</code> method. See the Appendix for more details.</p> Pay attention to return values of function calls <p>Function calls are also expression statements, which means their return values (when not <code>None</code>) may be captured as prompts based on the type. To avoid capturing the return value, you may write it as a assignment statement, for example when calling the <code>pop</code> function : <code>_ = {\"example\": \"Hello World\"}.pop(\"example\")</code>.</p> How about docstrings in APPL functions? <p>Docstring is a special expression statement in Python, so it will be captured as a prompt by default. Ideally, we hope the docstring can also be used as a part of the prompt. Otherwise, you may exclude the docstring by specifying <code>exclude_first_str</code>, like <pre><code>@ppl(exclude_first_str=True)\ndef my_function():\n    \"\"\"This is a docstring.\"\"\"\n    \"First prompt.\"\n</code></pre> Or if you do not want the first prompt to be the docstring of the function, you can change it as a f-string, like  <pre><code>@ppl\ndef my_function():\n    f\"First prompt.\"\n    \"Second prompt.\"\n</code></pre></p>"},{"location":"tutorials/3_appl_function/#prompt-retrieval","title":"Prompt Retrieval","text":"<p>Similar to the local and global variables in Python (retrieved with <code>locals()</code> and <code>globals()</code> functions, respectively), you can retrieve the prompts captured in the current function (with <code>records()</code>) or the full conversation in the context (with <code>convo()</code>). This example demonstrates how to retrieve the prompts captured in the current function and the full conversation in the context.</p> <p>When making LM calls using <code>gen()</code>, the full conversation is automatically retrieved from the context as the prompt. Therefore, instead of passing the prompt explicitly, the position of the <code>gen()</code> function within the APPL function determines the prompt used for the generation.</p>"},{"location":"tutorials/3_appl_function/#context-passing","title":"Context Passing","text":"<p>There are four different ways to pass the context when calling another APPL function (the callee) in an APPL function (the caller): new, copy, same, and resume.</p> <p></p> <ol> <li>new: The default behavior, create a new empty context.</li> <li>copy: This is similar to call by value in programming languages. The callee's context is a copy of the caller's context, therefore the changes in the callee's context won't affect the caller's context.</li> <li>same: This is similar to call by reference in programming languages. The callee's context is the same as the caller's context, therefore the changes in the callee's context will affect the caller's context.</li> <li>resume: This resumes the context of the function each time it is called, i.e., the context is preserved across calls, making the function stateful. It copies the caller's context for the first call as the initial context. It is useful when you want to continue the conversation from the last call.</li> </ol> <p>With these context management methods, you can now easily modularize your prompts as well as the workflow, so that they are more readable and maintainable.</p>"},{"location":"tutorials/3_appl_function/#example","title":"Example","text":"<p>In this example, we illustrate the usage of the first three context management methods and ways to decompose long prompts into smaller pieces using APPL functions. For the resume method, please refer to the multi-agent chat example.</p> <pre><code>import appl\nfrom appl import convo, gen, ppl, records\n\nappl.init()\n\n@ppl # (1)\ndef intro():\n    f\"Today is 2024/02/29.\"\n    return records() # (2)\n\n@ppl(ctx=\"same\") # (3)\ndef addon():\n    f\"Dates should be in the format of YYYY/MM/DD.\" # (4)\n\n@ppl(ctx=\"copy\")  # (5)\ndef query(question: str):\n    f\"Q: {question}\"\n    f\"A: \"\n    # print(convo())  # (6)\n    return gen()\n\n@ppl\ndef answer_questions(questions: list[str]):\n    # long prompt can be decomposed into several smaller `appl functions`\n\n    # method 1 (recommended): build the sub-prompts in an empty context\n    intro()  # (7)\n\n    # method 2: use the same context and modify it in the function\n    addon()  # (8)\n\n    return [query(q) for q in questions]\n\nquestions = [\n    \"What's the date tomorrow?\",\n    \"What's the date yesterday?\",\n    \"How many dates passed since 2024/02/02?\",\n]\nfor res in answer_questions(questions):\n    print(res)\n</code></pre> <ol> <li>Use new context, the default method for passing context.</li> <li>Local prompts are returned as a list of records, which can be add back to the caller's context.</li> <li>Use the caller's context, which contains the prompt <code>Today is 2024/02/29.</code>.</li> <li>The newly captured prompt influences the caller's context, now the caller's prompts contain both <code>Today is 2024/02/29.</code> and <code>Dates should be in the format of YYYY/MM/DD.</code>.</li> <li>Copy the caller's context, the prompts captured here will not influence the caller's context.</li> <li>Display the global prompts (<code>convo()</code>, means conversation) used for the generation (<code>gen()</code>).</li> <li>The callee returns <code>PromptRecords</code> containing sub-prompts, which are added to the caller's context.</li> <li>The callee returns <code>None</code>, the return value is not captured, but the context is already modified inside the callee.</li> </ol> <p>Three queries are independent and run in parallel, where the prompts and possible responses of the generations are shown below:</p> Overall outputFirst querySecond queryThird query <p>The Overall output will looks like: <pre><code>2024/03/01\n2024/02/28\n27 dates have passed since 2024/02/02.\n</code></pre></p> <p>Prompt: <pre><code>Today is 2024/02/29.\nDates should be in the format of YYYY/MM/DD.\nQ: What's the date tomorrow?\nA: \n</code></pre> Output will looks like <code>2024/03/01</code>.</p> <p>Prompt: <pre><code>Today is 2024/02/29.\nDates should be in the format of YYYY/MM/DD.\nQ: What's the date yesterday?\nA: \n</code></pre> Output will looks like <code>2024/02/28</code>.</p> <p>Prompt: <pre><code>Today is 2024/02/29.\nDates should be in the format of YYYY/MM/DD.\nQ: How many dates passed since 2024/02/02?\nA: \n</code></pre> Output will looks like <code>27 dates have passed since 2024/02/02.</code>.</p>"},{"location":"tutorials/3_appl_function/#caveats","title":"Caveats","text":"<p><code>@ppl</code> needs to be the last decorator.</p> <p>Since <code>@ppl</code> involves compiling the function, it should be the last decorator in the function definition, i.e. put it closest to the function definition. Otherwise, the function may not work as expected.</p> <p><code>@ppl</code> cannot be nested.</p> <p>Currently, <code>@ppl</code> cannot be nested within another <code>@ppl</code> function. You may define the inner function as a normal Python function and call it in the outer <code>@ppl</code> function.</p>"},{"location":"tutorials/4_concurrent/","title":"Concurrent LM Calls","text":"<p>Many prompt engineering techniques like Self-Consistency (CoT-SC) and Tree of Thoughts (ToT) involve non-sequential LM calls such as branching and gathering, where parallelizing the calls can significantly speed up the process.</p> <p>APPL provides a simple way to parallelize these calls using asynchronous computation.</p>"},{"location":"tutorials/4_concurrent/#asynchronous-execution","title":"Asynchronous Execution","text":"<p>In APPL, the <code>gen</code> function automatically starts a new thread (or process) to handle the LM call. The <code>gen</code> function does not block the main thread and returns a <code>Generation</code> object that represents the generation result. The generation result is not synchronized (waited) until its value is needed, therefore, multiple independent <code>gen</code> calls can be executed concurrently.</p> <p>StringFuture to represent strings that may not be available yet</p> <p>To support asynchronized execution, we introduce the <code>StringFuture</code> object similar to <code>concurrent.futures.Future</code>. <code>StringFuture</code> is a placeholder for a string value that will be available in the future, and can be used to represent generation results that are computed in other threads and not yet available.</p> <p>In most scenarios, you can use <code>StringFuture</code> as a normal <code>str</code>. The <code>StringFuture</code> delays its synchronization when possible, ideally only synchronizes the value when the <code>str</code> is called. For example, a concatenation of <code>StringFuture</code> objects can be done without waiting for the value of each <code>StringFuture</code> to be available.</p> <pre><code>import time\n\nimport appl\nfrom appl import gen, ppl, StringFuture\n\n@ppl\ndef mul(x:int, y:int):\n    f\"3*4=12\"\n    f\"{x}*{y}=\"\n    return gen()\n\nt0 = time.time()\nn = 3\ns = StringFuture(\"\\n\").join(\n    StringFuture(\" \").join(mul(i + 1, j + 1) for j in range(n))\n    for i in range(n)\n) # (1)\nprint(f\"Time: {time.time() - t0:.2f}\")\nprint(s)\nprint(f\"Time: {time.time() - t0:.2f}\")\n</code></pre> <ol> <li>equivalent to <pre><code>s = \"\"\nfor i in range(n):\n    if i:\n        s += \"\\n\"\n    for j in range(n):\n        if j:\n            s += \" \"\n        s += mul(i + 1, j + 1)\n</code></pre></li> </ol> <p>In this example, several <code>Generation</code> objects are returned by the <code>mul</code> function, and the <code>StringFuture</code> objects are used to concatenate the results, which results in a <code>StringFuture</code> object without synchronizing the generation results. The <code>print</code> function requires the value of the <code>StringFuture</code> object <code>s</code>, which triggers the synchronization of the generation results. Since the threads are already started when the <code>gen</code> function is called, the generation results are computed in parallel.</p> <p>Output will looks like: <pre><code>Time: 0.09\n1 2 3\n2 4 6\n3 6 9\nTime: 1.91\n</code></pre> where starting new threads could have a small overhead, but relatively small than API calls.</p> <p>Force synchronization</p> <p>If you want to force synchronization, you can call <code>.results</code> to wait for the results, or simply use <code>str</code> directly if the result is a string. For example, <code>mul(3, 4).results</code> or <code>str(mul(3, 4))</code>.</p> <p>This could lead to a slower execution time, for example, if you replace the computation of <code>s</code> as <code>s = \"\\n\".join(\" \".join(str(mul(i + 1, j + 1)) for j in range(n)) for i in range(n))</code>, the runtime could be around 8 seconds since the generations are not parallelized.</p>"},{"location":"tutorials/4_concurrent/#example-cot-sc","title":"Example (CoT-SC)","text":"<p>The following example demonstrates how to use APPL to naturally exploit the independence among the reasoning paths in Self Consistency of Chain-of-Thoughts to parallelize the execution.</p> Self Consistency of Chain-of-Thoughts (CoT-SC) <ul> <li>Chain-of-thoughts (CoT) prompting enhances the LLM's ability to perform complex reasoning by providing examples of intermediate reasoning steps.</li> <li>Self consistency samples different reasoning pathes from the LLM then marginalizes to generate a consensus. </li> </ul> <p>Below is an illustration of this method from the paper \"Self-Consistency Improves Chain of Thought Reasoning in Language Models\"<sup>1</sup>.</p> <p></p> <p>The implementation below shows an example of determining if a set of numbers add up to an even number (task introduced in source).</p> <pre><code>import time\n\nimport appl\nfrom appl import gen, ppl\n\nappl.init()\n\n\ndef parse_answer(answer: str):\n    # parse the ANS from: The answer is [ANS].\n    if (key := \"The answer is \") in answer:\n        return answer.split(key)[-1].split(\".\")[0].strip()\n    return None\n\n\ndef get_mode(answers: list[str]):\n    \"\"\"Get the mode of the answers\"\"\"\n    return max(set(answers), key=answers.count)\n\n\ndef marginalize(results: list):\n    \"\"\"Get the answer from the results and get the mode of the answers\"\"\"\n    # explicitly syncronize the results using str()\n    answers = [parse_answer(str(res)) for res in results]\n\n    return get_mode(answers)\n\n\n@ppl\ndef cot_consistency(cot_examples: list[str], question: str, num_trials: int):\n    cot_examples  # the list of examples are captured into prompt one-by-one\n    question\n    results = [gen() for _ in range(num_trials)]  # concurrent generation\n    return marginalize(results)  # marginalize the reasoning paths to get the answer\n\n\n@ppl\ndef cot_consistency_sequential(cot_examples: list[str], question: str, num_trials: int):\n    cot_examples  # the list of examples are captured into prompt one-by-one\n    question\n    results = [str(gen()) for _ in range(num_trials)]  # explicit syncronization\n    return marginalize(results)  # marginalize the reasoning paths to get the answer\n\n\n# example from https://www.promptingguide.ai/techniques/cot\ncot_examples = [\n    (\n        \"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\\n\"\n        \"A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\"\n    ),\n    (\n        \"The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\\n\"\n        \"A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\"\n    ),\n]\nquestion = (\n    \"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\"\n)\n\n\nn = 5\nstart_time = time.time()\nprint(f\"Parallel CoT-SC Answer: {cot_consistency(cot_examples, question, n)}\")\nprint(f\"Parallel CoT-SC takes {time.time() - start_time:.2f} seconds\")\n\nstart_time = time.time()\nprint(\n    f\"Sequential CoT-SC Answer: {cot_consistency_sequential(cot_examples, question, n)}\"\n)\nprint(f\"Sequential CoT-SC takes {time.time() - start_time:.2f} seconds\")\n</code></pre> <p>Output will looks like:</p> <pre><code>Parallel CoT-SC Answer: False\nParallel CoT-SC takes 1.74 seconds\nSequential CoT-SC Answer: False\nSequential CoT-SC takes 7.42 seconds\n</code></pre> <ol> <li> <p>https://arxiv.org/abs/2203.11171\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorials/5_tool_calls/","title":"Enabling Tool Calls for LMs","text":""},{"location":"tutorials/5_tool_calls/#defining-tools-with-python-functions","title":"Defining Tools with Python Functions","text":"<p>To streamline the process of LMs using tools, APPL provides a simple way to convert Python functions into tools that can be called by LMs. This is done by using the <code>as_tool</code> function, which automatically extract information from the function signature and docstring to create a tool specification from a Python function.</p> <p>Docstring Format</p> <p>The docstring needs to follow parsable formats like Google Style. We use <code>docstring_parser</code> to parse the docstring.</p> <p>For example, consider the following Python function that checks whether a number is a lucky number:</p> <pre><code>import sympy\n\ndef is_lucky(x: int) -&gt; bool:\n    \"\"\"Determine whether the input number is a lucky number.\n\n    Args:\n        x (int): The input number to be checked.\n\n    Returns:\n        bool: True if the number is a lucky number, False otherwise.\n    \"\"\"\n    return sympy.isprime(x + 3)\n</code></pre> <p>It can be converted into a tool using: <code>tool = as_tool(is_lucky)</code>, and then the tool can be expressed in a JSON format following the OpenAI schema using <code>tool.openai_schema</code>:</p> <pre><code>{\n  \"type\": \"function\",\n  \"function\": {\n    \"name\": \"is_lucky\",\n    \"description\": \"Determine whether the input number is a lucky number.\",\n    \"parameters\": {\n      \"properties\": {\n        \"x\": {\n          \"description\": \"The input number to be checked.\",\n          \"type\": \"integer\"\n        }\n      },\n      \"required\": [\"x\"],\n      \"type\": \"object\"\n    }\n  }\n}\n</code></pre> <p>Description of the Tool</p> <p>The description of the tool is extracted from the docstring. The description can be configured to different detail levels, for example, to include a long description, examples, etc.</p>"},{"location":"tutorials/5_tool_calls/#generating-and-running-tool-calls","title":"Generating and Running Tool Calls","text":"<p>APPL allows you to simply provide a list of Python functions as tools directly to the <code>gen</code> function, for example: <pre><code>actions = gen(tools=[is_lucky], tool_choice=\"required\")\n</code></pre></p> <p>Tool Calling Behavior</p> <p>The tool calling behavior is useful to control how LMs call tools, which can be specified by the <code>tool_choice</code> parameter in the <code>gen</code> function. Options includes <code>auto</code> (default), <code>required</code>, <code>none</code>, or a specific choice. Please refer to OpenAI's Documentation for more details. APPL provides another helper function <code>as_tool_choice</code> to convert a function to a <code>tool_choice</code>, e.g. <code>gen(tools=[is_lucky], tool_choice=as_tool_choice(is_lucky))</code>.</p> <p>The <code>actions</code> is a <code>Generation</code> object containing a list of tool calls, which can be easily executed via:</p> <pre><code>results = actions.run_tool_calls()\n</code></pre> <p>where the <code>results</code> are a list of <code>ToolMessage</code> objects that can be directly captured to the prompt.</p> <p>Adding Tool Calls and Results to the Prompt</p> <p>Both <code>Generation</code> and <code>ToolMessage</code> objects can be directly captured to the prompt. When the <code>Generation</code> contains tool calls, the tool calls will be captured to the prompt as a list of <code>AIMessage</code> objects containing the tool call information.</p>"},{"location":"tutorials/5_tool_calls/#examples","title":"Examples","text":""},{"location":"tutorials/5_tool_calls/#complete-example","title":"Complete Example","text":"<p>Now let's put everything together. The following code augments LM with a user-defined tool to answer a simple question:</p> <pre><code>import sympy\n\nimport appl\nfrom appl import AIMessage, Generation, convo, gen, ppl, records\n\nappl.init()\n\n\ndef is_lucky(x: int) -&gt; bool:\n    \"\"\"Determine whether the input number is a lucky number.\n\n    Args:\n        x (int): The input number to be checked.\n\n    Returns:\n        bool: True if the number is a lucky number, False otherwise.\n    \"\"\"\n    return sympy.isprime(x + 3)\n\n\n@ppl\ndef func(x):\n    f\"Is {x} a lucky number?\"\n\n    # Initiate the generation with tool `is_lucky``,\n    # which is built into a tool by automatically extracting\n    # information from the function signature and docstring.\n    # And then store the tool call messages into the prompt\n    (actions := gen(tools=[is_lucky]))\n\n    if actions.is_tool_call:  # LLM choose to call the tool\n        # Run the tool calls and store the resulted ToolMessages into the prompt\n        (results := actions.run_tool_calls())  # results is a list of ToolMessage\n        # results[0].content contains the result of the first tool call\n\n        # Let LLM generate the text answer while providing the tool information\n        answer = gen(tools=[is_lucky], tool_choice=\"none\")\n    else:  # LLM choose to generate the answer directly\n        answer = actions.message\n\n    return answer\n\n\nn = 2024\nans = func(n)\nprint(ans)\nprint(f\"The correct answer is {is_lucky(n)}.\")\n</code></pre> <p>The conversation including the tool calls would look like this:</p> Role Message User Is 2024 a lucky number? Assistant [ToolCall(id='call_...', name='is_lucky', args='{\"x\":2024}')] Tool(is_lucky) True <p>The output will look like this: <pre><code>Yes, 2024 is a lucky number!\nThe correct answer is True.\n</code></pre></p>"},{"location":"tutorials/5_tool_calls/#parallel-tool-calls","title":"Parallel Tool Calls","text":"<p>Similarly, let's try to reimplement the example used in OpenAI's documentation, where the amount of code is significantly reduced.</p> <pre><code>import json\nimport appl\nfrom appl import gen, ppl\n\nfrom typing import Literal\n\nappl.init()\n\n\ndef get_current_weather(\n    location: str, unit: Literal[\"celsius\", \"fahrenheit\"] = \"fahrenheit\"\n) -&gt; str:\n    \"\"\"Get the current weather in a given location.\n\n    Args:\n        location (str): The city and state, e.g. San Francisco, CA\n    \"\"\"\n    if \"tokyo\" in location.lower():\n        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n    elif \"san francisco\" in location.lower():\n        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n    elif \"paris\" in location.lower():\n        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n    else:\n        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n\n\n@ppl\ndef get_weather_for_cities():\n    \"What's the weather like in San Francisco, Tokyo, and Paris?\"\n\n    (actions := gen(tools=[get_current_weather]))\n\n    if actions.is_tool_call:\n        (results := actions.run_tool_calls())\n        answer = gen(tools=[get_current_weather], tool_choice=\"none\")\n    else:\n        answer = actions.message\n\n    return answer\n\n\nprint(get_weather_for_cities())\n</code></pre>"},{"location":"tutorials/5_tool_calls/#more-examples-in-cookbook","title":"More Examples in Cookbook","text":"<p>Now we are able to build more complex workflows involving tool calls, like the ReAct method, as shown in this cookbook.</p>"},{"location":"tutorials/6_prompt_coding/","title":"Introducing Prompt Coding Helpers","text":"<p>To better utilize the power of LMs, a lot of effort has been put into designing prompts, and the complexity of prompts has been increasing as observed in recent researches like ToolEmu, Swe-agent, etc.</p> <p>APPL provides two types of prompt coding helpers, <code>Compositor</code> and <code>Definition</code>, to facilitate coding prompts in a structured and maintainable way. These helpers were originally designed in PromptCoder and have been used to develop prompts in the ToolEmu project with more than 20k tokens in total. By leveraging Python's idiomatic features, we have enhanced the usability and flexibility of these helpers.</p>"},{"location":"tutorials/6_prompt_coding/#prompt-compositors","title":"Prompt Compositors","text":"<p>It is common to write prompts in Markdown or XML format to interact with LMs, where the prompts are structured with different elements like headers, lists, tags, etc.</p> <p>To facilitate the creation of structured prompts in a programmatic way, we provide a set of compositors that compose the text within their context into a structured prompt with the corresponding format. For example, the <code>NumberedList</code> is a context manager composes a list of text within its scope into a numbered list: <pre><code>with NumberedList():\n    f\"First item\"\n    f\"Second item\"\n&gt;&gt;&gt; composed into &gt;&gt;&gt;\n1. First item\n2. Second item\n</code></pre></p> <p>You can also nest the compositors to create more complex structures, like: <pre><code>@ppl\ndef compose(items: list[str]):\n    with Tagged(\"div\"):  # (1)\n        \"Display the items:\"\n        with NumberedList(indent=4): # (2)\n            items # (3)\n    return records()\n\nprint(compose([\"item1\", \"item2\"]))\n</code></pre></p> <ol> <li>The default indentation inside the tag is 4 spaces, can be changed by setting the <code>indent_inside</code> parameter.</li> <li>Explicitly set the indentation for the content inside the list.</li> <li>Fits different number of items.</li> </ol> <p>The composed prompt is: <pre><code>&lt;div&gt;\n    Display the items:\n        1. item1\n        2. item2\n&lt;/div&gt;\n</code></pre></p> <p>Check the list of available compositors in the API Reference. </p>"},{"location":"tutorials/6_prompt_coding/#prompt-definitions","title":"Prompt Definitions","text":"<p>To make the prompt more structured and clear, it is often helpful to define concepts in prompts and refer to them in different parts of the prompt.</p> <p>APPL provides the <code>Definition</code> class for defining concepts by subclassing it. For example:</p> <pre><code>class InputReq(Definition):\n    name = \"Input Requirement\"\n    fstr = \"[{}]\" # defines the format when referring to the concept\n</code></pre> <p>To include the concept in the prompt, you can instantiate the class with the description as an argument, for example: <pre><code>@ppl\ndef func():\n    InputReq(desc=\"The input should be two numbers.\")\n</code></pre></p> <p>Referring to the concept</p> <p>You can use the class name in the prompt (without instantiation), which will be replaced by a certain format containg the concept's name. For example, <pre><code>&gt;&gt;&gt; print(f\"{InputReq}\")\n[Input Requirement]\n</code></pre> In some cases you may need the raw name of the concept without formatting, you can use the <code>!r</code> flag: <pre><code>&gt;&gt;&gt; print(f\"{InputReq!r}\")\nInput Requirement\n</code></pre></p> <p>With the help of modern IDEs like VSCode, you can easily navigate to the definition and references of the concept. The IDEs can also provide highlights to class names, which makes it easier to distinguish between concepts defined in the prompt and other variables in the code. These features are especially useful when the prompt is large and complex. </p>"},{"location":"tutorials/6_prompt_coding/#example","title":"Example","text":"<p>We use the example in PromptCoder to illustrate the usage of these prompt coding helpers:</p> <pre><code>import appl\nfrom appl import BracketedDefinition as Def\nfrom appl import define, empty_line, ppl, records\nfrom appl.compositor import *\n\n# (1)\nclass InputReq(Def):\n    name = \"Input Requirement\"\n\nclass OutputReq(Def):\n    name = \"Output Requirement\"\n\n@ppl\ndef requirements(opr: str):\n    \"Requirements\"\n    with NumberedList():\n        InputReq(desc=\"The input should be two numbers.\") # (2)\n        OutputReq(desc=f\"The output should be the {opr} of the two numbers.\") # (3)\n    return records()\n\n@ppl\ndef instruction(language: str):\n    \"Instruction\"\n    with LineSeparated():\n        f\"Write a function in {language} that satisfies the {InputReq} and {OutputReq}.\" # (4)\n    return records()\n\n@ppl\ndef get_prompt(opr: str, language: str):\n    with LineSeparated(indexing=\"##\"):\n        requirements(opr)  # (5)\n        empty_line()  # (6)\n        instruction(language)\n    return records()\n</code></pre> <ol> <li>Declare the input and output requirements classes for reference.     Alternatively, but not recommended, you can define classes as follows:     <code>InputReq = define(\"Input Requirement\")</code> and <code>OutputReq = define(\"Output Requirement\")</code>.     But then VSCode cannot recognize it as a class.</li> <li>Complete the input requirement with a description.</li> <li>Complete the output requirement with a description.</li> <li>The naming can be used to distinguish:<ul> <li>variable naming (e.g. language): the dynamic input.</li> <li>class naming (e.g. InputReq): the reference to the concept.</li> </ul> </li> <li>The returned prompt will be formatted using the compositor.</li> <li>Create an empty line regardless of other compositors.</li> </ol> <p>The result of <code>get_prompt(\"sum\", \"Python\")</code> will be: <pre><code>## Requirements\n1. Input Requirement: The input should be two numbers.\n2. Output Requirement: The output should be the sum of the two numbers.\n\n## Instruction\nWrite a function in Python that satisfies the [Input Requirement] and [Output Requirement].\n</code></pre></p> <p>Overall, these helpers provide a more structured and maintainable way to write dynamic prompts.</p>"},{"location":"tutorials/7_tracing/","title":"Using Tracing","text":"<p>APPL supports tracing APPL functions and LM calls to facilitate users to understand and debug the program executions. The trace is useful for reproducing (potentially partial) execution results by loading cached responses of the LM calls, which enables failure recovery and avoids the extra costs of resending these calls. This also unlocks the possibility of debugging one LM call conveniently.</p>"},{"location":"tutorials/7_tracing/#enabling-appl-tracing","title":"Enabling APPL Tracing","text":"<p>To enable tracing in APPL, you can set the <code>tracing</code> configuration to <code>true</code> in <code>appl.yaml</code>:</p> appl.yaml<pre><code>settings:\n  tracing:\n    enabled: true\n    path_format: &lt;Your custom path for trace files&gt;\n    # The default path format is \"./dumps/traces/{basename}_{time:YYYY_MM_DD__HH_mm_ss}\"\n    strict_match: true # For loading the trace files, explain later.\n</code></pre>"},{"location":"tutorials/7_tracing/#visualizing-the-trace","title":"Visualizing the Trace","text":"<p>Then we run the QA example with tracing enabled:</p> answer_questions.py<pre><code>import appl\nfrom appl import AIRole, gen, ppl\nfrom appl.const import NEWLINE\n\nappl.init()\n\n\n@ppl(ctx=\"copy\")  # copy the context from caller\ndef get_answer(question: str):\n    question  # append to the prompt\n    return gen()  # return as a future object\n\n\n@ppl  # marks APPL function\ndef answer_questions(quotation: str, questions: list[str]):\n    \"Extract the name of the author from the quotation below and answer questions.\"\n    quotation  # append to the prompt\n    with AIRole():  # assistant message\n        f\"The name of the author is {gen(stop=NEWLINE)}\"  # specify the prefix\n    return [get_answer(q) for q in questions]  # parallelize calls\n\n\nquotation = '\"Simplicity is the ultimate sophistication.\" -- Leonardo da Vinci'\nquestions = [\n    \"In what era did the author live?\",\n    \"What is the most famous painting of the author?\",\n]\nfor ans in answer_questions(quotation, questions):\n    print(ans)\n</code></pre> <pre><code>$ python answer_questions.py\n</code></pre> <p>You can find the result trace file in the specified path. The default location is <code>./dumps/traces/answer_questions_&lt;the timestamp&gt;.pkl</code>. You can then visualize the traces using the script:</p> <pre><code>$ python -m appl.cli.vis_trace &lt;path to the trace file&gt; -o &lt;output file&gt;\n</code></pre> <p>The default output file is a HTML file, which can be viewed in a browser. We provide a sample trace file here.</p> <p>If you specify the output file to be a <code>.json</code> file, the script will generate a JSON file that is loadable by Chrome's tracing viewer (with address: chrome://tracing/). The loaded trace will look like this:</p> <p></p>"},{"location":"tutorials/7_tracing/#resuming-from-a-previous-trace","title":"Resuming from a Previous Trace","text":"<p>You can reproduce the results from a previous trace by specifying the <code>APPL_RESUME_TRACE</code> environment variable with the path to the trace file:</p> <pre><code>$ APPL_RESUME_TRACE=&lt;path to the trace file&gt; python answer_questions.py\n</code></pre> <p>Then each LM call will be loaded from the trace file if it exists. Such loading can be useful for:</p> <ul> <li>Debugging a specific LM call: the LM calls before that can be loaded from the trace file, therefore no need to resend them with extra costs.</li> <li>Reproducible results: the trace file can be shared with others to reproduce the same results.</li> <li>Recovery from failures: if the program fails, you can resume from the trace file to avoid resending the LM calls.</li> </ul> <p><code>strict_match</code> for calls with same prompts</p> <p>When <code>strict_match</code> is <code>False</code>, the LM calls with the same prompt will load the same response from the trace file. To load the response for each LM call correspondingly, you can set <code>strict_match</code> to <code>True</code> (which is the default setting), then the <code>gen_id</code> of the LM call will also be used for matching.</p>"},{"location":"tutorials/7_tracing/#langsmith-tracing","title":"LangSmith Tracing","text":"<p>Optionally, you can use LangSmith to inspect the LM calls and responses in the trace files. You need to obtain your API key from LangSmith and add the following environment variables to your <code>.env</code> file:</p> .env<pre><code>LANGCHAIN_TRACING_V2=true\nLANGCHAIN_API_KEY=&lt;your api key&gt;\n# [Optional] specify the project name\n# LANGCHAIN_PROJECT=&lt;your project name&gt;\n</code></pre> LangSmith may contain inaccurate statistics for asynchronous LM calls <p></p> <p>When running the example, the time statistics for the <code>get_answer</code> function calls are not consistent.</p> <p>Nonetheless, it is sometimes useful to record and inspect the LM calls and responses using LangSmith.</p>"},{"location":"tutorials/appendix/prompt_capture/","title":"Prompt Capture","text":"<p>Expression statements within APPL functions are captured as prompts based on the type of the value, when the value is not <code>None</code>.</p> <p>The types can be categorized into three groups according to the behavior when converting to prompts: prompts, sequence of prompts, and custom promptable.</p>"},{"location":"tutorials/appendix/prompt_capture/#1-prompts","title":"1. Prompts","text":"<p>The most basic prompt is a string (including <code>StringFuture</code>), which can be a string literal, formatted string or string variable. We convert the string to a message based on the role scope.</p> <p>An already constructed <code>Message</code> object is also considered a prompt, as shown in the following example.</p> <pre><code>import appl\nfrom appl import ppl, records, AIMessage\n\nappl.init()\n\n@ppl\ndef greeting(name: str):\n    \"Hello world!\"\n    AIMessage(\"Nice to meet you.\")\n    return records()\n\nprint(greeting(\"APPL\"))\n# user: Hello world!\n# assistant: Nice to meet you.\n</code></pre> <p>Besides, for LMs that support multimodal inputs, the <code>Image</code> are also captured as part of the prompt.</p> <p>Note types like <code>int</code>, <code>float</code> and <code>bool</code> are not captured. To capture these values, you can explicitly convert them to strings or use them in formatted strings.</p>"},{"location":"tutorials/appendix/prompt_capture/#2-sequence-of-prompts","title":"2. Sequence of Prompts","text":"<p>For types that subclass <code>Sequence</code>, such as <code>list</code> and <code>tuple</code>, the elements are recursively captured as prompts one by one.</p> <pre><code>import appl\nfrom appl import ppl, records\n\nappl.init()\n\n@ppl\ndef greeting(name: str):\n    [\"Hello world!\", (\"My name is APPL.\", \"Nice to meet you.\")]\n    return records()\n\nprint(greeting(\"APPL\"))\n# Hello world!\n# My name is APPL.\n# Nice to meet you.\n</code></pre>"},{"location":"tutorials/appendix/prompt_capture/#3-custom-promptable","title":"3. Custom Promptable","text":"<p>You may also define custom types and the ways to convert them to prompts by subclassing <code>Promptable</code> and implementing the <code>__prompt__</code> method.</p> <pre><code>import appl\nfrom appl import Promptable, ppl, records\n\nappl.init()\n\nclass MyPromptable(Promptable):\n    def __init__(self, number: int):\n        self.number = number\n\n    def __prompt__(self):\n        return f\"The number is {self.number}.\"\n\n@ppl\ndef custom_promptable():\n    MyPromptable(42)\n    return records()\n\nprint(custom_promptable())\n# The number is 42.\n</code></pre> <p>Warning messages for unsupported types</p> <p>APPL will display a warning message when encountering unsupported types that are not captured as prompts. <pre><code>WARNING | Cannot convert {VALUE} of type {TYPE} to prompt, ignore.\n</code></pre></p>"},{"location":"tutorials/usage/instructor/","title":"Using Instructor","text":"<p>Instrcutor is a Python library that makes it a breeze to work with structured outputs from LMs. APPL uses <code>instructor</code> to support specifying the structure of the output, with a simple argument <code>response_model</code>.</p>"},{"location":"tutorials/usage/instructor/#get-started","title":"Get Started","text":"<p>Let's reimplement the example from the instructor:</p> <pre><code>from pydantic import BaseModel\n\nimport appl\nfrom appl import gen, ppl\n\nappl.init()\n\n\n# Define your desired output structure\nclass UserInfo(BaseModel):\n    name: str\n    age: int\n\n\n@ppl\ndef get_user_info() -&gt; UserInfo:\n    # Extract structured data from natural language\n    \"John Doe is 30 years old.\"\n    return gen(response_model=UserInfo).results\n\n\nuser_info = get_user_info()\n\nprint(user_info.name)\n# &gt; John Doe\nprint(user_info.age)\n# &gt; 30\n</code></pre>"},{"location":"tutorials/usage/instructor/#with-streaming","title":"With Streaming","text":"<p>When using streaming, the <code>response_obj</code> is a generator that yields partial objects. Let's slightly modify the example from instructor:</p> <pre><code># https://jxnl.github.io/instructor/why/?h=iterable#partial-extraction\nfrom typing import List\n\nfrom pydantic import BaseModel\nfrom rich.console import Console\n\nimport appl\nfrom appl import Generation, gen, ppl\nfrom instructor import Partial\n\nappl.init()\n\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n\nclass Info(BaseModel):\n    users: List[User]\n\n\n@ppl\ndef extract_info() -&gt; Generation:\n    f\"randomly generate 3 users.\"\n    return gen(response_model=Partial[Info], stream=True).response_obj\n\n\nconsole = Console()\n\nfor extraction in extract_info():\n    obj = extraction.model_dump()\n    console.clear()\n    console.print(obj)\n</code></pre> <p>It will gradually print the output:</p> <pre><code>{\n    'users': [\n        {'name': 'Alice', 'age': 25},\n        {'name': 'Bob', 'age': 30},\n        {'name': 'Charlie', 'age': 20}\n    ]\n}\n</code></pre>"},{"location":"tutorials/usage/servers/","title":"Servers","text":"<p>APPL manages various LM backends as servers, where each server contains a set of configurations, such as the model name, base url, and default parameters.</p>"},{"location":"tutorials/usage/servers/#generation-parameters","title":"Generation Parameters","text":"<p>The parameters used in the <code>gen</code> function to interact with the LM servers are unified into the OpenAI format, which is supported by the <code>litellm</code> package.</p> <p>See the documentation of <code>litellm.completion</code> for the full list of parameters, where the required parameters are managed by APPL:</p> <ul> <li><code>model</code>: configured in the server settings.</li> <li><code>messages</code>: the full conversation (a list of messages) stored in the context when the <code>gen</code> function is called.</li> </ul>"},{"location":"tutorials/usage/servers/#server-configurations","title":"Server Configurations","text":"<p>The basic servers are configured as follows: <pre><code>servers:\n  default: gpt35-turbo\n  gpt35-turbo: # the name of the server, should avoid using '.' in the name\n    model: gpt-3.5-turbo # the model name\n  gpt4-turbo:\n    model: gpt-4-turbo\n  gpt4o:\n    model: gpt-4o\n</code></pre></p> <p>You may specify another server of <code>gpt-3.5-turbo</code> with default temperature to be <code>0.0</code> in the <code>appl.yaml</code> file: <pre><code>servers:\n  # default: gpt35-turbo-temp0  # (1)\n  gpt35-turbo-temp0: # (2)\n    model: gpt-3.5-turbo\n    temperature: 0.0 # (3)\n</code></pre></p> <ol> <li>you may set the default server here, so you don't need to specify the server name in the <code>gen</code> function.</li> <li>Then when you call <code>gen(\"gpt35-turbo-temp0\")</code>, the default temperature will be <code>0.0</code>.</li> <li>You could still override the temperature by specifying it in the <code>gen</code> function.</li> </ol> <p>We provide examples of configurations for different servers in our setup guide. See also the list of available models in <code>litellm</code>.</p>"},{"location":"tutorials/usage/servers/#multiple-servers-example","title":"Multiple Servers Example","text":"<p>In the following, we provide a complete example for using multiple servers in different <code>gen</code> calls. The used servers are configured in this example.</p> <pre><code>import appl\nfrom appl import gen, ppl\n\nappl.init()\n\n\n@ppl\ndef add1(a, b):\n    f\"what's {a} plus {b}?\"\n    return gen(\"azure-gpt35\")\n    # The default server is \"gpt35-turbo\", if not specified\n\n\n@ppl\ndef add2(a, b):\n    f\"what's {a} plus {b}?\"\n    return gen(\"claude-35-sonnet\")\n\n\n@ppl\ndef add3(a, b):\n    f\"what's {a} plus {b}?\"\n    return gen(\"moonshot-8k\")\n\n\n@ppl\ndef add4(a, b):\n    f\"what's {a} plus {b}?\"\n    return gen(\"srt-llama2\")\n\n\n# print(add1(\"one\", \"two\"))\n# print(add2(\"three\", \"four\"))\n# print(add3(\"five\", \"six\"))\n# print(add4(\"seven\", \"eight\"))\n</code></pre>"},{"location":"tutorials/usage/srt/","title":"Using SGLang Runtime (SRT)","text":"<p>Work in progress</p> <p>This page is still a work in progress. It will be updated soon.</p>"},{"location":"tutorials/usage/streaming/","title":"Using Streaming","text":"<p><code>gen</code> returns a <code>Generation</code> object, which is a wrapper around the response from the LM.</p> <p>Enabling streaming in APPL is simple. Just set the <code>stream</code> parameter to <code>True</code> when calling <code>gen</code>. The return is a generator that yields the response in chunks, but you can still access the complete response.</p>"},{"location":"tutorials/usage/streaming/#example","title":"Example","text":"<pre><code>import appl\nfrom appl import ppl, records\nfrom appl.func import gen\n\nappl.init()\n\n\n@ppl\ndef func(stream=True):\n    # adopted from https://cookbook.openai.com/examples/how_to_stream_completions\n    \"Count to 100, with a comma between each number and no newlines. E.g., 1, 2, 3, ...\"\n    return gen(stream=stream)\n\n\ncontent = func(stream=False)\nprint(f\"Content: {content}\")\n\ncontent = func(stream=True)\nprint(f\"Content: {content}\")\n</code></pre>"},{"location":"coverage/","title":"Coverage Report","text":""}]}